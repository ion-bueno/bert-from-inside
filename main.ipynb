{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Inside a NLP multitasking neural network BERT, one model to rule them all.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f1502687ebd4b54ab04f5ffd19217aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bee040519a9f41098bef35c2a60a1465",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45990e9736824aeb986c06acc81a2965",
              "IPY_MODEL_f6deb2fe8240481d9d5bfd1b44e783f1"
            ]
          }
        },
        "bee040519a9f41098bef35c2a60a1465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45990e9736824aeb986c06acc81a2965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_985b9b33df73463a8c71522efda6d6a0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2c61aa06ce94964be1379da1ec22121"
          }
        },
        "f6deb2fe8240481d9d5bfd1b44e783f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2e188df132a471ebdc9dce413cfc498",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 1.63kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6e8641592ec4564b8e3778035210bd2"
          }
        },
        "985b9b33df73463a8c71522efda6d6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2c61aa06ce94964be1379da1ec22121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2e188df132a471ebdc9dce413cfc498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6e8641592ec4564b8e3778035210bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f6c0d79e98a4e9e8293c85e1b8e4f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0fd4e2e2fa994cc78c79f27062067e77",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8171dc4159a4bf3b003ad47ebac4764",
              "IPY_MODEL_26277e5b42004678bbaaf580363edf2c"
            ]
          }
        },
        "0fd4e2e2fa994cc78c79f27062067e77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8171dc4159a4bf3b003ad47ebac4764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8e7d35680455433e855651b091793cca",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a0f163d2a45401798ef64e14cf4fc6c"
          }
        },
        "26277e5b42004678bbaaf580363edf2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2762151775a148aea97b73eb74495c4f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 55.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b6b827a504c4f2b889f32dfcd36fa6d"
          }
        },
        "8e7d35680455433e855651b091793cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a0f163d2a45401798ef64e14cf4fc6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2762151775a148aea97b73eb74495c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b6b827a504c4f2b889f32dfcd36fa6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af14dda1b790437189dd7c0382935d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c4feec35de94e958ba374628c7054e7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_acaa213161414aeabbf241b61941e1a0",
              "IPY_MODEL_bdea8d6ff88e40119c85853a54f35fb5"
            ]
          }
        },
        "0c4feec35de94e958ba374628c7054e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acaa213161414aeabbf241b61941e1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fccbe30ef2684ca699ea28856cc5ed2f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f511a1b0c9444bfb8cae31e5db352f79"
          }
        },
        "bdea8d6ff88e40119c85853a54f35fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5b60500dc1d643128f907fa143ccacab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 115kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81bc148563b7470f9196d8fbc47e6ed9"
          }
        },
        "fccbe30ef2684ca699ea28856cc5ed2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f511a1b0c9444bfb8cae31e5db352f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b60500dc1d643128f907fa143ccacab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81bc148563b7470f9196d8fbc47e6ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "506ca0e3c62a452cb3e2704b8b9bf8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_13ff9da6e10541aab9e9e9a704147cb1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bbbf5459306e40ffabe640b1548f976b",
              "IPY_MODEL_f1426195d8bc42338cc9610a1f437ca3"
            ]
          }
        },
        "13ff9da6e10541aab9e9e9a704147cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bbbf5459306e40ffabe640b1548f976b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_abb68cbf86004239b71e993e64184478",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a198eb06b4b04b788e9ec59be37151a0"
          }
        },
        "f1426195d8bc42338cc9610a1f437ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e47a75498d649a9a40d82d3b7796ee5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 37.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f2c59cd2bb5493ab7933ab53d3936a7"
          }
        },
        "abb68cbf86004239b71e993e64184478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a198eb06b4b04b788e9ec59be37151a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e47a75498d649a9a40d82d3b7796ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f2c59cd2bb5493ab7933ab53d3936a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "440b9472437e49ebb9a9260530baa2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b9004dbe0dc488d86a533825c688595",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_33bb89426b80409eb9cd732e82388ef8",
              "IPY_MODEL_4be1c68778824de4a26be9165895de05"
            ]
          }
        },
        "8b9004dbe0dc488d86a533825c688595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33bb89426b80409eb9cd732e82388ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6df2816983de43958b865bd7f7617cad",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b69aa86d8a364765842bd254012e9d12"
          }
        },
        "4be1c68778824de4a26be9165895de05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c22d5d233f25410f8b2b0ef98198210c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 2.94MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd709bd239914f939d7715d0521b15ec"
          }
        },
        "6df2816983de43958b865bd7f7617cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b69aa86d8a364765842bd254012e9d12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c22d5d233f25410f8b2b0ef98198210c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd709bd239914f939d7715d0521b15ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e9725e1ba544d3d9203eae5a2d0e475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8788bfb0ccd445f6ba3ad9bb7be74bc9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c3f9948aac948d293c398cf5a417e32",
              "IPY_MODEL_f4c57e72e00d40948ba36dc6adf08cd1"
            ]
          }
        },
        "8788bfb0ccd445f6ba3ad9bb7be74bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c3f9948aac948d293c398cf5a417e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_126c4d2b672e4a5cbfcd9d512abae2c6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56f2e3acc95648f7a782b9722841c366"
          }
        },
        "f4c57e72e00d40948ba36dc6adf08cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e69d18b335ba46b4b5c1d162230bf4c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:24&lt;00:00, 9.52kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac6bf0402d8044da90bb8d9f0d1984e0"
          }
        },
        "126c4d2b672e4a5cbfcd9d512abae2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56f2e3acc95648f7a782b9722841c366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e69d18b335ba46b4b5c1d162230bf4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac6bf0402d8044da90bb8d9f0d1984e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe0432f9218b4c12bc35c922b536f195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a76be72a95d465496f4d8cea582f535",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f0069b280dc40c4bcb9ccc5abb2f885",
              "IPY_MODEL_5d00075a0c3643d18d26f22561a274c2"
            ]
          }
        },
        "1a76be72a95d465496f4d8cea582f535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f0069b280dc40c4bcb9ccc5abb2f885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a35acaf71359436caad40f1e32ef29b4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d50b5a17d804e068a774a62adb25538"
          }
        },
        "5d00075a0c3643d18d26f22561a274c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71e3380df79249df9080c49c5b461c9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:03&lt;00:00, 132kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f794ffbf82484c6d9d0a960bf295cf93"
          }
        },
        "a35acaf71359436caad40f1e32ef29b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d50b5a17d804e068a774a62adb25538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71e3380df79249df9080c49c5b461c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f794ffbf82484c6d9d0a960bf295cf93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b7ac193b8154a51bad7914a00b0a3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80ad8ae47c7043eca3f4cff4a7d12d93",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f316730905274844a1f91871c0b16e76",
              "IPY_MODEL_f969fcb81223486f8c7a4e7a7b0f4627"
            ]
          }
        },
        "80ad8ae47c7043eca3f4cff4a7d12d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f316730905274844a1f91871c0b16e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7f428cd9bf384cb8b71c2e42a75b76cb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9b57a531a8d44e7902c7677657b68c9"
          }
        },
        "f969fcb81223486f8c7a4e7a7b0f4627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e518741636ae442aa5d6524980626779",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:19&lt;00:00, 1.47B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_756fffb49b884e5c969ef125903f05b3"
          }
        },
        "7f428cd9bf384cb8b71c2e42a75b76cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9b57a531a8d44e7902c7677657b68c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e518741636ae442aa5d6524980626779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "756fffb49b884e5c969ef125903f05b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1090b21d25245f88b2a72c6a01b4ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_41c0f0756da845f494f8e8e3ef16b36c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9afe269498c4253903288d39941238c",
              "IPY_MODEL_451ee635bd094208b3143a981b0cd7e5"
            ]
          }
        },
        "41c0f0756da845f494f8e8e3ef16b36c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9afe269498c4253903288d39941238c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e22473163684c44815186e59b577aad",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25f2426e7bc249adbedeb9284fd5be54"
          }
        },
        "451ee635bd094208b3143a981b0cd7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4259839021854589a8c8ceb2ef06d768",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59/59 [00:23&lt;00:00,  2.49ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a88431e2e3db465bb2a53f401641a682"
          }
        },
        "2e22473163684c44815186e59b577aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25f2426e7bc249adbedeb9284fd5be54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4259839021854589a8c8ceb2ef06d768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a88431e2e3db465bb2a53f401641a682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddbfc0a78ac546babe28623be113d2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_31eff7bd4d874f2ca17d25340452a87f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7062d92bec54453f86a6d74276521993",
              "IPY_MODEL_7718d264c80f490f82a0969770e12b07"
            ]
          }
        },
        "31eff7bd4d874f2ca17d25340452a87f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7062d92bec54453f86a6d74276521993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a69380d978664da89cdf6ca98f287e12",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccb247d7e9354ddb987e94ae00e7b6ee"
          }
        },
        "7718d264c80f490f82a0969770e12b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3bc6944b18c4e0a937043a5e9eb8b2e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11/11 [00:05&lt;00:00,  1.94ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08598375abb64fc1a3ef663393bad0dd"
          }
        },
        "a69380d978664da89cdf6ca98f287e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccb247d7e9354ddb987e94ae00e7b6ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3bc6944b18c4e0a937043a5e9eb8b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08598375abb64fc1a3ef663393bad0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0598196dd17457db1b77b9e618c2413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe724a5b17424057b4735eb93199da54",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a311de2a4154f3ab0af1d2dee560d37",
              "IPY_MODEL_513310f02c3d4c7d98c626ea8468cf9f"
            ]
          }
        },
        "fe724a5b17424057b4735eb93199da54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a311de2a4154f3ab0af1d2dee560d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf3ff96fce274888beb6c61993c54d04",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba16af5336214c97ba6f5991448df2ed"
          }
        },
        "513310f02c3d4c7d98c626ea8468cf9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_126f777ee99448f0a084ea777be9f5e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29/29 [00:23&lt;00:00,  1.26ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21df018008614224afa5c3f6f94443cd"
          }
        },
        "bf3ff96fce274888beb6c61993c54d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba16af5336214c97ba6f5991448df2ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "126f777ee99448f0a084ea777be9f5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21df018008614224afa5c3f6f94443cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d0a2ebe953f42da803bdac9c2595734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2ed81205538b46edabca7dbfe1184f47",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_81fec09cc1af446cae82b34350949c6a",
              "IPY_MODEL_165ea7b45b8c40319c559ec964e7659c"
            ]
          }
        },
        "2ed81205538b46edabca7dbfe1184f47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81fec09cc1af446cae82b34350949c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0a2f12911184da1ae63d10792997f9d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b09aa3ef534d44fd9118eadfa57bf2d1"
          }
        },
        "165ea7b45b8c40319c559ec964e7659c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c518782401cf4f3a9fca433d2263456b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 663B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1f40d992aaf47c3b43f3e353969eecd"
          }
        },
        "a0a2f12911184da1ae63d10792997f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b09aa3ef534d44fd9118eadfa57bf2d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c518782401cf4f3a9fca433d2263456b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1f40d992aaf47c3b43f3e353969eecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbaa2c0e8ca0482bba6b292e95d80d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5898b35a148a45ceb873c5a62bcf5d8e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1cecf2c992324159987be5e3b7fd396c",
              "IPY_MODEL_e43481a6687445b6850721c1b2744596"
            ]
          }
        },
        "5898b35a148a45ceb873c5a62bcf5d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cecf2c992324159987be5e3b7fd396c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e0ac7b4346041daae56916fbc3d2202",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e17eed2f91b4171bd43cbfcbf4c47c1"
          }
        },
        "e43481a6687445b6850721c1b2744596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce18f6c4c8aa47c9b037482aa7bf05a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 54.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de668dd4988049efa6240a16ea941d35"
          }
        },
        "1e0ac7b4346041daae56916fbc3d2202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e17eed2f91b4171bd43cbfcbf4c47c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce18f6c4c8aa47c9b037482aa7bf05a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de668dd4988049efa6240a16ea941d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64d974ee29b34346a1e23ab84e83da29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a81b4db3b21f4787aacaabe2ee5b7589",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_79dead5fec0d40a0be9b5e3cbac3cb78",
              "IPY_MODEL_30e2db9525fa446db58f4f62531c8252"
            ]
          }
        },
        "a81b4db3b21f4787aacaabe2ee5b7589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79dead5fec0d40a0be9b5e3cbac3cb78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d35ad4cc26194ae989ec0a43a935439a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8538d594f594a7caa35aaec126c89f1"
          }
        },
        "30e2db9525fa446db58f4f62531c8252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c015fc852ad4c13882d5c2e6dda7d7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29/29 [00:45&lt;00:00,  1.57s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_883a8c99d8214c9ab23d505bec2386ea"
          }
        },
        "d35ad4cc26194ae989ec0a43a935439a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8538d594f594a7caa35aaec126c89f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c015fc852ad4c13882d5c2e6dda7d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "883a8c99d8214c9ab23d505bec2386ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b2925cf924a4c1b9ed4e9c04946eac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_628dc2219a0c433e94a47ed23abcdb8a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_110fb8ae4b8b4d769a06ed28d865bfd7",
              "IPY_MODEL_8fffe27c5aaa49d1940455a2a74fee22"
            ]
          }
        },
        "628dc2219a0c433e94a47ed23abcdb8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "110fb8ae4b8b4d769a06ed28d865bfd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ccdda2c8aba44598cf3f3d37f59acfc",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28908,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28908,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60419ef214d64c19ac613ac1c64f40c0"
          }
        },
        "8fffe27c5aaa49d1940455a2a74fee22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93809beebdce4b5fa05b601e1f7caf1c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28908/28908 [01:04&lt;00:00, 450.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a6966989e534c0e8e6b7fcaecd8983c"
          }
        },
        "9ccdda2c8aba44598cf3f3d37f59acfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60419ef214d64c19ac613ac1c64f40c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93809beebdce4b5fa05b601e1f7caf1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a6966989e534c0e8e6b7fcaecd8983c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8484a0bfcf0841f093c1ce69d348ca1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cf69768a777b4f4b9258c86fc062f079",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_24c9f41ff2c64a5c8bc6506a65ddb14a",
              "IPY_MODEL_ca73b6a35d3446fc9284816e830de84c"
            ]
          }
        },
        "cf69768a777b4f4b9258c86fc062f079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24c9f41ff2c64a5c8bc6506a65ddb14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0d0f0b646534c7da04db2eb0fc79930",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1726,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1726,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84ad0a35fb024434bf8677841d8a96e3"
          }
        },
        "ca73b6a35d3446fc9284816e830de84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55bca16ee108408f921a5b59124fc3f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.51k/? [00:00&lt;00:00, 8.29kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2edf729d2a44cc28fbecd5d481accc6"
          }
        },
        "b0d0f0b646534c7da04db2eb0fc79930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84ad0a35fb024434bf8677841d8a96e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55bca16ee108408f921a5b59124fc3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2edf729d2a44cc28fbecd5d481accc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f10d3549f244fc386416f0befdfcf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_777a4312aaec410aa65e1fd60bef3dc8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_24ff47fed31942fa944c14a7de11f3d6",
              "IPY_MODEL_30c283d72bfb4023a9ef6010f47a1aae"
            ]
          }
        },
        "777a4312aaec410aa65e1fd60bef3dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24ff47fed31942fa944c14a7de11f3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d684d83cd49a4b6e8f95ca9384a3b99e",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1119,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1119,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e929ea257f441a0a0311bd26f44c350"
          }
        },
        "30c283d72bfb4023a9ef6010f47a1aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c252d2d260643aaad00da4a543d3a6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.31k/? [00:00&lt;00:00, 101kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c95955470ee42c69473bcf647ce1e86"
          }
        },
        "d684d83cd49a4b6e8f95ca9384a3b99e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e929ea257f441a0a0311bd26f44c350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c252d2d260643aaad00da4a543d3a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c95955470ee42c69473bcf647ce1e86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6e3d15baec24120b3c367ca80678568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8f8268933c86452eb34abd1838a2ccbc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26d33194cf9b4bf298e14a270e324bae",
              "IPY_MODEL_c14e3520b77542159ebe28d15a7bbed8"
            ]
          }
        },
        "8f8268933c86452eb34abd1838a2ccbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26d33194cf9b4bf298e14a270e324bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0474700018be4e4d970483e4fff94b1b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f2c3d64a809431f89e3ede6be9c39d1"
          }
        },
        "c14e3520b77542159ebe28d15a7bbed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14bcd76be7d24a2fa51618074c92fec2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  4.30ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8864580db2db4f9791d45bf8328919c1"
          }
        },
        "0474700018be4e4d970483e4fff94b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f2c3d64a809431f89e3ede6be9c39d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14bcd76be7d24a2fa51618074c92fec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8864580db2db4f9791d45bf8328919c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "305834880de044beb14e8b89191710b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_11d6a2566cd641c08e25491e01b2bd8a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_979984a1e3ad4d25a6e6698864bca662",
              "IPY_MODEL_2d6fff80042c49479d6b134f74171541"
            ]
          }
        },
        "11d6a2566cd641c08e25491e01b2bd8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "979984a1e3ad4d25a6e6698864bca662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a066cf72c1064964ab21f2021a40f7c3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d16af42af3b940afa8503bd5d4db2190"
          }
        },
        "2d6fff80042c49479d6b134f74171541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85fa2f4f0a6f4b169966df5d7807f3b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [31:54&lt;00:00, 1914.48s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a1b45412cac469383e238a73ed356e6"
          }
        },
        "a066cf72c1064964ab21f2021a40f7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d16af42af3b940afa8503bd5d4db2190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85fa2f4f0a6f4b169966df5d7807f3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a1b45412cac469383e238a73ed356e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ion-bueno/bert-from-inside/blob/main/Inside_a_NLP_multitasking_neural_network_BERT%2C_one_model_to_rule_them_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo8tsaAo5a11"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDbShn3OWDj0"
      },
      "source": [
        "During this notebook it is used Pytorch. It is installed running next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npZ_8a2vxn7N"
      },
      "source": [
        "#!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oic_Lz0GZ6Pt"
      },
      "source": [
        "Other modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2LVsAsvOwqW"
      },
      "source": [
        "# Pytorch modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "# Colab modules\n",
        "from google.colab import files\n",
        "# Usual modules used\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmA7A_2yZ28N"
      },
      "source": [
        "Mount drive to load files from Google Drive. Useful to load trained models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KatQ5N1QI_ie",
        "outputId": "5d332284-9a6b-40a5-d08c-3be096ce0ecd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksCpEC_5vdb_"
      },
      "source": [
        "# 1 - Background\n",
        "\n",
        "Recurrent neural networks (RNN) were declared as state of the art in sequence modeling and transduction problems, in particular long short-term memory (LSTM) and gated recurrent neural networks (GRU).\n",
        "\n",
        "These models work respect the position of the symbols, input and output. They generate a sequence of hidden states $h_t$, function of previous hidden states $h_{t-1}$ and current input $x_t$.\n",
        "\n",
        "\\begin{equation}\n",
        "  h_t = f(x_t, h_{t-1})\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByU_MM9YmQLq"
      },
      "source": [
        "![RNN](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/RNN.png)\n",
        "\n",
        "> RNN high level structure. Original image from [Dive into Deep Learning](https://d2l.ai/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL9zstqnViDC"
      },
      "source": [
        "However, RNNs are really slow to train due to the sequential computation they employ. This operations cannot be optimized with modern hardware employed today (GPUs or TPUs).\n",
        "\n",
        "Another important issue is the difficulty to capture long-term dependencies. Gradient based learning algorithms face many problems as the sequence or spans increases. Gradients can exploit or vanish, resulting in many difficulties for gradient optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHtLxnVeSryf"
      },
      "source": [
        "One novel mechanism employed was **Attention**. It is based on retaining the most significant information. It is applied between the elements of the input and the output. In translation for example, between the source sentence and the translation. Attention has been widely used for many tasks, specially in translation.\n",
        "\n",
        "In this work we are interested in one type of attention: **Self-attention**. Attention is only applied between the elements of the input sequence, relating themselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fs7sOi1O53b"
      },
      "source": [
        "# 2 - Self Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlzWfPuaNpyf"
      },
      "source": [
        "It is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. The goal is mapping sets to sets, regardless of the order in the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations. \\\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snXFyJKGRZSP"
      },
      "source": [
        "## 2.1 - Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gddSt8MOQdP6"
      },
      "source": [
        "If we have a sentence with length $ n $, each word is usually represented with a word vector $ x_i \\in \\mathbb R^{d}, i \\in \\lbrace1, \\dots, n \\rbrace $, where $ d $ is the dimension of the vector. This parameter depends on the size of embedding we are using. \n",
        "\n",
        "\\begin{array}\n",
        "  \\text{The} & \\text{orange} & \\text{is} & \\text{very} & \\text{healthy} \\\\\n",
        "  x_1 & x_2 & x_3 & x_4 & x_5\n",
        "\\end{array}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_ZPAha90o8p",
        "outputId": "8425e10b-e899-46bd-a0ab-0992d3f9d543"
      },
      "source": [
        "#@title { vertical-output: true }\n",
        "sentence = \"The orange is very healthy\" #@param {type:\"string\"}\n",
        "list_sentence = sentence.split()\n",
        "#@markdown Dimension of the embedding vector\n",
        "d =  3#@param {type:\"number\"}\n",
        "vocab = set(list_sentence)\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "embeds = nn.Embedding(len(word_to_ix), d)\n",
        "\n",
        "for word in list_sentence:\n",
        "  lookup_tensor = torch.tensor(word_to_ix[word], dtype=torch.long)\n",
        "  vector = embeds(lookup_tensor)\n",
        "  print(word)\n",
        "  print(vector.detach().numpy(), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The\n",
            "[-0.31746945 -0.7561296  -1.6417314 ] \n",
            "\n",
            "orange\n",
            "[ 1.0567445  1.3392346 -1.5657164] \n",
            "\n",
            "is\n",
            "[ 0.38440773  1.9201869  -1.7528055 ] \n",
            "\n",
            "very\n",
            "[-0.6748045   0.6028945  -0.38523147] \n",
            "\n",
            "healthy\n",
            "[0.22498168 2.5262623  0.47089648] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQiDwc4JybzS"
      },
      "source": [
        "These vectors do not provide context information, i.e. the relationship with the rest of the elements in the sequence. For example, $ x_2 $ does not determine if *orange* refers to the color or to the fruit, so it is not clear if it exists a clear relationship with *healthy*.\n",
        "\n",
        "We are looking for an output vector, formed by attention weigths, $ y_i \\in \\mathbb R^{n}, i \\in \\lbrace1,\\dots,n\\rbrace $, where $ n $ is the number of elements in the sequence. For all $ i, j \\in \\lbrace{1,\\dots,n}\\rbrace $.\n",
        "\n",
        "\\begin{equation}\n",
        "  y_i = \\sum^{n}_{j} x_j w_{ij}\n",
        "\\end{equation}\n",
        "\n",
        "The question is, how could we get these weigths? In order to illustrate the process, we are going to use the previous sentence and get the weights associated to the new embedding vector for *orange* ($ y_{2} $).\n",
        "\n",
        "> Remember that $ n $ is the number of words in the sentence and $ d $ the dimension of the word vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo04Vmks3Gq0"
      },
      "source": [
        "> The explanation is based in the slides of [A series of videos on transformers](https://www.youtube.com/playlist?list=PLDw5cZwIToCvXLVY2bSqt7F2gu8y-Rqje) by Lennart Svensson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BgDkBMJ2yxK"
      },
      "source": [
        "## 2.2 - Weighted Averages of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_6qnuArbEUh"
      },
      "source": [
        "The traditional idea was based in providing larger weigths to similar words making use of the **dot product**. Two similar vectors are going to get a bigget dot product than two very distant. Applying the dot product and softmax respect $ x_2 $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqoYDolEOJdg"
      },
      "source": [
        "\\begin{equation}\n",
        "  \\begin{matrix} z_{1} = x_1^T x_2 & \\dots & z_{n} = x_n^T x_2 \\end{matrix} \\\\\n",
        "  \\begin{bmatrix} w_{1} & \\dots & w_{n} \\end{bmatrix} = \\text{softmax} \\begin{pmatrix} z_{1} & \\dots & z_{n} \\end{pmatrix} \\\\\n",
        "  y_2 = \\sum_{j=1}^{n} x_j w_{j}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRMYg52-XN6d"
      },
      "source": [
        "![Weighted Averaged of Words](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/weight_ave_words.png)\n",
        "\n",
        "> Observations and weights respect time. Original image from [A series of videos on transformers](https://www.youtube.com/playlist?list=PLDw5cZwIToCvXLVY2bSqt7F2gu8y-Rqje)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7WPCEYKYbh_"
      },
      "source": [
        "Intuitively, it is a method which could obatin good results. Nevertheless, several times correlated words are not necessary close. Therefore it is not an accurate and general method to extract the information between one element and the rest of the sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s8JJyH4MNy0"
      },
      "source": [
        "## 2.3 - Weights in Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biJITJoQXosT"
      },
      "source": [
        "We need to introduce three new vectors: **query**, **keys** and **values**. It is also included three new parameters: $ W_Q, W_K, W_V $, which are going to be trained. For all $ i \\in \\lbrace{1,\\dots,n}\\rbrace $.\n",
        "\n",
        "\\begin{matrix}\n",
        "  \\text{Query} & \\rightarrow & q_i = W^Q x_2 \\\\\n",
        "  \\text{Keys} & \\rightarrow & k_i = W^K x_i \\\\\n",
        "  \\text{Values} & \\rightarrow & v_i = W^V x_i \n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2outRvCKMV-Z"
      },
      "source": [
        "Instead of using directly the inputs $ x_i $, it is employed the **query** $ q_i $ and **keys** $ k_i $ to calculate the weights:\n",
        "\\begin{equation}\n",
        "    \\begin{matrix} z_{1} = \\frac{k_1^T q_2}{\\sqrt{d}} & \\dots & z_{n} = \\frac{k_n^T q_2}{\\sqrt{d}} \\end{matrix} \\\\\n",
        "  \\begin{bmatrix} w_1 & \\dots & w_n \\end{bmatrix} = \\text{softmax} \\begin{pmatrix} z_1 & \\dots & z_n \\end{pmatrix}\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AAWQFphXsty"
      },
      "source": [
        "To calculate the final embedding vector it is used the **values** $ v_i $ instead of the inputs $ x_i $\n",
        "\n",
        "\\begin{equation}\n",
        "  y_2 = \\sum_{j=1}^{n} v_j w_{j}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLDkf7xi-hsw"
      },
      "source": [
        "Intuitively,the query attends the word for which we are going to get the attention weights. Keys corresponds with the rest of the elements in the dot product operation. Values are used in the final combination with the weights. Thanks to learnable matrixes, these combinations are optimized to find combinations and correlations in the own sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsBg0CcUAqvi"
      },
      "source": [
        "![Self-attention process](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/self-attention_process.png)\n",
        "\n",
        "> Self-attention process. Original image from [Illustrated: Self-Attention](https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PLlEXM0YpG2"
      },
      "source": [
        "### 2.3.1 - Matrix Notation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnvZVIwwDn5W"
      },
      "source": [
        "To represent the whole process in matrix notation:\n",
        "\n",
        "\\begin{matrix}\n",
        "  \\text{Input} & \\rightarrow & X = \\begin{bmatrix} x_1 & \\dots & x_n \\end{bmatrix}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ca6iaIA1EjQ",
        "outputId": "f4faad63-69cb-475d-d098-c3afc110fae1"
      },
      "source": [
        "lookup_tensor = torch.tensor([word_to_ix[word] for word in list_sentence], dtype=torch.long)\n",
        "X = embeds(lookup_tensor).T\n",
        "print('Input: word per column\\n')\n",
        "print(X.detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: word per column\n",
            "\n",
            "[[-0.31746945  1.0567445   0.38440773 -0.6748045   0.22498168]\n",
            " [-0.7561296   1.3392346   1.9201869   0.6028945   2.5262623 ]\n",
            " [-1.6417314  -1.5657164  -1.7528055  -0.38523147  0.47089648]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yME-uGRP24l_"
      },
      "source": [
        "Calculate **query**, **keys** and **values**:\n",
        "\n",
        "\\begin{matrix}\n",
        "  Q = W^Q X = \\begin{bmatrix} q_1 & \\dots & q_n \\end{bmatrix}  \\\\\n",
        "  K = W^K X = \\begin{bmatrix} k_1 & \\dots & k_n \\end{bmatrix} \\\\\n",
        "  V = W^V X = \\begin{bmatrix} v_1 & \\dots & v_n \\end{bmatrix}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEMuOjMq4XU0",
        "outputId": "9ce9969b-89d5-4a32-fea4-21183da21b03"
      },
      "source": [
        "# initialize weight matrixes\n",
        "dim = (X.shape[-1], X.shape[0])\n",
        "W_Q = torch.randn(dim)\n",
        "W_K = torch.randn(dim)\n",
        "W_V = torch.randn(dim)\n",
        "\n",
        "# calculate query, keys, values\n",
        "Q = W_Q @ X\n",
        "K = W_K @ X\n",
        "V = W_V @ X\n",
        "\n",
        "print('Query\\n')\n",
        "print(Q.detach().numpy(), '\\n')\n",
        "print('Keys\\n')\n",
        "print(K.detach().numpy(), '\\n')\n",
        "print('Values\\n')\n",
        "print(V.detach().numpy(), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query\n",
            "\n",
            "[[ 0.40143386  1.4549783   1.3745883   0.00988346  0.4754185 ]\n",
            " [-2.2835617  -2.7096138  -2.2824137   0.1534014   1.1689688 ]\n",
            " [-2.3086407  -0.7271125  -0.8702544  -0.35365814  1.8533789 ]\n",
            " [ 0.28501964 -0.25374693  0.37790537  0.6649422   0.3226221 ]\n",
            " [-0.03956471 -1.0332265   0.7107655   1.7592607   1.5696275 ]] \n",
            "\n",
            "Keys\n",
            "\n",
            "[[-3.6956363  -6.423422   -7.0837703  -1.2404075  -1.286077  ]\n",
            " [-0.87281394  2.9651587   4.331558    1.4782315   4.811989  ]\n",
            " [ 0.10588197 -1.2205676  -1.4331455  -0.2650718  -1.2491778 ]\n",
            " [ 2.6784935   1.2734275   0.75933963 -0.27580094 -2.7265365 ]\n",
            " [-0.59819865  0.5450333   0.17361934 -0.40630165  0.5639424 ]] \n",
            "\n",
            "Values\n",
            "\n",
            "[[ 1.5186684e+00  1.2753845e+00  1.9212992e+00  8.3878815e-01\n",
            "   5.3446352e-02]\n",
            " [-1.1084964e+00  6.7837077e-01 -6.3989872e-01 -1.4200007e+00\n",
            "  -1.5725984e-03]\n",
            " [-7.0784152e-01  3.3553225e-01  1.3670356e+00  1.0299271e+00\n",
            "   2.3493910e+00]\n",
            " [-2.2009237e+00  1.1667681e+00  1.9532933e+00  6.9959748e-01\n",
            "   4.2658615e+00]\n",
            " [ 2.1095672e+00 -7.6235515e-01  1.0950362e-01  1.0292510e+00\n",
            "  -1.7392871e+00]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJhYMfJBhMV_"
      },
      "source": [
        "Calculate the **weights**:\n",
        "\n",
        "\\begin{matrix}\n",
        "  Z = \\frac{K^T Q}{\\sqrt{d}} \\\\\n",
        "  W = \\text{softmax}(Z)\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9Iir7Nn1NCp",
        "outputId": "dac2b4d8-b506-46a4-8bbb-06c88b0553e0"
      },
      "source": [
        "Z = (K.T @ Q) / (d)\n",
        "# dim=0 since we want to apply it per column\n",
        "W = nn.LogSoftmax(dim=0)(Z)\n",
        "print('Weigths\\n')\n",
        "print(W.detach().numpy(), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weigths\n",
            "\n",
            "[[-0.32573107 -0.44227198 -0.3947039  -1.8314507  -2.5964112 ]\n",
            " [-2.7399578  -5.1851063  -4.0858665  -1.1288322  -1.9056249 ]\n",
            " [-3.7487602  -6.5165844  -5.5190873  -1.3678294  -1.8587875 ]\n",
            " [-1.7845215  -1.1012802  -1.2774891  -2.2016933  -1.7377019 ]\n",
            " [-3.8165622  -4.0228477  -3.6281216  -1.889592   -0.8098069 ]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYvPf694-192"
      },
      "source": [
        "Finally, we get the **output** matrix:\n",
        "\n",
        "\\begin{matrix}\n",
        "  \\text{Output} & \\rightarrow & Y = VW = \\begin{bmatrix} y_1 & \\dots & y_n \\end{bmatrix}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg6YXnOC_e4w",
        "outputId": "dc1ac2f4-5ccd-48c7-ade6-5b5fd7a23842"
      },
      "source": [
        "Y = V @ W\n",
        "print('Output\\n')\n",
        "print(Y.detach().numpy(), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output\n",
            "\n",
            "[[-12.892485  -20.943724  -17.679747   -8.796818  -11.445624 ]\n",
            " [  3.441215    2.7129316   3.0171936   5.2690396   5.2436395]\n",
            " [-16.61799   -20.920595  -18.475939   -7.6592283  -5.0348387]\n",
            " [-27.331787  -35.736576  -31.049734   -9.559011   -4.8098927]\n",
            " [  5.7925434   8.169694    6.673355   -2.1323311  -4.6081295]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0yR7j8HDIaw"
      },
      "source": [
        "As it is normal, we have not obtained a meaningful result, since $ W^Q, W^K, W^V $ have not been trained. At the end, we are looking for a rectangular matrix which relates every word in the sentence. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkH-EJ8jlh8O"
      },
      "source": [
        "![Intuition self-attention](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/intuition_att.png)\n",
        "\n",
        "> Intuition about attention. Image from [exBERT](https://huggingface.co/exbert/?model=bert-base-cased&modelKind=bidirectional&sentence=The%20orange%20is%20very%20healthy&layer=0&heads=..0,1,2,3,4,5,6,7,8,9,10,11&threshold=0.7&tokenInd=null&tokenSide=null&maskInds=..&hideClsSep=true) tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx2d2n9VycK7"
      },
      "source": [
        "# 3 - The Transformer\n",
        "\n",
        "In 2017 was presented the Transformer in the paper [Attention is All You Need](https://arxiv.org/abs/1706.03762). It is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequence aligned RNNs or convolution. The Transformer reached a new state of the art in translation quality, the original goal for the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_xD9N3umEyu"
      },
      "source": [
        "![Transformer architecture](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/transformer.png)\n",
        "\n",
        "> Transformer architecture. Image from [Attention is All You Need](https://arxiv.org/abs/1706.03762)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78bu--O6DXAu"
      },
      "source": [
        "In order to understand how the Transformer works, it is going to be explained the main parts.\n",
        "\n",
        "> The code is based mainly in the implementation of [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html), which implements the model step by step as it is discussed in the original paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9XTCL8IJ9Ma"
      },
      "source": [
        "## 3.1 - Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIW801LBKBh5"
      },
      "source": [
        "The model is based in an encoder-decoder structure, as other competitive neural sequence transduction models. It receives as input a complete sentence and generates the probabilities for the next word as output. Usually it is selected the higher one and feed it into the decoder until it is selected the token which indicates the end of sequence. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nofb2wJqO9TP"
      },
      "source": [
        "![High level transformer architecture](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/hl_trans_archi.png)\n",
        "\n",
        "> High-level transformer architecture. From the slides of [A series of videos on transformers](https://www.youtube.com/watch?v=0SmNEp4zTpc&list=PLDw5cZwIToCvXLVY2bSqt7F2gu8y-Rqje)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jopZSHTl6sk2"
      },
      "source": [
        "The Transformer generates a one symbol at a time, consuming the previously generated symbols as additional input, so it is an example of auto-regressive model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxiXBozxPpWI"
      },
      "source": [
        "## 3.2 - Input Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOKfYGq8R90U"
      },
      "source": [
        "Before going into the encoder and decoder stacks, mention how the sentences are preprocessed. The word vectors used as input in the encoder and the decoder are formed by the sum of other two vectors: **word embedding** and **positional encoding**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE33YK_we8uE"
      },
      "source": [
        "> Let's define some variables:\n",
        "\n",
        "\n",
        "\n",
        "*   Number of sentences in a batch: $ m $\n",
        "*   Number of words per sentence: $ n $\n",
        "*   Embedding dimension: $ d_{model} $\n",
        "*   Size of vocabulary: $ vocab $\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np5nmAyUbPgV"
      },
      "source": [
        "![Transformer input embedding](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/in_emb.png)\n",
        "\n",
        "> Transformer input embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsV9N-zJYnGg"
      },
      "source": [
        "### 3.2.1 - Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLsRZqxRTL4i"
      },
      "source": [
        "It is used learned embeddings to convert the input tokens and output tokens to vectors of dimension $ d_{model} $. It is shared the same weight matrix between the two embbeding layers, similar to [Using the Output Embedding to Improve Language Models](https://arxiv.org/abs/1608.05859). Also mention those weihts are multiplied by $ \\sqrt{d_{model}} $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kav4S0GhU3Jd"
      },
      "source": [
        "class Embeddings(nn.Module):\n",
        "  def __init__(self, d_model, vocab):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.lut = nn.Embedding(vocab, d_model)\n",
        "    self.d_model = d_model\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lut(x) * math.sqrt(self.d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmnQ3x8IYrRV"
      },
      "source": [
        "### 3.2.2 - Positional Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuY7cXIoTnaj"
      },
      "source": [
        "The attention blocks only map sets to sets, due to that, there is not any information about the position of the word in the sentence. Then it is injected some information about the relative or absolute position. In the original paper, it is used sine and cosine functions of different frequencies:\n",
        "\n",
        "\\begin{equation}\n",
        "  PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}}) \\\\\n",
        "  PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}})\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s3UgPQ0Wdck"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  \"\"\"Implement the PE function\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, d_model, dropout, max_len=5000):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    position = torch.arange(0, max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2) * \n",
        "                         -(math.log(10000.0) / d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
        "    return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhcQ8jbyyzlp"
      },
      "source": [
        "The output is the addition of both embeddings. \n",
        "\n",
        "\\begin{matrix}\n",
        "  x_i = & \\underbrace{E_i}_\\text{Word Embedding} & + & \\underbrace{P_i}_\\text{Positional Encoding}\n",
        "\\end{matrix}\n",
        "\n",
        "Let's see how is the input and how is transformed after this process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpnPSaICY6OA"
      },
      "source": [
        "Function to mask Transformer inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lzuoKnVa03e"
      },
      "source": [
        "def subsequent_mask(size):\n",
        "  \"\"\"Mask out subsequent positions\n",
        "\n",
        "  \"\"\"\n",
        "  attn_shape = (1, size, size)\n",
        "  subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "  return torch.from_numpy(subsequent_mask) == 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oSCMJUEY2pU"
      },
      "source": [
        "Class to manage one batch of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCLpgj6fZ4UW"
      },
      "source": [
        "class Batch:\n",
        "  \"\"\"Object for holding a batch of data with mask during training\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, src, trg=None, pad=0):\n",
        "    self.src = src\n",
        "    self.src_mask = (src != pad).unsqueeze(-2)\n",
        "    if trg is not None:\n",
        "      self.trg = trg[:, :-1]\n",
        "      self.trg_y = trg[:, 1:]\n",
        "      self.trg_mask = self.make_std_mask(self.trg, pad)\n",
        "      self.ntokens = (self.trg_y != pad).data.sum()\n",
        "\n",
        "  @staticmethod\n",
        "  def make_std_mask(tgt, pad):\n",
        "    \"\"\"Create a mask to hide padding and future words\n",
        "\n",
        "    \"\"\"\n",
        "    tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "    tgt_mask = tgt_mask & Variable(subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
        "    return tgt_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS_sxWBgY_wJ"
      },
      "source": [
        "Function to generate a random batch of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f_dsjQNVVfT"
      },
      "source": [
        "def batch_gen(V, batch, words):\n",
        "  \"\"\"Generate random data for a src-tgt copy task.\n",
        "\n",
        "  Args:\n",
        "  V (int): until number created for random int\n",
        "  batch (int): number of rows\n",
        "  words (int): number of columns\n",
        "\n",
        "  Returns:\n",
        "  Batch\n",
        "\n",
        "  \"\"\"\n",
        "  data = torch.from_numpy(np.random.randint(1, V, size=(batch, words)))\n",
        "  data[:, 0] = 1\n",
        "  src = Variable(data, requires_grad=False)\n",
        "  tgt = Variable(data, requires_grad=False)\n",
        "  return Batch(src, tgt, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cyPzIoPVu_A"
      },
      "source": [
        "We can check the Transformer input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZAKlqt0iSBb",
        "outputId": "6f982f7b-7c96-47da-cc7e-fb29ab6f4a59"
      },
      "source": [
        "#@title { vertical-output: true }\n",
        "#@markdown Number of sentences in a batch\n",
        "m = 5 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Number of words in a sentence\n",
        "n = 10 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Embedding dimension\n",
        "d_model = 512 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Vocabulary size\n",
        "vocab = 11 #@param {type:\"integer\"}\n",
        "\n",
        "batch = batch_gen(vocab, m, n)\n",
        "emb = Embeddings(d_model, vocab)\n",
        "pos = PositionalEncoding(d_model, 0.01)\n",
        "\n",
        "emb_w = emb.lut.weight\n",
        "print('Embedding matrix with dimension: (vocab x d_model)')\n",
        "print(tuple(emb_w.shape), '\\n')\n",
        "#print(emb_w.detach().numpy(), '\\n')\n",
        "\n",
        "enc_in = batch.src\n",
        "print('Encoder input before embedding with dimension: (m x n) ')\n",
        "print(tuple(enc_in.shape), '\\n')\n",
        "\n",
        "enc_out = nn.Sequential(emb, pos)(enc_in)\n",
        "print('Encoder input with dimension: (m x n x d_model)')\n",
        "print(tuple(enc_out.shape), '\\n')\n",
        "\n",
        "dec_in = batch.trg\n",
        "print('Decoder input before embedding  with dimension: (m x n-1) ')\n",
        "print(tuple(dec_in.shape), '\\n')\n",
        "\n",
        "dec_out = nn.Sequential(emb, pos)(dec_in)\n",
        "print('Decoder input with dimension: (m x n-1 x d_model)')\n",
        "print(tuple(dec_out.shape), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding matrix with dimension: (vocab x d_model)\n",
            "(11, 512) \n",
            "\n",
            "Encoder input before embedding with dimension: (m x n) \n",
            "(5, 10) \n",
            "\n",
            "Encoder input with dimension: (m x n x d_model)\n",
            "(5, 10, 512) \n",
            "\n",
            "Decoder input before embedding  with dimension: (m x n-1) \n",
            "(5, 9) \n",
            "\n",
            "Decoder input with dimension: (m x n-1 x d_model)\n",
            "(5, 9, 512) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9ofzwczProp"
      },
      "source": [
        "## 3.3 - Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PP1EybI5CV6"
      },
      "source": [
        "The encoder stacks $ N $ encoder blocks which map sets to sets, what means the output size is the same than input: $ ( m \\ x \\ n \\ x \\ d_{model} ) $. In the original implementation, they employ $ N=6 $ encoders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms1C-CsrbIuR"
      },
      "source": [
        "![Transformer's encoder](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/encoder.png)\n",
        "\n",
        "> Encoder architecture. Modified image from [Attention is All You Need](https://arxiv.org/abs/1706.03762)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAibzJp2sMNL"
      },
      "source": [
        "Each block is formed by two sub-layers: **Multi-Head Attention** and **Feed Forward**. Both are followed by an **Add \\& Norm** layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuOR0vIaZeH6"
      },
      "source": [
        "### 3.3.1 - Multi-Head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSCGGrr5Uof3"
      },
      "source": [
        "The Transformer differs for using exclusively self-attention. This model employs a type of self-attention called **Scaled Dot-Product Attention**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3njTSJhVEfur"
      },
      "source": [
        "#### 3.3.1.1 - Scaled Dot-Product Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdUPRWV1u9Ao"
      },
      "source": [
        "It is fast and space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code.\n",
        "\n",
        "We have queries $ Q $ and keys $ K $ of dimension $ d_k $ and values $ V $ of dimension $ d_v $.\n",
        "\n",
        "\\begin{equation}\n",
        "  \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\n",
        "\\end{equation}\n",
        "\n",
        "For large values of $ d_k $ the softmax function could have extremely small gradients. For this reason, the dot product is scaled by $ \\frac{1}{\\sqrt{d_k}} $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLtjORVBnZ1D"
      },
      "source": [
        "![Scaled dot product attention](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/sdp_attention.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeDeFHvgWprw"
      },
      "source": [
        "def sdp_attention(query, key, value, mask=None, dropout=None):\n",
        "  d_k = query.size(-1)\n",
        "  scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scores = scores.masked_fill(mask == 0, -1e9)\n",
        "  p_attn = F.softmax(scores, dim=-1)\n",
        "  if dropout is not None:\n",
        "    p_attn = dropout(p_attn)\n",
        "  return torch.matmul(p_attn, value), p_attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cxAhy-RZxHi"
      },
      "source": [
        "> To remember variables:\n",
        "\n",
        "*   Number of sentences in a batch: $ m $\n",
        "*   Number of words per sentence: $ n $\n",
        "*   Embedding dimension: $ d_{model} $\n",
        "\n",
        "> And let's introduce new ones\n",
        "\n",
        "\n",
        "*   Attention blocks: $ h $\n",
        "*   Dimension attention layers: $ d_k = \\frac{d_{model}}{h} $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64X60ZyWAQz"
      },
      "source": [
        "Multi-Head Attention is based on performing attention in parallel. There are $ h $ different blocks, with identical structure but different parameterers: $ W^Q $, $ W^K $ and $ W^V $. The output vectors from different heads are concatenated for each word using the parameter $ W^O $.\n",
        "\n",
        "\\begin{equation}\n",
        "  \\text{MultiHead}(Q,K,V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h) W_O \\\\\n",
        "  \\text{where} \\ \\text{head}_i = \\text{Attention}(QW^Q_i, KW^K_i, VW^V_i) \\\\\n",
        "  W^Q_i \\in \\mathbb R^{d_{model}\\ x \\ d_k}, \\ W^K_i \\in \\mathbb R^{d_{model}\\ x \\ d_k}, \\ W^V_i \\in \\mathbb R^{d_{model}\\ x \\ d_v} \\\\\n",
        "  W^O \\in \\mathbb R^{h d_v\\ x \\ d_{model}}\n",
        "\\end{equation}\n",
        "\n",
        "The idea is to get information from different representation subspaces at different positions. To get an intuition, we could see it as one head is understanding the sentence gramatically, another one from the point of spelling, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB3nhzM6dyOk"
      },
      "source": [
        "> In the papers [Attention is All You Need](https://arxiv.org/abs/1706.03762) and [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html), it is used $ h = 8 $ and they assume that $ d_v = d_k $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcZ1ULyDnpXm"
      },
      "source": [
        "![Multi-Head Attention](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/multi__head_attention.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKpHHa4vZ0Lc"
      },
      "source": [
        "To generate $ N $ identical layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIptwAwCj7wB"
      },
      "source": [
        "import copy\n",
        "\n",
        "def clones(module, N):\n",
        "  return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCpFzMs6Z6yr"
      },
      "source": [
        "A class to represent Multi-Head Attention:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGabuvuHebXG"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  \n",
        "  def __init__(self, h, d_model, dropout=0.1):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    assert d_model % h == 0\n",
        "    # To assume d_v always equals d_k\n",
        "    self.d_k = d_model // h\n",
        "    self.h = h\n",
        "    self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "    self.attn = None\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "\n",
        "  def forward(self, query, key, value, mask=None):\n",
        "    if mask is not None:\n",
        "      # Same mask applied to all h heads.\n",
        "      mask = mask.unsqueeze(1)\n",
        "    nbatches = query.size(0)\n",
        "\n",
        "    # 1) Do all the linear projections in batch from d_model => h x d_k\n",
        "    query, key, value = \\\n",
        "      [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "      for l, x in zip(self.linears, (query, key, value))]\n",
        "\n",
        "    # 2) Apply attention on all the projected vectors in batch.\n",
        "    att_out, self.attn = sdp_attention(query, key, value, mask=mask, \n",
        "                                       dropout=self.dropout)\n",
        "\n",
        "    # 3) \"Concat\" using a view and apply a final linear.\n",
        "    concat_out = att_out.transpose(1, 2).contiguous().view(nbatches, -1, \n",
        "                                                           self.h * self.d_k)\n",
        "\n",
        "    # 4) Last linear\n",
        "    return query, key, value, att_out, concat_out, self.linears[-1](concat_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbId20t_aBu4"
      },
      "source": [
        "We can see how the tensor is divided into the $ h $ heads and then contactenated to recover its original shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se0tXhR_fCks",
        "outputId": "8b55b12d-3723-4f9d-decb-dd5dcb72e308"
      },
      "source": [
        "#@title  { vertical-output: true }\n",
        "#@markdown Attention blocks\n",
        "h =  8#@param {type:\"integer\"}\n",
        "\n",
        "# get previous output as input\n",
        "input = enc_out\n",
        "\n",
        "multi = MultiHeadAttention(h , d_model)\n",
        "q, k, v, att, concat, output = multi(input, input, input)\n",
        "\n",
        "print('Input with dimension: (m x n)')\n",
        "print(tuple(input.shape), '\\n')\n",
        "\n",
        "print('Query, keys and values with dimension: (m x h x n x d_k)')\n",
        "print(tuple(q.shape), '\\n')\n",
        "\n",
        "print('Output with dimension: (m x n x d_model)')\n",
        "print(tuple(output.shape), '\\n')\n",
        "\n",
        "for w, layer in zip(['W_Q', 'W_K', 'W_V', 'W_O'], multi.linears): \n",
        "  print(f'{w} with dimension: {tuple(layer.weight.shape)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input with dimension: (m x n)\n",
            "(5, 10, 512) \n",
            "\n",
            "Query, keys and values with dimension: (m x h x n x d_k)\n",
            "(5, 8, 10, 64) \n",
            "\n",
            "Output with dimension: (m x n x d_model)\n",
            "(5, 10, 512) \n",
            "\n",
            "W_Q with dimension: (512, 512)\n",
            "W_K with dimension: (512, 512)\n",
            "W_V with dimension: (512, 512)\n",
            "W_O with dimension: (512, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyScS4mWaIGG"
      },
      "source": [
        "### 3.3.2 - Feed-Forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leKQ5Bk1M6fW"
      },
      "source": [
        "Each layer contains a fully connected feed-forward network. It is used different parameters between blocks.\n",
        "\n",
        "\\begin{equation}\n",
        "  \\text{FFN}(x) = \\text{max}(0,\\ xW_1 \\ + \\ b_1)W_2 \\ + \\ b_2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAS0XzeuaNSt"
      },
      "source": [
        "> In the original paper the input and output have dimensionality $ d_{model} = 512 $ and the inner-layer $ d_{ff} = 2048 $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMlushNuv3BV"
      },
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "\n",
        "  def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "    super(PositionwiseFeedForward, self).__init__()\n",
        "    self.w_1 = nn.Linear(d_model, d_ff)\n",
        "    self.w_2 = nn.Linear(d_ff, d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.w_2(self.dropout(F.relu(self.w_1(x))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98jLXRaxnDJv"
      },
      "source": [
        "### 3.3.3 Add & Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rgP8tPIVuS7"
      },
      "source": [
        "This layer corresponds to a [residual connection](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html) followed by [layer normalization](https://arxiv.org/abs/1607.06450) in both sub-layers. The goal of a residual connection is easing the training, with layers learning functions with reference to the layer inputs, instead of learning unreferenced ones. The layer normalization is a normalization which is applied per feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PEU842En4eM"
      },
      "source": [
        "![Layer Normalization](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/layer_norm.png)\n",
        "\n",
        "> Layer Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDoWEwSxtlCi"
      },
      "source": [
        "Then, the output of each sub-layer is:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{LayerNorm}(x \\ + \\ \\text{Sublayer}(x))\n",
        "\\end{equation}\n",
        "\n",
        "where $ \\text{Sublayer}(x) $ is the function implemented by the corresponding sub-layer. \n",
        "\n",
        "In order to reduce overfitting, it is applied dropout to the output of each sub-layer, before it is added to the sub-layer input and normalized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWCRO3n8w6GK"
      },
      "source": [
        "class LayerNorm(nn.Module):\n",
        "\n",
        "  def __init__(self, features, eps=1e-6):\n",
        "    super(LayerNorm, self).__init__()\n",
        "    self.a_2 = nn.Parameter(torch.ones(features))\n",
        "    self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "    self.eps = eps\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(-1, keepdim=True)\n",
        "    std = x.std(-1, keepdim=True)\n",
        "    return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0riUa70aU8b"
      },
      "source": [
        "To show normalization process in a layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsnnp7boyMI5",
        "outputId": "6796249e-9f76-4a8a-adf8-133093243e59"
      },
      "source": [
        "#@title { vertical-output: true }\n",
        "#@markdown This variable would correspond with d_model in the Transformer\n",
        "features = 5 #@param {type:\"integer\"}\n",
        "rows = 2 #@param {type:\"integer\"}\n",
        "\n",
        "batch_norm = batch_gen(5, rows, features)\n",
        "input = batch_norm.src.float()\n",
        "print('Input')\n",
        "print(input.detach().numpy(), '\\n')\n",
        "\n",
        "output = LayerNorm(features)(input)\n",
        "print('Output')\n",
        "print(output.detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input\n",
            "[[1. 3. 4. 1. 1.]\n",
            " [1. 3. 1. 1. 3.]] \n",
            "\n",
            "Output\n",
            "[[-0.7071063  0.7071063  1.4142126 -0.7071063 -0.7071063]\n",
            " [-0.730296   1.0954442 -0.730296  -0.730296   1.0954442]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il6ellS9aas_"
      },
      "source": [
        "Class to represent Sublayer Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klJw2QYEw8js"
      },
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "  \"\"\"A residual connection followed by a layer norm.\n",
        "  Note for code simplicity the norm is first as opposed to last\n",
        "  \n",
        "  \"\"\"\n",
        "  def __init__(self, size, dropout):\n",
        "    super(SublayerConnection, self).__init__()\n",
        "    self.norm = LayerNorm(size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, sublayer):\n",
        "    \"\"\"Apply residual connection to any sublayer with the same size\n",
        "\n",
        "    \"\"\"\n",
        "    return x + self.dropout(sublayer(self.norm(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aofgg0qifWRd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB-x7Ye92U_A"
      },
      "source": [
        "Now that all layers are explained, we can implement the whole encoder. First, it is defined the class for an instance in the stack."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHgrd2822bir"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "  def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    self.self_attn = self_attn\n",
        "    self.feed_forward = feed_forward\n",
        "    self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "    self.size = size\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "    return self.sublayer[1](x, self.feed_forward)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9_hBtxp3Rhm"
      },
      "source": [
        "And the whole class for the encoder\n",
        "\n",
        "> In the original paper they used a stack of $ N=6 $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF0BUBYQ3UhK"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \n",
        "  def __init__(self, layer, N):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.layers = clones(layer, N)\n",
        "    self.norm = LayerNorm(layer.size)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    for layer in self.layers: \n",
        "      x = layer(x, mask)\n",
        "    return self.norm(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7qGfrVEaoXA"
      },
      "source": [
        "To show encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3fL2fnkMQKl",
        "outputId": "761093cd-522a-4a03-dc83-68e2ff169c07"
      },
      "source": [
        "#@title \n",
        "#@markdown Attention blocks\n",
        "h =  8#@param {type:\"integer\"}\n",
        "#@markdown Embedding dimension\n",
        "d_model = 512 #@param {type:\"integer\"}\n",
        "#@markdown Dimension inner layer\n",
        "d_ff = 2048 #@param {type:\"integer\"}\n",
        "#@markdown Dropout\n",
        "dropout = 0.1 #@param {type:\"number\"}\n",
        "#@markdown Encoder blocks\n",
        "N = 6 #@param {type:\"integer\"}\n",
        "\n",
        "c = copy.deepcopy\n",
        "attn = MultiHeadAttention(h, d_model)\n",
        "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "enc_block = EncoderLayer(d_model, c(attn), c(ff), dropout)\n",
        "encoder = Encoder(enc_block, N)\n",
        "\n",
        "print(f'One encoder block, there are {N} like this\\n')\n",
        "print(encoder.layers[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One encoder block, there are 6 like this\n",
            "\n",
            "EncoderLayer(\n",
            "  (self_attn): MultiHeadAttention(\n",
            "    (linears): ModuleList(\n",
            "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (feed_forward): PositionwiseFeedForward(\n",
            "    (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "    (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (sublayer): ModuleList(\n",
            "    (0): SublayerConnection(\n",
            "      (norm): LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): SublayerConnection(\n",
            "      (norm): LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6apm_esRlPP"
      },
      "source": [
        "## 3.4 - Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5WY0_QqyvBF"
      },
      "source": [
        "It is also composed of a stack of $ N $ decoder blocks. Using the output from the encoder its function is also mapping sets to sets, maintaning the shape: number of vectors $ m $ and length $ n $. However, the dimensionality in the number of words differs one position from the encoder, being the size: $ ( m \\ x \\ n-1 \\ x \\ d_{model} ) $. In the original implementation, they employ $ N=6 $ decoders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivW20glBbTXN"
      },
      "source": [
        "![Transformer's decoder](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/decoder.png)\n",
        "\n",
        "> Decoder architecture. Modified image from [Attention is All You Need](https://arxiv.org/abs/1706.03762)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XLa9Wa8U7Wj"
      },
      "source": [
        "The architecture is almost equal to the encoder. Appart from the dimension, there are other two differences:\n",
        "\n",
        "-   The mask for the first multi-attention.\n",
        "-   The encoder's output used as input in the second multi-attention.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Ocr6ZOa_fk"
      },
      "source": [
        "### 3.4.1 - Masked Multi-Head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XutrVAx7Vk_H"
      },
      "source": [
        "The use of a mask is already implemented in the self-attention function and in the generation of a batch. This prevents attending to subsequent positions and ensures that the predictions only depend on known outputs previous to the current one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzScbuiZbYh6"
      },
      "source": [
        "![Masked self-attention](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/masked_attn.png)\n",
        "\n",
        "> Self-attention intuition in encoder and decoder. Image from [Transformer video](https://www.youtube.com/watch?v=TQQlZhbC5ps&list=PLTl9hO2Oobd_bzXUpzKMKA3liq2kj6LfE) by CodeEmporium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZgY-1yCaphw",
        "outputId": "f056d2eb-275c-4172-8476-132fb24a8c5a"
      },
      "source": [
        "enc_mask = batch.src_mask.detach().numpy()\n",
        "dec_mask = batch.trg_mask[0].detach().numpy()\n",
        "\n",
        "print('No mask used in encoder\\n')\n",
        "print(enc_mask, '\\n\\n')\n",
        "\n",
        "print('Mask used in decoder\\n')\n",
        "print(dec_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No mask used in encoder\n",
            "\n",
            "[[[ True  True  True  True  True  True  True  True  True  True]]\n",
            "\n",
            " [[ True  True  True  True  True  True  True  True  True  True]]\n",
            "\n",
            " [[ True  True  True  True  True  True  True  True  True  True]]\n",
            "\n",
            " [[ True  True  True  True  True  True  True  True  True  True]]\n",
            "\n",
            " [[ True  True  True  True  True  True  True  True  True  True]]] \n",
            "\n",
            "\n",
            "Mask used in decoder\n",
            "\n",
            "[[ True False False False False False False False False]\n",
            " [ True  True False False False False False False False]\n",
            " [ True  True  True False False False False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvvlsaTyb7BS"
      },
      "source": [
        "### 3.4.2 - Encoder-Decoder Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFncrjt8eTiR"
      },
      "source": [
        "The second sublayer in the decoder is a multi-head attention, without mask in this case, but using the encoder's output as input in the block.\n",
        "\n",
        "\\begin{matrix}\n",
        "  \\text{Query} & \\rightarrow & Q^D  & \\text{from decoder's input embedding} \\\\\n",
        "  \\text{Keys} & \\rightarrow & K^E & \\text{from encoder's output} \\\\\n",
        "  \\text{Values} & \\rightarrow & V^E & \\text{from encoder's output}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8E3Qhk1h22R"
      },
      "source": [
        "Once these two differences are explained, it can be implemented the decoder's blocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVuMeBPJh-tN"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "  def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "    self.size = size\n",
        "    self.self_attn = self_attn\n",
        "    self.src_attn = src_attn\n",
        "    self.feed_forward = feed_forward\n",
        "    self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "  def forward(self, x, memory, src_mask, tgt_mask):\n",
        "    \n",
        "    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "    x = self.sublayer[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
        "    return self.sublayer[2](x, self.feed_forward)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNn7e0ZiiK1G"
      },
      "source": [
        "And the complete decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8l37wzGiMPw"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self, layer, N):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.layers = clones(layer, N)\n",
        "    self.norm = LayerNorm(layer.size)\n",
        "\n",
        "  def forward(self, x, memory, src_mask, tgt_mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, memory, src_mask, tgt_mask)\n",
        "    return self.norm(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCnMNMjUcBQo"
      },
      "source": [
        "To show decoder architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8cZH1NvB2Ml",
        "outputId": "e5e68fa5-6636-4e59-bb8a-615faa42a391"
      },
      "source": [
        "#@title \n",
        "#@markdown Attention blocks\n",
        "h =  8#@param {type:\"integer\"}\n",
        "#@markdown Embedding dimension\n",
        "d_model = 512 #@param {type:\"integer\"}\n",
        "#@markdown Dimension inner layer\n",
        "d_ff = 2048 #@param {type:\"integer\"}\n",
        "#@markdown Dropout\n",
        "dropout = 0.1 #@param {type:\"number\"}\n",
        "#@markdown Encoder blocks\n",
        "N = 6 #@param {type:\"integer\"}\n",
        "\n",
        "c = copy.deepcopy\n",
        "attn = MultiHeadAttention(h, d_model)\n",
        "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "dec_block = DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout)\n",
        "decoder = Decoder(dec_block, N)\n",
        "\n",
        "print(f'One decoder block, there are {N} like this\\n')\n",
        "print(decoder.layers[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One decoder block, there are 6 like this\n",
            "\n",
            "DecoderLayer(\n",
            "  (self_attn): MultiHeadAttention(\n",
            "    (linears): ModuleList(\n",
            "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (src_attn): MultiHeadAttention(\n",
            "    (linears): ModuleList(\n",
            "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (feed_forward): PositionwiseFeedForward(\n",
            "    (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "    (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (sublayer): ModuleList(\n",
            "    (0): SublayerConnection(\n",
            "      (norm): LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): SublayerConnection(\n",
            "      (norm): LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): SublayerConnection(\n",
            "      (norm): LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxEz0m8hW9y2"
      },
      "source": [
        "## 3.5 - Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBFIP1RX2KwQ"
      },
      "source": [
        "The final block is a combination of a feed-forward network and a softmax in order to get probabilities for next word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_qOaBC1cK13"
      },
      "source": [
        "![Transformer's generator](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/generator.png)\n",
        "\n",
        "> Final module, generator. Modified image from [Attention is All You Need](https://arxiv.org/abs/1706.03762)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1XNpbMhBHh6"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "   \n",
        "  def __init__(self, d_model, vocab):\n",
        "    super(Generator, self).__init__()\n",
        "    self.proj = nn.Linear(d_model, vocab)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyjjFoHV4Z9H"
      },
      "source": [
        "## 3.6 - Final Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-Csm3wmI6Vm"
      },
      "source": [
        "Finally, we can implement the whole transformer architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6pCQJOKDOpR"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "    super(EncoderDecoder, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embed\n",
        "    self.tgt_embed = tgt_embed\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "    return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
        "\n",
        "  def encode(self, src, src_mask):\n",
        "    return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "  def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypAq7A13cUIm"
      },
      "source": [
        "Function to get a transforme by just setting the parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbLhOCWTchCh"
      },
      "source": [
        "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadAttention(h, d_model)\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "    model = EncoderDecoder(\n",
        "            Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "            Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
        "            nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
        "            nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
        "            Generator(d_model, tgt_vocab))\n",
        "\n",
        "    # This was important from their code.\n",
        "    # Initialize parameters with Glorot / fan_avg.\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9Zt7OVFcq6e"
      },
      "source": [
        "Set the Transformer parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKdpBa-aFIR_"
      },
      "source": [
        "#@markdown Size of source vocabulary\n",
        "src_vocab = 11#@param {type:\"integer\"}\n",
        "#@markdown Size of target vocabulary\n",
        "tgt_vocab = 11#@param {type:\"integer\"}\n",
        "#@markdown Number of encoder and decoder blocks\n",
        "N = 6#@param {type:\"integer\"}\n",
        "#@markdown Inner Transformer size\n",
        "d_model = 512#@param {type:\"integer\"}\n",
        "#@markdown Hidden feed forward size\n",
        "d_ff = 2048#@param {type:\"integer\"}\n",
        "#@markdown Number of attention heads\n",
        "h = 8#@param {type:\"integer\"}\n",
        "#@markdown Dropout probability\n",
        "dropout = 0.1#@param {type:\"number\"}\n",
        "\n",
        "model = make_model(src_vocab, tgt_vocab, N, d_model, d_ff, h, dropout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH-9hBJudSnF"
      },
      "source": [
        "To visualize the whole architecture or per block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf9xw--dFRnk",
        "outputId": "32de52bc-d5e8-4a7c-bb0f-f7639a1bbf56"
      },
      "source": [
        "#@markdown Select a block in the Transformer to visualize it\n",
        "block = \"transformer\" #@param [\"transformer\", \"encoder\", \"decoder\", \"src_embed\", \"tgt_embed\", \"generator\"]\n",
        "\n",
        "if block == 'transformer':\n",
        "    print(model)\n",
        "else:\n",
        "    print(getattr(model, block))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EncoderDecoder(\n",
            "  (encoder): Encoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (4): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (4): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm()\n",
            "  )\n",
            "  (src_embed): Sequential(\n",
            "    (0): Embeddings(\n",
            "      (lut): Embedding(11, 512)\n",
            "    )\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (tgt_embed): Sequential(\n",
            "    (0): Embeddings(\n",
            "      (lut): Embedding(11, 512)\n",
            "    )\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Generator(\n",
            "    (proj): Linear(in_features=512, out_features=11, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcmcatefeCb3"
      },
      "source": [
        "# 4 - BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KexD7CXsOLxz"
      },
      "source": [
        "**B**idirectional **E**ncoder **R**epresentations from **T**ransformer, released in 2019 in paper [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805), obtaining new state-of-the-art results on eleven NLP tasks. \n",
        "\n",
        "BERT was designed to pretrain deep bidirecional representations from unlabeled text by using self-attention to get the left and right context. This pretrained model can be fine-tuned adding one output layer and used for a wide range of NLP tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGrb8nPpeHz6"
      },
      "source": [
        "> The original model developed in TensorFlow is in [github.com/google-research/bert](https://github.com/google-research/bert), but it is going to be used the libray of [HuggingFace](https://huggingface.co/transformers/index.html) to show the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnUkCtDSRYPs",
        "outputId": "cea0eaec-964b-4cca-ba05-d83b124bdb09"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 6.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 38.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 57.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Qe3tZVePqX"
      },
      "source": [
        "## 4.1 - Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR6BHy1eOAez"
      },
      "source": [
        "It is a multi-layer bidirectional Transformer encoder, based on [Attention is All You Need](https://arxiv.org/abs/1706.03762) and implemented as [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html). The different hyperparameters and the original notation are:\n",
        "\n",
        "\n",
        "\n",
        "*   Number of layers: $ L $, number of encoder blocks which compose the whole stack. Previously defined as $ N $ in the Encoder part.\n",
        "\n",
        "*   Hidden size: $ H $, embedding dimension of the model. Previously deined as $ d_{model} $.\n",
        "\n",
        "*   Self-attention heads: $ A $, number of heads in self-attention blocks. Previously defined as $ h $.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXQPhg66eVM5"
      },
      "source": [
        "There are defined two model sizes: \n",
        "\n",
        "\\begin{matrix}\n",
        "  \\text{BERT}_{\\text{BASE}} & \\rightarrow & L=12, \\ H=768, \\ A=12 & \\text{Total parameters}:\\ 110\\text{M} \\\\\n",
        "  \\text{BERT}_{\\text{LARGE}} & \\rightarrow & L=24, \\ H=1024, \\ A=16 & \\text{Total parameters}:\\ 340\\text{M}\n",
        "\\end{matrix}\n",
        "\n",
        "In both cases the inner layer for the last feed-forward block is defined as $ 4H $, being in the BASE 3072 and in the LARGE 4096."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EBnC4w7eYxG"
      },
      "source": [
        "BERT has been already trained, so we can easily instantiate one of the base model classes of the [HuggingFace](https://huggingface.co/transformers/index.html) library from a pretrained model. To load the required model is used the class [`BertModel`](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel).\n",
        "\n",
        "> [HuggingFace](https://huggingface.co/transformers/index.html) has the the possibility to differentiate between *cased* and *uncased* models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt7Oq3-r3PmA"
      },
      "source": [
        "from transformers import BertModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "0f1502687ebd4b54ab04f5ffd19217aa",
            "bee040519a9f41098bef35c2a60a1465",
            "45990e9736824aeb986c06acc81a2965",
            "f6deb2fe8240481d9d5bfd1b44e783f1",
            "985b9b33df73463a8c71522efda6d6a0",
            "c2c61aa06ce94964be1379da1ec22121",
            "d2e188df132a471ebdc9dce413cfc498",
            "d6e8641592ec4564b8e3778035210bd2",
            "5f6c0d79e98a4e9e8293c85e1b8e4f50",
            "0fd4e2e2fa994cc78c79f27062067e77",
            "d8171dc4159a4bf3b003ad47ebac4764",
            "26277e5b42004678bbaaf580363edf2c",
            "8e7d35680455433e855651b091793cca",
            "2a0f163d2a45401798ef64e14cf4fc6c",
            "2762151775a148aea97b73eb74495c4f",
            "5b6b827a504c4f2b889f32dfcd36fa6d"
          ]
        },
        "id": "yp0Vn4p1R4EH",
        "outputId": "83bc0ec7-1daf-4c56-cd4f-358ad6340148"
      },
      "source": [
        "#@markdown Select one configuration\n",
        "model_name = \"bert-base-uncased\" #@param [\"bert-base-uncased\", \"bert-base-cased\", \"bert-large-uncased\", \"bert-large-cased\"]\n",
        "# We need to create the model and tokenizer\n",
        "model = BertModel.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f1502687ebd4b54ab04f5ffd19217aa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f6c0d79e98a4e9e8293c85e1b8e4f50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1qpQYvHS8Rj"
      },
      "source": [
        "The warning is telling us we are throwing away some weights and randomly initializing some other. That is because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do in next sections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvyTaI6sh-oB",
        "outputId": "c04f2029-d65c-4a5a-d39e-cd7f9e3ec949"
      },
      "source": [
        "#@markdown Select whole model or a block to visualize it\n",
        "block = \"bert\" #@param [\"bert\", \"embeddings\", \"encoder\", \"pooler\"]\n",
        "if block == 'bert':\n",
        "    print(model)\n",
        "else:\n",
        "    print(getattr(model, block))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F7MxCNyfPeo"
      },
      "source": [
        "### 4.1.1 - Input-Output Representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xsn3fTeGbFdL"
      },
      "source": [
        "In order to handle a variety of tasks, the input can be a single sentence or a pair of sentences in one token sequence, which is certainly the name given to the input. The input representation of a word is the addition of three different embeddings:\n",
        "\n",
        "*   **Token Embedding**: normal word embedding. It is used WordPiece with a 30.000 token vocabulary.\n",
        "\n",
        "*   **Segment Embedding**: to differentiate the sentence the word belongs to. It is used the special token $ [SEP] $ to separate both sentences. \n",
        "\n",
        "*   **Position Embedding**: to indicate the position in the whole sequence.\n",
        "\n",
        "The first token is always a special classification token $ [CLS] $, whose final hidden state layer is used in classification tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hBoDdzBAIvD"
      },
      "source": [
        "![BERT's input](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/in_BERT.png)\n",
        "\n",
        "> Input Embedding. Image from [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSmOADeOfOiY",
        "outputId": "e583b110-72e7-4d5d-d74c-4962688233db"
      },
      "source": [
        "print(model.embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertEmbeddings(\n",
            "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "  (position_embeddings): Embedding(512, 768)\n",
            "  (token_type_embeddings): Embedding(2, 768)\n",
            "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGc2QVvs6vDl"
      },
      "source": [
        "As output we get the corresponding sequence embedding, as it is explained in the encoder, and *NSP* for classification. These values are going to be explained better in *Pre-Training* section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g6fHh4mfHXX"
      },
      "source": [
        "## 4.2 - Pre-training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2M14_bCgkfM"
      },
      "source": [
        "This step is in charge of the model to understand the language and its context. It is used two unsupervised tasks instead of the traditional left-to-right or right-to-left."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3AH5O6uALAE"
      },
      "source": [
        "![Pre-training BERT](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/pretrain_BERT.png)\n",
        "\n",
        "> Pre-training process in BERT. Image from [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zmfGdJHfFC1"
      },
      "source": [
        "### 4.2.1 - Masked Language Model (MLM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swuvqUT5jALw"
      },
      "source": [
        "Some tokens are masked at random and then predicted. The final $ T_i $ vectors have the sime size and are generated simultaneously. They are fed into an output softmax over the vocabulary (30k) to get a distribution and compare with cross entropy loss in order to train the model.\n",
        "\n",
        "However, as the output have all the worlds, included the ones were not masked, it is only considered the ones were masked and ignores the others to calculate the cross entropy loss. This ensures more focus into predict the masked values and increases the context awareness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkGOlDsqpShP"
      },
      "source": [
        "![MLM](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/cross_entro_BERT.png)\n",
        "\n",
        "> Prediction of masked word in BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0QIZVHpfbJA"
      },
      "source": [
        "### 4.2.2 - Next Sentence Prediction (NSP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuQTTjvOjdp8"
      },
      "source": [
        "Many important tasks as question and answering are based on understanding relationship between two sentences, which is not captured by language modeling. For that reason, while the model is being trained in MLM, is also trained in next sentence prediction.\n",
        "\n",
        "For this purpose it is used the special token $ [CLS] $ in the input and $ C $ in the output to indicate if *Sentence B* could follow *Sentence A*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul_LRGnUpb-j"
      },
      "source": [
        "![Pre-train BERT](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/pretrain_BERT_methods.png)\n",
        "\n",
        "> MLM and NSP in pre-training BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qEQi_BDffW1"
      },
      "source": [
        "### 4.2.3 - Self-Attention Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm8NzovuqEqC"
      },
      "source": [
        "As it has been mentioned, the model contains $ L $ blocks and $ A $ attention heads. Many models which come from BERT acquired the encoder to perform self-attention. Self-attention operations are not straightforward, even further if we have different blocks and many heads into them.\n",
        "\n",
        "To get an intuition for BERT (and other similar models) respect the attention weights between the elements, we can use [exBERT](https://huggingface.co/exbert/?model=bert-base-cased&modelKind=bidirectional&sentence=This%20model%20has%20revolutionized%20the%20world!&layer=0&heads=..0,1,2,3,4,5,6,7,8,9,10,11&threshold=0.7&tokenInd=null&tokenSide=null&maskInds=..&hideClsSep=true). Following next steps:\n",
        "\n",
        "1. First we select a model and introduce the input sentence.\n",
        "2. We can choose if hide special tokens and the percentage of attention shown.\n",
        "3. We select an encoder block (as *Layer*).\n",
        "4. Lastly the attention heads we want to visualize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyG_JpNiG299"
      },
      "source": [
        "![exBERT](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/exbert.png)\n",
        "\n",
        "> Example of [exBERT](https://huggingface.co/exbert/?model=bert-base-cased&modelKind=bidirectional&sentence=This%20model%20has%20revolutionized%20the%20world!&layer=0&heads=..0,1,2,3,4,5,6,7,8,9,10,11&threshold=0.7&tokenInd=null&tokenSide=null&maskInds=..&hideClsSep=true) visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9ky2Sp-N5Ut"
      },
      "source": [
        "## 4.3 - Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DJIu80m4QdU"
      },
      "source": [
        "Thanks to self-attention, which is in charge of applying bidirectional cross attention between the two sentences, is straightforward to model many downstream tasks. In addition to, the two sentences as input in pretraining are equivalent to different trainings in NLP as sentence pairs in paraphrasing, hypothesis-premise pairs, question-passage pairs, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NwtnjUvpwFh"
      },
      "source": [
        "![Fine-tune BERT](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/finetune_examples.png)\n",
        "\n",
        "> Different NLP tasks implemented by fine-tuning BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dASIeoBig8mC"
      },
      "source": [
        "The output token representations are fed into an output layer and the $ C $ is fed into an output layer for classification. Only new parameters are learned from sratch, while the rest are slightly fine-tuned. \n",
        "\n",
        "That is the reason fine-tune is relatively inexpensive in computation cost compared with pretraining. In the original paper, authors claim that all of the results can be replicated in at most 1 hour on a single Cloud TPU, or a few hours on a GPU, starting from the exact same pre-trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRQ7TcbAp9Nl"
      },
      "source": [
        "![Fine-tune BERT details](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/finetune_BERT_details.png)\n",
        "\n",
        "> Output layer added in fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhsnqD1UKfE4"
      },
      "source": [
        "# 5 - Sentiment Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISgoHueqCeEg"
      },
      "source": [
        "A tradiditonal task in NLP is **Sentiment Analysis**. The target is to determine if the sentence has a *positive* or *negative* sentiment, corresponding with a binary classification problem. As it is normal, these two labels depend on the context of our text. In spite of being one of the most simple applications, it is really useful and currently demanded in many applications, for example in films or series reviews.\n",
        "\n",
        "In addition to be a standard assignment, it compounds one of the task of [GLUE](https://gluebenchmark.com/) (General Language Understanding Evaluation), a group of nine classification tasks on sentences or pairs of sentences, which is commonly used to evaluate state-of-the-art models. Sentiment analysis corresponds with [SST-2](https://nlp.stanford.edu/sentiment/index.html) (Stanford Sentiment Treebank)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEm7PX1G3luN"
      },
      "source": [
        "![Sentiment Analysis](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/sentiment_analysis.PNG)\n",
        "\n",
        "> Example of sentiment analysis in one of the [Hugging Face's models](https://huggingface.co/models)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7sSjqazGNDT"
      },
      "source": [
        "> For this task, two tutorials [Fine tuning BERT for Sentiment Analysis](https://skimai.com/fine-tuning-bert-for-sentiment-analysis/) and [BERT Fine-Tuning Tutorial with PyTorch](http://mccormickml.com/2019/07/22/BERT-fine-tuning/), have been used as guide and support to the development of the application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C72t07tkgGGf"
      },
      "source": [
        "## 5.1 - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sy2wgHzAwRJ"
      },
      "source": [
        "In spite of being much faster than pre-training, fine-tune a BERT model for any class could be slow for a CPU. Due to that, we are going to try using a GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYpkzpTFBEIY"
      },
      "source": [
        "> In case of running it from Colab, we could make use of Google's GPUs. Make sure to select GPU from *Runtime > Change runtime type > Hardware accelerator > GPU*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_x4k_DmO5M8",
        "outputId": "8fec9ab5-e00c-451e-cdf2-c196f2f3546e"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcAwK4YSYAtO"
      },
      "source": [
        "def info_device():\n",
        "    # If there's a GPU available\n",
        "    if torch.cuda.is_available():\n",
        "        print(f'\\nUsing GPU {torch.cuda.get_device_name(0)}.', '\\n')\n",
        "    # If not\n",
        "    else:\n",
        "        print('\\nNo GPU available, using the CPU instead.', '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWOX4s-agL1m"
      },
      "source": [
        "## 5.2 - Load SST-2 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSzeqGUCIPCh"
      },
      "source": [
        "First of all we need to download the dataset. We’ll use the `wget` package to download the dataset to the Colab instance’s file system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_EKeJwIMOjb",
        "outputId": "4ce1b419-355e-4a20-c7aa-755ac333d12a"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=d1fc06afaf733f98395f4a136a04865c519b7ab9b30f654ccb3969c3e623db78\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1QkRBVoI6G0"
      },
      "source": [
        "In this [repository](https://github.com/nyu-mll/GLUE-baselines) is explained how to manage GLUE datasets, altough in this case we only need the corresponding URL. We donwload the dataset and then unzip it to access it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ0uAJ2WNE1t",
        "outputId": "b63ca121-5c19-4d4e-f463-2733931a4f3e"
      },
      "source": [
        "import wget\n",
        "\n",
        "sentiment_dir = Path('sentiment_analysis')\n",
        "if not os.path.exists(sentiment_dir):\n",
        "    !mkdir $sentiment_dir\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://dl.fbaipublicfiles.com/glue/data/SST-2.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./SST-2.zip'):\n",
        "    print('Downloading dataset...')\n",
        "    wget.download(url, './SST-2.zip')\n",
        "\n",
        "# Unzip the dataset (if we haven't already)\n",
        "sst2_dataset = Path('sst-2_dataset')\n",
        "if not os.path.exists(sst2_dataset):\n",
        "    !unzip SST-2.zip\n",
        "    shutil.move('SST-2', sst2_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n",
            "Archive:  SST-2.zip\n",
            "   creating: SST-2/\n",
            "  inflating: SST-2/dev.tsv           \n",
            "   creating: SST-2/original/\n",
            "  inflating: SST-2/original/README.txt  \n",
            "  inflating: SST-2/original/SOStr.txt  \n",
            "  inflating: SST-2/original/STree.txt  \n",
            "  inflating: SST-2/original/datasetSentences.txt  \n",
            "  inflating: SST-2/original/datasetSplit.txt  \n",
            "  inflating: SST-2/original/dictionary.txt  \n",
            "  inflating: SST-2/original/original_rt_snippets.txt  \n",
            "  inflating: SST-2/original/sentiment_labels.txt  \n",
            "  inflating: SST-2/test.tsv          \n",
            "  inflating: SST-2/train.tsv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyXCF0E3fW8o"
      },
      "source": [
        "There are three different datasets: *train.csv*, *test.csv*, *dev.csv*. As its own name indicates, they are used for training, testing and validate respectively, the studied model. As there is a [GLUE leaderboard](https://gluebenchmark.com/leaderboard), the test dataset is not labeled. In order to study the performance of our model, we are going to divide the train dataset, which has enough samples, into train and test. Test set is going to be one third of the original train test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMYvqVOQfIg8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df = pd.read_csv(sst2_dataset/'train.tsv', delimiter='\\t', header=1, names=['sentence', 'label'])\n",
        "val_df = pd.read_csv(sst2_dataset/'dev.tsv', delimiter='\\t', header=1, names=['sentence', 'label'])\n",
        "train_df, test_df = train_test_split(train_df, test_size=0.33, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaVAVVZgJPID"
      },
      "source": [
        "They are saved into a dictionay to allow an easy access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO9lvi3_T_oA"
      },
      "source": [
        "# Load the datasets into a pandas dataframe.\n",
        "original_datasets = {\n",
        "    'train':    train_df, \n",
        "    'val':      val_df, \n",
        "    'test':     test_df\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sUA4BM7LO3C"
      },
      "source": [
        "To get a fast intuition on the dataset, we can plot some used sentences for the three splits. Mention the label 1 corresponds with positive sentiment while label 0 with negative.\n",
        "\n",
        "\\begin{matrix}\n",
        "    \\text{Class 0} & \\rightarrow & \\text{Negative sentiment} \\\\\n",
        "    \\text{Class 1} & \\rightarrow & \\text{Positive sentiment}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "_1s1Y3T5RS-z",
        "outputId": "be7669cc-642c-4b72-ce23-80989cd94c88"
      },
      "source": [
        "#@markdown Select a split\n",
        "split = \"train\" #@param [\"train\", \"val\", \"test\"]\n",
        "\n",
        "#@markdown Select number of examples to visualize it\n",
        "num_examples = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "print(f'Some sentences of {split} split, which has a length of {len(original_datasets[split])}\\n')\n",
        "pd.set_option(\"max_colwidth\", 150)\n",
        "original_datasets[split].sample(num_examples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some sentences of train split, which has a length of 45123\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36265</th>\n",
              "      <td>possibly the best actor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29016</th>\n",
              "      <td>just lapses into unhidden british</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32615</th>\n",
              "      <td>has the right stuff for silly summer entertainment</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40913</th>\n",
              "      <td>what a reckless squandering of four fine acting talents</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59603</th>\n",
              "      <td>sly , sophisticated and surprising</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       sentence  label\n",
              "36265                                  possibly the best actor       1\n",
              "29016                        just lapses into unhidden british       0\n",
              "32615       has the right stuff for silly summer entertainment       1\n",
              "40913  what a reckless squandering of four fine acting talents       0\n",
              "59603                       sly , sophisticated and surprising       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o03dUBH1KxIp"
      },
      "source": [
        "Depending on the computation velocity, training process could be more or less slow. For a fast intuition on the model, we can remove some data, since the original size of the dataset has more than 60k samples only in training. With `perc` we select the percentage of data we are going to use. Removed sample are selected randomly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3d-eYHQgegp",
        "outputId": "0e25b624-b6b5-47f4-9c72-d133830af496"
      },
      "source": [
        "#@title 5.2.1 Resize dataset { vertical-output: true }\n",
        "#@markdown Percentage of dataset to use %\n",
        "perc = 100 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "datasets = {}\n",
        "\n",
        "for key, df in original_datasets.items():\n",
        "    new_df = df.sample(n=round(len(df)*(perc/100)), random_state=np.random.RandomState())\n",
        "    datasets[key] = new_df.reset_index(drop=True)\n",
        "    if perc != 100:\n",
        "        print(f'{key:<10}', f'From: {len(original_datasets[key]):<10}', f'To: {len(datasets[key]):<10}')\n",
        "    else:\n",
        "        print(f'{key:<10}', f'size: {len(original_datasets[key]):<10}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train      size: 45123     \n",
            "val        size: 871       \n",
            "test       size: 22225     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxgbVHrorSqy"
      },
      "source": [
        "It is important to know how many samples we have per class in our training dataset, in case we are dealing with an imbalanced classification problem. The number of samples is going to depend on how the original train datatset has been splitted to get the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chVHT0EOrcW3",
        "outputId": "e3f49937-2deb-4baf-fe99-98b7e35d550b"
      },
      "source": [
        "train_labels = datasets['train'].label\n",
        "\n",
        "# Print resulted samples\n",
        "print(f\"{'Total samples':^15} | {'Positive':^10} | {'Negative':^10}\")\n",
        "print(42*'-')\n",
        "print(f\"{len(train_labels):^15} | {len(train_labels[train_labels==1]):^10} | {len(train_labels[train_labels==0]):^10}\")\n",
        "print(42*'-')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Total samples  |  Positive  |  Negative \n",
            "------------------------------------------\n",
            "     45123      |   25248    |   19875   \n",
            "------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPwweniNgTvl"
      },
      "source": [
        "## 5.3 -  Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krEPtT0qTpQ9"
      },
      "source": [
        "Before input sequences into BERT, it is necessary to preprocess data. Depending on the model, there are more or less steps to do, but mainly the guide to follow is:\n",
        "\n",
        "*   Tokenize sequences. Convert text into integers according to embedding space used. There are many literature about tokenization algorithms.\n",
        "\n",
        "*   Pad each sentence to the maximum length there is in your batch.\n",
        "\n",
        "*   Truncate each sentence to the maximum length the model can accept (if applicable). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRbrb0iDqkZX"
      },
      "source": [
        "![Tokenization](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/tokenization.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjbGx7_xMfdH"
      },
      "source": [
        "Remember that BERT input follows next scheme\n",
        "\n",
        "\\begin{matrix}\n",
        "    \\text{[CLS]} & \\text{Sentence A} & \\text{[SEP]} & \\text{Sentence B} & \\text{[SEP]}\n",
        "\\end{matrix}\n",
        "\n",
        "or\n",
        "\n",
        "\\begin{matrix}\n",
        "    \\text{[CLS]} & \\text{Sentence} & \\text{[SEP]}\n",
        "\\end{matrix} \\\\\n",
        "\n",
        "depending on the final task. Our case, classification of one sentence, corresponds with second option.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSdChhNAOfLC"
      },
      "source": [
        "In order to preprocess according to the model, it is going to be used the [`BertTokenizer`](https://huggingface.co/transformers/model_doc/bert.html?highlight=berttokenizer#transformers.BertTokenizer) from Hugging Face which ensures that we get a tokenizer that corresponds to the model architecture we want to use. Besides that, it downloads the vocabulary used when pretraining this specific checkpoint.\n",
        "\n",
        "\n",
        "It is necessary to pass to the tokenizer the name of the pre-trained model we are going to use. For this task the selected one is [`bert-base-uncased`](https://huggingface.co/bert-base-uncased), a base BERT which does not distinguish between upper and lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "af14dda1b790437189dd7c0382935d2a",
            "0c4feec35de94e958ba374628c7054e7",
            "acaa213161414aeabbf241b61941e1a0",
            "bdea8d6ff88e40119c85853a54f35fb5",
            "fccbe30ef2684ca699ea28856cc5ed2f",
            "f511a1b0c9444bfb8cae31e5db352f79",
            "5b60500dc1d643128f907fa143ccacab",
            "81bc148563b7470f9196d8fbc47e6ed9",
            "506ca0e3c62a452cb3e2704b8b9bf8c3",
            "13ff9da6e10541aab9e9e9a704147cb1",
            "bbbf5459306e40ffabe640b1548f976b",
            "f1426195d8bc42338cc9610a1f437ca3",
            "abb68cbf86004239b71e993e64184478",
            "a198eb06b4b04b788e9ec59be37151a0",
            "8e47a75498d649a9a40d82d3b7796ee5",
            "3f2c59cd2bb5493ab7933ab53d3936a7",
            "440b9472437e49ebb9a9260530baa2b1",
            "8b9004dbe0dc488d86a533825c688595",
            "33bb89426b80409eb9cd732e82388ef8",
            "4be1c68778824de4a26be9165895de05",
            "6df2816983de43958b865bd7f7617cad",
            "b69aa86d8a364765842bd254012e9d12",
            "c22d5d233f25410f8b2b0ef98198210c",
            "fd709bd239914f939d7715d0521b15ec"
          ]
        },
        "id": "_QEvK9RzQdln",
        "outputId": "953d0ffc-4676-46f6-ee7f-29196e93bb2b"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "MODEL_NAME = 'bert-base-uncased'\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...\\n')\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af14dda1b790437189dd7c0382935d2a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "506ca0e3c62a452cb3e2704b8b9bf8c3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "440b9472437e49ebb9a9260530baa2b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esjs9IJyQ-mU"
      },
      "source": [
        "From this instance we can get many information about the model: \n",
        "\n",
        "- Dimension of the vocabulary used\n",
        "- Maximum allowed length of the model\n",
        "- In which size is applied padding\n",
        "- Special used tokens for separation token, padding token, classification token, mask token and other unknown tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbJCgRpQYODR",
        "outputId": "dba72292-09c1-415c-91ef-022d6b33d9d1"
      },
      "source": [
        "#@markdown Select an option to visualize it\n",
        "attribute = \"vocab_size\" #@param [\"vocab_size\", \"model_max_length\", \"padding_side\", \"sep_token\", \"pad_token\", \"cls_token\", \"mask_token\", \"unk_token\"]\n",
        "\n",
        "print(getattr(tokenizer, attribute))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1hLzeZHRJHb"
      },
      "source": [
        "BERT works with sentences of same dimension. Due to that, it is required to pad (add padding tokens until a specified size) or truncate (separate a sentence if it is longer than the maximum model length). For this reason it is very useful to know which is the maximum length in our sentences, and limit the input size to this value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLbnuF07maXq",
        "outputId": "8f1034ba-5bf1-450e-be5d-4daff6be9605"
      },
      "source": [
        "# Concatenate sentences in datasets\n",
        "all_sentences = np.concatenate([datasets['train'].sentence.values, \n",
        "                                datasets['val'].sentence.values, \n",
        "                                datasets['test'].sentence.values])\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_sentences = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_sentences]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_sentences])\n",
        "print(f'Max length: {max_len}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length: 66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re7NomrbSU4B"
      },
      "source": [
        "In addition to, we have to add the special tokens: [CLS] at the beginning of a sentence and [SEP] between them, altough in our case it will be only at the end of each one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqTTwCtTSwNw"
      },
      "source": [
        "In next function, we tokenize each sentence in addition to add special tokens and perform the required padding or truncating operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2uqvgtbrZSV"
      },
      "source": [
        "def preprocessing_for_sa(data, tokenizer, max_len=512):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            sent,                           # Tokenize sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=max_len,             # Max length to truncate/pad\n",
        "            padding='max_length',           # Pad sentence to max length\n",
        "            truncation=True,                # Truncate to max_length\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Get output and attention mask\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0oMD7QcTUH_"
      },
      "source": [
        "From this function we will get the corresponding token IDs as `input_ids`. Also, the second output `attention_masks`, indicates which tokens are useful and which ones are padding tokens. This requirement in the input is necessary for BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggrf-hV_3Qmr"
      },
      "source": [
        "encoded_datasets = dict.fromkeys(datasets)\n",
        "\n",
        "for split, df in datasets.items(): \n",
        "    encoded_datasets[split] = dict()\n",
        "    encoded_datasets[split]['input_ids'], encoded_datasets[split]['attention_mask'] = preprocessing_for_sa(df.sentence, tokenizer, max_len)\n",
        "    # Add the corresponding labels\n",
        "    encoded_datasets[split]['label'] = torch.tensor(df.label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS872sOtUW60"
      },
      "source": [
        "To get an intutiton about the whole process, we can print a random sentence as well as the corresponding token IDs and the result after tokenize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uMO0Akt4VSR",
        "outputId": "dae39e56-e3fc-47fd-8a49-aeb114d05c26"
      },
      "source": [
        "# Random index\n",
        "rnd_index = random.randint(0, len(datasets[split])-1)\n",
        "# Original sentence\n",
        "sentence = datasets[split].sentence[rnd_index]\n",
        "print('Original sentence:')\n",
        "print(sentence, '\\n')\n",
        "\n",
        "# IDs\n",
        "ids = encoded_datasets[split]['input_ids'][rnd_index]\n",
        "print('Token IDs:')\n",
        "print(ids.detach().numpy(), '\\n')\n",
        "\n",
        "# Token IDs\n",
        "#tokens = tokenizer.convert_ids_to_tokens(ids)\n",
        "print('After tokenization:')\n",
        "print(np.array(tokenizer.convert_ids_to_tokens(ids)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence:\n",
            "charming in comedies like american pie and  \n",
            "\n",
            "Token IDs:\n",
            "[  101 11951  1999 22092  2066  2137 11345  1998   102     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0] \n",
            "\n",
            "After tokenization:\n",
            "['[CLS]' 'charming' 'in' 'comedies' 'like' 'american' 'pie' 'and' '[SEP]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0qzQm6Ag2fG"
      },
      "source": [
        "We will create an iterator for our dataset using the torch [data loader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) class. This will help save on memory during training and boost the training speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmgor3yXeUsW"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "def generate_data_loaders(batch_size, test=False):\n",
        "    # Train and val dataloaders\n",
        "    if test is False:\n",
        "        dataloaders = list()\n",
        "        for dataset in (encoded_datasets['train'], \n",
        "                        encoded_datasets['val']):\n",
        "            \n",
        "            data = TensorDataset(dataset['input_ids'], \n",
        "                                dataset['attention_mask'], \n",
        "                                dataset['label'])\n",
        "            sampler = RandomSampler(data)\n",
        "            dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
        "            dataloaders.append(dataloader)\n",
        "        return tuple(dataloaders)\n",
        "\n",
        "    # Test dataloader\n",
        "    else:\n",
        "        dataset = encoded_datasets['test']\n",
        "        data = TensorDataset(dataset['input_ids'], \n",
        "                                dataset['attention_mask'], \n",
        "                                dataset['label'])\n",
        "        sampler = SequentialSampler(data)\n",
        "        return DataLoader(data, sampler=sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPQVNkKcgfQp"
      },
      "source": [
        "## 5.4 - Create the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jqdXV0CFsG4"
      },
      "source": [
        "To fine-tune on GLUE, new parameters introduced are classification layer weigths $ W \\in \\mathbb R^{K \\ x \\ H} $, where $ K $ is the number of labels. Then we compute a standard classification loss with $ C $ and $ W $:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{log}(\\text{softmax}(CW^T))\n",
        "\\end{equation}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUkyebe_q0cZ"
      },
      "source": [
        "![Fine tune sentiment analysis](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/sentiment_analysis_fine_tune.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhpgGfl9heot"
      },
      "source": [
        "In **Sentiment Analysis** task, the final model is just a combination of BERT's encoder and a classifier to get the final probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bV6gHgCqrRP"
      },
      "source": [
        "![BERT Classifier](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/bert-classifier.png)\n",
        "\n",
        "> Diagram of BERT Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUAMrvRQYa_a"
      },
      "source": [
        "Hugging Face provides [`BertForSequenceClassification`](https://huggingface.co/transformers/model_doc/bert.html?highlight=berttokenizer#bertforsequenceclassification) to perform this task. However, in order to show the simplicity of fine-tune process, we are going to create our own model. At the end, this is the combination of the pre-trained [`BertModel`](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel) and a classifier, composed by a simple feed-forward neural netword with only one hidden layer, plus a softmax to get the probabilities of each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujfnQXfrhwcB"
      },
      "source": [
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_classifier=50, dropout=0.1, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        H = in_classifier\n",
        "        D_in = self.bert.config.hidden_size\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "                nn.Linear(D_in, H),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(H, 2)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        # outputs[0] = last_hidden_state\n",
        "        # last_hidden_state dimension: (n_batches x words x inner_dim_BERT)\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1NLY5sbc097"
      },
      "source": [
        "Finally, we have to decide the classifier's parameters. In our case the number of neurons in the hidden layer of the neural network as `in_classifier` and a dropout probability as `dropout_classifier`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r__KXCK8-9jI",
        "outputId": "a5395abc-2a7c-48d8-c5db-b5b726f9e37b"
      },
      "source": [
        "#@markdown Size classifier layer\n",
        "in_classifier = 50 #@param {type:\"integer\"}\n",
        "#@markdown Classifier droput probability\n",
        "dropout_classifier = 0.01 #@param {type:\"number\"}\n",
        "model = BertClassifier(in_classifier, dropout_classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LVmrGBOeB15"
      },
      "source": [
        "With the model created, we can visualize each part: the whole model, only pretrained BERT or the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyXhITJRm0Pq",
        "outputId": "d9296cc4-ef4c-4ab7-d002-5a40b899c2cb"
      },
      "source": [
        "#@markdown Select whole model, only pretrained BERT or the classifier\n",
        "block = \"classifier\" #@param [\"model\", \"bert\", \"classifier\"]\n",
        "if block == 'model':\n",
        "    print(model)\n",
        "else:\n",
        "    print(getattr(model, block))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=768, out_features=50, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Dropout(p=0.01, inplace=False)\n",
            "  (3): Linear(in_features=50, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6iOXiN8-8gc"
      },
      "source": [
        "To fine-tune our Bert Classifier, we need to create an optimizer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "D4RYJWzH0wYH"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def init_model(train_dataloader,\n",
        "               in_classifier=50, dropout_classifier=0.1, \n",
        "               learning_rate=5e-5, epsilon=1e-8, \n",
        "               epochs=4):\n",
        "    # Model\n",
        "    bert_classifier = BertClassifier(in_classifier, dropout_classifier)\n",
        "    # Run model in device\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(\n",
        "        bert_classifier.parameters(),\n",
        "        lr=learning_rate,    \n",
        "        eps=epsilon    \n",
        "    )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beqNViLcz0es"
      },
      "source": [
        "## 5.5 - Fine-Tune on SST-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf1km6oGwsat"
      },
      "source": [
        "Before going into detail about how to fine-tune the model, a recap about binary classification problems. There are 4 possible combinations in a binary classification problem (predict a class between two possible ones).\n",
        "\n",
        "- **True Positive (TP)**: if both predicted and actual values are *Positive*.\n",
        "- **False Positive (FP)**: if predicted value is *Positive* and actual one is *Negative*.\n",
        "- **False Negative (FN)**: if predicted value is *Negative* and actual one is *Positive*.\n",
        "- **True Negative (NP)**: if both predicted and actual values are *Negative*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSiDusMqx_Nx"
      },
      "source": [
        "![Confussion matrix](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/conf_matrix.png)\n",
        "\n",
        "> Confusion matrix. Predicted vs. real values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOQkdtq70lGH"
      },
      "source": [
        "One method to measure the performance of the model is the **accuracy**. This is defined as the coefficient between the number of correct predictions and the total number of predictions. Then, with previous classification possibilities defined we have:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}} = \\frac{TP \\ + \\ TN}{TP \\ + \\ TN \\ + \\ FP \\ + \\ FN}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za8pBoDYzw5B"
      },
      "source": [
        "In addition to the accuracy, we use the [cross-entropy loss](https://machinelearningmastery.com/cross-entropy-for-machine-learning/). Each sample has a known class label with a probability of 1.0, and 0.0 for the other label. The model can estimate the probability of an example belonging to each class label. Cross-entropy can then be used to calculate the difference between the two probability distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo_Ew7bvz74W"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb7K4dyOestG"
      },
      "source": [
        "To train the model, as in other architectures, we are going to iterate through batches. At the end of each epoch the model is evaluated respect the validation dataset. We use a [fixed seed](https://machinelearningmastery.com/reproducible-results-neural-networks-keras/) for the random number generator to ensure the same result in two consecutive executions with same parameters, and do not let it to random initialization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq2h2osmcg-D"
      },
      "source": [
        "import datetime\n",
        "import time\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round(elapsed))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBwRZLp97bTB"
      },
      "source": [
        "class BertTrainer():\n",
        "\n",
        "    def __init__(self, params):\n",
        "        self.epochs = params['epochs']\n",
        "        self.train_dataloader, self.val_dataloader = generate_data_loaders(params['batch_size'])\n",
        "        self.training_stats = []\n",
        "        self.model, self.optimizer, self.scheduler = init_model(self.train_dataloader,\n",
        "                                                                params['in_classifier'], params['dropout'],\n",
        "                                                                params['learning_rate'], params['epsilon'],\n",
        "                                                                self.epochs)\n",
        "        \n",
        "    def set_seed(self, seed_value=42):\n",
        "        \"\"\"Set seed for reproducibility.\n",
        "        \"\"\"\n",
        "        random.seed(seed_value)\n",
        "        np.random.seed(seed_value)\n",
        "        torch.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "    def train(self, evaluation=True):\n",
        "        self.set_seed(42)\n",
        "        info_device()\n",
        "        for epoch_i in range(self.epochs):\n",
        "\n",
        "            # =======================================\n",
        "            #               Training\n",
        "            # =======================================\n",
        "            print(f'======== Epoch {epoch_i+1} / {epochs} ========\\n')\n",
        "\n",
        "            # Print the header of the result table\n",
        "            print(f'Training: {len(self.train_dataloader)} batches\\n')\n",
        "            print(f\"{'Batch':^7} | {'Train Loss':^12} | {'Elapsed':^9}\")\n",
        "            print(\"-\"*35)\n",
        "\n",
        "            # Measure the elapsed time of each epoch\n",
        "            training_time = 0\n",
        "            t0_batch = time.time()\n",
        "\n",
        "            # Reset tracking variables at the beginning of each epoch\n",
        "            total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "            # Put the model into the training mode\n",
        "            self.model.train()\n",
        "\n",
        "            # For each batch of training data...\n",
        "            for step, batch in enumerate(self.train_dataloader):\n",
        "\n",
        "                batch_counts +=1\n",
        "                # Load batch to device\n",
        "                b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "                # Zero out any previously calculated gradients\n",
        "                self.model.zero_grad()\n",
        "\n",
        "                # Perform a forward pass. This will return logits.\n",
        "                logits = self.model(b_input_ids, b_attn_mask)\n",
        "\n",
        "                # Compute loss and accumulate the loss values\n",
        "                loss = loss_fn(logits, b_labels)\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                # Perform a backward pass to calculate gradients\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "\n",
        "                # Update parameters and the learning rate\n",
        "                self.optimizer.step()\n",
        "                self.scheduler.step()\n",
        "\n",
        "                # Print the loss values and time elapsed for every 20 batches\n",
        "                if (step % 20 == 0 and step != 0) or (step == len(self.train_dataloader) - 1):\n",
        "                    # Calculate time elapsed for 20 batches\n",
        "                    time_elapsed = time.time() - t0_batch\n",
        "                    training_time += time_elapsed\n",
        "                    time_elapsed = format_time(time_elapsed)\n",
        "\n",
        "                    # Print training results\n",
        "                    print(f\"{step:^7} | {batch_loss / batch_counts:^12.6f} | {time_elapsed:^9}\")\n",
        "\n",
        "                    # Reset batch tracking variables\n",
        "                    batch_loss, batch_counts = 0, 0\n",
        "                    t0_batch = time.time()\n",
        "\n",
        "            # Calculate the average loss over the entire training data\n",
        "            avg_train_loss = total_loss / len(self.train_dataloader)\n",
        "            # Format training_time\n",
        "            training_time = format_time(training_time)\n",
        "\n",
        "            print(\"-\"*35)\n",
        "            print(f\"{'-':^7} | {avg_train_loss:^12.6f} | {training_time:^9}\")\n",
        "            print(\"-\"*35)\n",
        "            print(\"\\n\")\n",
        "\n",
        "            # =======================================\n",
        "            #               Evaluation\n",
        "            # =======================================\n",
        "\n",
        "            if evaluation:\n",
        "                # After the completion of each training epoch, measure the model's performance\n",
        "                # on our validation set.\n",
        "                val_loss, val_accuracy, validation_time = self.evaluate()\n",
        "\n",
        "            print(\"\\n\")\n",
        "\n",
        "            # Record all statistics from this epoch.\n",
        "            self.training_stats.append(\n",
        "                {\n",
        "                    'epoch': epoch_i + 1,\n",
        "                    'Training Loss': avg_train_loss,\n",
        "                    'Validation Loss': val_loss,\n",
        "                    'Accuracy': val_accuracy,\n",
        "                    'Training Time': training_time,\n",
        "                    'Validation Time': validation_time\n",
        "                }\n",
        "            )\n",
        "\n",
        "        # Finished all epochs\n",
        "        print(\"Training completed!\")\n",
        "\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "        on our validation set.\n",
        "        \"\"\"\n",
        "        # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "        # the test time.\n",
        "        self.model.eval()\n",
        "\n",
        "        # Set time\n",
        "        t0_val = time.time()\n",
        "\n",
        "        # Tracking variables\n",
        "        val_accuracy = []\n",
        "        val_loss = []\n",
        "\n",
        "        # For each batch in our validation set...\n",
        "        for batch in self.val_dataloader:\n",
        "            # Load batch to device\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Compute logits\n",
        "            with torch.no_grad(): \n",
        "                logits = self.model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "            # Get the predictions\n",
        "            preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "            # Calculate the accuracy rate\n",
        "            accuracy = (preds == b_labels).cpu().numpy().mean()\n",
        "            val_accuracy.append(accuracy)\n",
        "\n",
        "        # Compute the average accuracy and loss over the validation set.\n",
        "        val_loss = np.mean(val_loss)\n",
        "        val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "        # Compute elapsed time\n",
        "        time_elapsed = format_time(time.time() - t0_val)\n",
        "\n",
        "        print('Evaluation\\n')\n",
        "        print(f\"{'Val Loss':^10} | {'Accuracy':^10} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*35)\n",
        "        print(f\"{val_loss:^10.6f} | {val_accuracy:^10.6f} | {time_elapsed:^9}\")\n",
        "        print(\"-\"*35)\n",
        "\n",
        "        return val_loss, val_accuracy, time_elapsed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Owa1c6DDge93"
      },
      "source": [
        "Once we have declared the `BertTrainer` class, it is only necessary to specify the parameters to train the model. The authors recommend following hyper-parameters:\n",
        "\n",
        "- Batch size: 16 or 32\n",
        "- Learning rate for AdamW optimizer: 5e-5, 3e-5 or 2e-5\n",
        "- Number of epochs: 2, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX0SIOS7AtWH"
      },
      "source": [
        "#@title 5.5.1 - Hyperparameters Selection\n",
        "in_classifier = 50 #@param {type:\"integer\"}\n",
        "dropout_classifier = 0.1 #@param {type:\"number\"}\n",
        "batch_size =  32#@param {type:\"integer\"}\n",
        "learning_rate = 5e-5 #@param {type:\"number\"}\n",
        "epochs =  3#@param {type:\"integer\"}\n",
        "epsilon = 1e-8 #@param {type:\"number\"}\n",
        "\n",
        "args = {\n",
        "    'batch_size': batch_size,\n",
        "    'in_classifier': in_classifier,\n",
        "    'dropout': dropout_classifier,\n",
        "    'learning_rate': learning_rate,\n",
        "    'epsilon': epsilon,\n",
        "    'epochs': epochs,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vkGIBQ9jIrY"
      },
      "source": [
        "And now we only need to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THVUZrz-jIKy",
        "outputId": "87d9ca66-cba4-4d57-c462-d92aa1ead32c"
      },
      "source": [
        "trainer = BertTrainer(args)\n",
        "bert_classifier = trainer.model\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using GPU Tesla V100-SXM2-16GB. \n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "\n",
            "Training: 1411 batches\n",
            "\n",
            " Batch  |  Train Loss  |  Elapsed \n",
            "-----------------------------------\n",
            "  20    |   0.555438   |  0:00:03 \n",
            "  40    |   0.351080   |  0:00:03 \n",
            "  60    |   0.339012   |  0:00:03 \n",
            "  80    |   0.276070   |  0:00:03 \n",
            "  100   |   0.329376   |  0:00:03 \n",
            "  120   |   0.315651   |  0:00:03 \n",
            "  140   |   0.255791   |  0:00:03 \n",
            "  160   |   0.287897   |  0:00:03 \n",
            "  180   |   0.259710   |  0:00:03 \n",
            "  200   |   0.307018   |  0:00:03 \n",
            "  220   |   0.218056   |  0:00:03 \n",
            "  240   |   0.309831   |  0:00:03 \n",
            "  260   |   0.280426   |  0:00:03 \n",
            "  280   |   0.264489   |  0:00:03 \n",
            "  300   |   0.235010   |  0:00:03 \n",
            "  320   |   0.261343   |  0:00:03 \n",
            "  340   |   0.287082   |  0:00:03 \n",
            "  360   |   0.239603   |  0:00:03 \n",
            "  380   |   0.231830   |  0:00:03 \n",
            "  400   |   0.236977   |  0:00:03 \n",
            "  420   |   0.257990   |  0:00:03 \n",
            "  440   |   0.207908   |  0:00:03 \n",
            "  460   |   0.183973   |  0:00:03 \n",
            "  480   |   0.234772   |  0:00:03 \n",
            "  500   |   0.215050   |  0:00:03 \n",
            "  520   |   0.216594   |  0:00:03 \n",
            "  540   |   0.250292   |  0:00:03 \n",
            "  560   |   0.239748   |  0:00:03 \n",
            "  580   |   0.228981   |  0:00:03 \n",
            "  600   |   0.214876   |  0:00:03 \n",
            "  620   |   0.238977   |  0:00:03 \n",
            "  640   |   0.224044   |  0:00:03 \n",
            "  660   |   0.227067   |  0:00:03 \n",
            "  680   |   0.224259   |  0:00:03 \n",
            "  700   |   0.224043   |  0:00:03 \n",
            "  720   |   0.187492   |  0:00:03 \n",
            "  740   |   0.197600   |  0:00:03 \n",
            "  760   |   0.182428   |  0:00:03 \n",
            "  780   |   0.203660   |  0:00:03 \n",
            "  800   |   0.148308   |  0:00:03 \n",
            "  820   |   0.259542   |  0:00:03 \n",
            "  840   |   0.192439   |  0:00:03 \n",
            "  860   |   0.228221   |  0:00:03 \n",
            "  880   |   0.185666   |  0:00:03 \n",
            "  900   |   0.174603   |  0:00:03 \n",
            "  920   |   0.180943   |  0:00:03 \n",
            "  940   |   0.172616   |  0:00:03 \n",
            "  960   |   0.203420   |  0:00:03 \n",
            "  980   |   0.195837   |  0:00:03 \n",
            " 1000   |   0.150154   |  0:00:03 \n",
            " 1020   |   0.226337   |  0:00:03 \n",
            " 1040   |   0.196248   |  0:00:03 \n",
            " 1060   |   0.185805   |  0:00:03 \n",
            " 1080   |   0.204309   |  0:00:03 \n",
            " 1100   |   0.176149   |  0:00:03 \n",
            " 1120   |   0.201194   |  0:00:03 \n",
            " 1140   |   0.182539   |  0:00:03 \n",
            " 1160   |   0.214196   |  0:00:03 \n",
            " 1180   |   0.215805   |  0:00:03 \n",
            " 1200   |   0.177510   |  0:00:03 \n",
            " 1220   |   0.193761   |  0:00:03 \n",
            " 1240   |   0.162708   |  0:00:03 \n",
            " 1260   |   0.194760   |  0:00:03 \n",
            " 1280   |   0.157535   |  0:00:03 \n",
            " 1300   |   0.145813   |  0:00:03 \n",
            " 1320   |   0.164146   |  0:00:03 \n",
            " 1340   |   0.165993   |  0:00:03 \n",
            " 1360   |   0.148505   |  0:00:03 \n",
            " 1380   |   0.198019   |  0:00:03 \n",
            " 1400   |   0.136861   |  0:00:03 \n",
            " 1410   |   0.285800   |  0:00:01 \n",
            "-----------------------------------\n",
            "   -    |   0.225543   |  0:03:03 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "Evaluation\n",
            "\n",
            " Val Loss  |  Accuracy  |  Elapsed \n",
            "-----------------------------------\n",
            " 0.254492  |  0.919005  |  0:00:01 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "\n",
            "Training: 1411 batches\n",
            "\n",
            " Batch  |  Train Loss  |  Elapsed \n",
            "-----------------------------------\n",
            "  20    |   0.072319   |  0:00:03 \n",
            "  40    |   0.115612   |  0:00:03 \n",
            "  60    |   0.088238   |  0:00:03 \n",
            "  80    |   0.108739   |  0:00:03 \n",
            "  100   |   0.096666   |  0:00:03 \n",
            "  120   |   0.061493   |  0:00:03 \n",
            "  140   |   0.097590   |  0:00:03 \n",
            "  160   |   0.098089   |  0:00:03 \n",
            "  180   |   0.127830   |  0:00:03 \n",
            "  200   |   0.078615   |  0:00:03 \n",
            "  220   |   0.124187   |  0:00:03 \n",
            "  240   |   0.108401   |  0:00:03 \n",
            "  260   |   0.106333   |  0:00:03 \n",
            "  280   |   0.100271   |  0:00:03 \n",
            "  300   |   0.117443   |  0:00:03 \n",
            "  320   |   0.120873   |  0:00:03 \n",
            "  340   |   0.105831   |  0:00:03 \n",
            "  360   |   0.103158   |  0:00:03 \n",
            "  380   |   0.099981   |  0:00:03 \n",
            "  400   |   0.110912   |  0:00:03 \n",
            "  420   |   0.095511   |  0:00:03 \n",
            "  440   |   0.103234   |  0:00:03 \n",
            "  460   |   0.095601   |  0:00:03 \n",
            "  480   |   0.120289   |  0:00:03 \n",
            "  500   |   0.102274   |  0:00:03 \n",
            "  520   |   0.092063   |  0:00:03 \n",
            "  540   |   0.113593   |  0:00:03 \n",
            "  560   |   0.100597   |  0:00:03 \n",
            "  580   |   0.067635   |  0:00:03 \n",
            "  600   |   0.095311   |  0:00:03 \n",
            "  620   |   0.119959   |  0:00:03 \n",
            "  640   |   0.092875   |  0:00:03 \n",
            "  660   |   0.131382   |  0:00:03 \n",
            "  680   |   0.117474   |  0:00:03 \n",
            "  700   |   0.074815   |  0:00:03 \n",
            "  720   |   0.119689   |  0:00:03 \n",
            "  740   |   0.117896   |  0:00:03 \n",
            "  760   |   0.111450   |  0:00:03 \n",
            "  780   |   0.086658   |  0:00:03 \n",
            "  800   |   0.150996   |  0:00:03 \n",
            "  820   |   0.114772   |  0:00:03 \n",
            "  840   |   0.091011   |  0:00:03 \n",
            "  860   |   0.098810   |  0:00:03 \n",
            "  880   |   0.165014   |  0:00:03 \n",
            "  900   |   0.094031   |  0:00:03 \n",
            "  920   |   0.120180   |  0:00:03 \n",
            "  940   |   0.085546   |  0:00:03 \n",
            "  960   |   0.138499   |  0:00:03 \n",
            "  980   |   0.091755   |  0:00:03 \n",
            " 1000   |   0.109452   |  0:00:03 \n",
            " 1020   |   0.103488   |  0:00:03 \n",
            " 1040   |   0.119754   |  0:00:03 \n",
            " 1060   |   0.082003   |  0:00:03 \n",
            " 1080   |   0.126963   |  0:00:03 \n",
            " 1100   |   0.099838   |  0:00:03 \n",
            " 1120   |   0.117023   |  0:00:03 \n",
            " 1140   |   0.100062   |  0:00:03 \n",
            " 1160   |   0.089121   |  0:00:03 \n",
            " 1180   |   0.124510   |  0:00:03 \n",
            " 1200   |   0.104424   |  0:00:03 \n",
            " 1220   |   0.093490   |  0:00:03 \n",
            " 1240   |   0.090418   |  0:00:03 \n",
            " 1260   |   0.127287   |  0:00:03 \n",
            " 1280   |   0.075014   |  0:00:03 \n",
            " 1300   |   0.080099   |  0:00:03 \n",
            " 1320   |   0.099655   |  0:00:03 \n",
            " 1340   |   0.122537   |  0:00:03 \n",
            " 1360   |   0.135842   |  0:00:03 \n",
            " 1380   |   0.105515   |  0:00:03 \n",
            " 1400   |   0.096185   |  0:00:03 \n",
            " 1410   |   0.073826   |  0:00:01 \n",
            "-----------------------------------\n",
            "   -    |   0.104815   |  0:03:03 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "Evaluation\n",
            "\n",
            " Val Loss  |  Accuracy  |  Elapsed \n",
            "-----------------------------------\n",
            " 0.241967  |  0.924107  |  0:00:01 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "\n",
            "Training: 1411 batches\n",
            "\n",
            " Batch  |  Train Loss  |  Elapsed \n",
            "-----------------------------------\n",
            "  20    |   0.032546   |  0:00:03 \n",
            "  40    |   0.068907   |  0:00:03 \n",
            "  60    |   0.069330   |  0:00:03 \n",
            "  80    |   0.041475   |  0:00:03 \n",
            "  100   |   0.049386   |  0:00:03 \n",
            "  120   |   0.047769   |  0:00:03 \n",
            "  140   |   0.039676   |  0:00:03 \n",
            "  160   |   0.042408   |  0:00:03 \n",
            "  180   |   0.062334   |  0:00:03 \n",
            "  200   |   0.058476   |  0:00:03 \n",
            "  220   |   0.097458   |  0:00:03 \n",
            "  240   |   0.044635   |  0:00:03 \n",
            "  260   |   0.067325   |  0:00:03 \n",
            "  280   |   0.065397   |  0:00:03 \n",
            "  300   |   0.045987   |  0:00:03 \n",
            "  320   |   0.053620   |  0:00:03 \n",
            "  340   |   0.063941   |  0:00:03 \n",
            "  360   |   0.046003   |  0:00:03 \n",
            "  380   |   0.036988   |  0:00:03 \n",
            "  400   |   0.085366   |  0:00:03 \n",
            "  420   |   0.054657   |  0:00:03 \n",
            "  440   |   0.040556   |  0:00:03 \n",
            "  460   |   0.051309   |  0:00:03 \n",
            "  480   |   0.037407   |  0:00:03 \n",
            "  500   |   0.054300   |  0:00:03 \n",
            "  520   |   0.030397   |  0:00:03 \n",
            "  540   |   0.052287   |  0:00:03 \n",
            "  560   |   0.108117   |  0:00:03 \n",
            "  580   |   0.066625   |  0:00:03 \n",
            "  600   |   0.059031   |  0:00:03 \n",
            "  620   |   0.056238   |  0:00:03 \n",
            "  640   |   0.060868   |  0:00:03 \n",
            "  660   |   0.086221   |  0:00:03 \n",
            "  680   |   0.068495   |  0:00:03 \n",
            "  700   |   0.050812   |  0:00:03 \n",
            "  720   |   0.062190   |  0:00:03 \n",
            "  740   |   0.037744   |  0:00:03 \n",
            "  760   |   0.096159   |  0:00:03 \n",
            "  780   |   0.051588   |  0:00:03 \n",
            "  800   |   0.084455   |  0:00:03 \n",
            "  820   |   0.072414   |  0:00:03 \n",
            "  840   |   0.046875   |  0:00:03 \n",
            "  860   |   0.024247   |  0:00:03 \n",
            "  880   |   0.059114   |  0:00:03 \n",
            "  900   |   0.046501   |  0:00:03 \n",
            "  920   |   0.042333   |  0:00:03 \n",
            "  940   |   0.057758   |  0:00:03 \n",
            "  960   |   0.027826   |  0:00:03 \n",
            "  980   |   0.039719   |  0:00:03 \n",
            " 1000   |   0.051483   |  0:00:03 \n",
            " 1020   |   0.044091   |  0:00:03 \n",
            " 1040   |   0.039099   |  0:00:03 \n",
            " 1060   |   0.049087   |  0:00:03 \n",
            " 1080   |   0.075820   |  0:00:03 \n",
            " 1100   |   0.066660   |  0:00:03 \n",
            " 1120   |   0.038495   |  0:00:03 \n",
            " 1140   |   0.085075   |  0:00:03 \n",
            " 1160   |   0.068016   |  0:00:03 \n",
            " 1180   |   0.049787   |  0:00:03 \n",
            " 1200   |   0.049088   |  0:00:03 \n",
            " 1220   |   0.037788   |  0:00:03 \n",
            " 1240   |   0.036803   |  0:00:03 \n",
            " 1260   |   0.031693   |  0:00:03 \n",
            " 1280   |   0.051686   |  0:00:03 \n",
            " 1300   |   0.038937   |  0:00:03 \n",
            " 1320   |   0.060191   |  0:00:03 \n",
            " 1340   |   0.065268   |  0:00:03 \n",
            " 1360   |   0.054976   |  0:00:03 \n",
            " 1380   |   0.049582   |  0:00:03 \n",
            " 1400   |   0.049524   |  0:00:03 \n",
            " 1410   |   0.081877   |  0:00:01 \n",
            "-----------------------------------\n",
            "   -    |   0.055010   |  0:03:02 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "Evaluation\n",
            "\n",
            " Val Loss  |  Accuracy  |  Elapsed \n",
            "-----------------------------------\n",
            " 0.311103  |  0.918527  |  0:00:01 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "Training completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZBJw6_Kufca"
      },
      "source": [
        "After training the model, we can easily print its statistics in a data frame and save it as an excel table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "d9cqHoFsscUh",
        "outputId": "9f4f9223-f611-4ffc-cec9-e4a86306f67a"
      },
      "source": [
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=trainer.training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Save data frame\n",
        "df_stats.to_excel(sentiment_dir/'training_stats.xlsx')\n",
        "\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.225543</td>\n",
              "      <td>0.254492</td>\n",
              "      <td>0.919005</td>\n",
              "      <td>0:03:03</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.104815</td>\n",
              "      <td>0.241967</td>\n",
              "      <td>0.924107</td>\n",
              "      <td>0:03:03</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.055010</td>\n",
              "      <td>0.311103</td>\n",
              "      <td>0.918527</td>\n",
              "      <td>0:03:02</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Validation Loss  Accuracy Training Time Validation Time\n",
              "epoch                                                                        \n",
              "1           0.225543         0.254492  0.919005       0:03:03         0:00:01\n",
              "2           0.104815         0.241967  0.924107       0:03:03         0:00:01\n",
              "3           0.055010         0.311103  0.918527       0:03:02         0:00:01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FlBfCt1vzj9"
      },
      "source": [
        "We can print how both (training and validation) losses evolve during epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P38nQ_tbvpm2"
      },
      "source": [
        "def plot_loss_curves(df):\n",
        "    # Use plot styling from seaborn.\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "    # Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(df['Training Loss'], 'b-o', label=\"Training\")\n",
        "    plt.plot(df['Validation Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.xticks(df.index.values)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "54tP7ZpO-5Ui",
        "outputId": "f941f2dc-0209-4d77-bd05-4cd70323f902"
      },
      "source": [
        "plot_loss_curves(df_stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVxU5f4H8M8MzAw7DMi+KIIMpohggibljqiYaS4lV0uzNNO8lTf1Z6v3ertXLcssb5m2mEuKG+a+l9fC1K5mAgqogCAgOwizMOf3BzA6DigoMDP4eb9evmSec85znhnp9H3OfL/PEQmCIICIiIiIiMyC2NgDICIiIiKixmMAT0RERERkRhjAExERERGZEQbwRERERERmhAE8EREREZEZYQBPRERERGRGGMAT0UMvKysLCoUCn3766X33MW/ePCgUimYcVdvV0OetUCgwb968RvXx6aefQqFQICsrq9nHt3XrVigUCiQmJjZ730REzcHS2AMgIrpTUwLhQ4cOwcfHpwVHY35u3ryJ//znP9i9ezfy8vLg7OyMHj16YMaMGQgICGhUH6+++ir27duH7du3o3PnzvXuIwgCBg4ciNLSUhw/fhxWVlbN+TZaVGJiIk6ePInnnnsODg4Oxh6OgaysLAwcOBBxcXF45513jD0cIjIxDOCJyOQsXrxY7/Xp06fxww8/YPz48ejRo4feNmdn5wc+n7e3N86dOwcLC4v77uPvf/873n///QceS3N46623sGvXLsTGxiIiIgL5+fk4fPgwzp492+gAfsyYMdi3bx+2bNmCt956q959fv31V1y7dg3jx49vluD93LlzEItb54vhkydPYsWKFRg1apRBAD9y5EgMHz4cEomkVcZCRNRUDOCJyOSMHDlS73V1dTV++OEHdO/e3WDbncrLy2FnZ9ek84lEIshksiaP83amEuxVVlZi7969iIqKwocffqhrnzlzJlQqVaP7iYqKgqenJ3bu3Ik333wTUqnUYJ+tW7cCqAn2m8OD/hs0FwsLiweazBERtTTmwBOR2RowYAAmTpyICxcu4IUXXkCPHj3w5JNPAqgJ5JctW4axY8ciMjISXbt2xeDBg7F06VJUVlbq9VNfTvbtbUeOHMHTTz+NkJAQREVF4d///jc0Go1eH/XlwNe1lZWV4d1330Xv3r0REhKCZ555BmfPnjV4P0VFRZg/fz4iIyMRFhaGSZMm4cKFC5g4cSIGDBjQqM9EJBJBJBLVO6GoLwhviFgsxqhRo1BcXIzDhw8bbC8vL8f+/fsRFBSEbt26Nenzbkh9OfBarRZffPEFBgwYgJCQEMTGxiIhIaHe49PS0vDee+9h+PDhCAsLQ2hoKEaPHo3Nmzfr7Tdv3jysWLECADBw4EAoFAq9f/+GcuALCwvx/vvvo2/fvujatSv69u2L999/H0VFRXr71R3/yy+/YPXq1Rg0aBC6du2KIUOGYNu2bY36LJoiOTkZr7zyCiIjIxESEoJhw4Zh1apVqK6u1tsvJycH8+fPR//+/dG1a1f07t0bzzzzjN6YtFotvvnmG4wYMQJhYWEIDw/HkCFD8H//939Qq9XNPnYiuj+8A09EZi07OxvPPfccYmJiEB0djZs3bwIAcnNzER8fj+joaMTGxsLS0hInT57EV199haSkJKxevbpR/R87dgzr16/HM888g6effhqHDh3CmjVr4OjoiOnTpzeqjxdeeAHOzs545ZVXUFxcjK+//hovvfQSDh06pPu2QKVSYfLkyUhKSsLo0aMREhKClJQUTJ48GY6Ojo3+PKysrPDUU09hy5Yt+PHHHxEbG9voY+80evRorFy5Elu3bkVMTIzetl27dqGqqgpPP/00gOb7vO/0wQcf4LvvvkPPnj3x/PPPo6CgAAsXLoSvr6/BvidPnsSpU6fQr18/+Pj46L6NeOutt1BYWIhp06YBAMaPH4/y8nIcOHAA8+fPh1wuB3D32ouysjI8++yzuHr1Kp5++mk88sgjSEpKwoYNG/Drr79i8+bNBt/8LFu2DFVVVRg/fjykUik2bNiAefPmwc/PzyAV7H798ccfmDhxIiwtLREXF4d27drhyJEjWLp0KZKTk3Xfwmg0GkyePBm5ubmYMGECOnTogPLycqSkpODUqVMYNWoUAGDlypVYvnw5+vfvj2eeeQYWFhbIysrC4cOHoVKpTOabJqKHnkBEZOK2bNkiBAUFCVu2bNFr79+/vxAUFCRs2rTJ4BilUimoVCqD9mXLlglBQUHC2bNndW2ZmZlCUFCQsHz5coO20NBQITMzU9eu1WqF4cOHC3369NHrd+7cuUJQUFC9be+++65e++7du4WgoCBhw4YNurbvv/9eCAoKEj7//HO9feva+/fvb/Be6lNWVia8+OKLQteuXYVHHnlE2LVrV6OOa8ikSZOEzp07C7m5uXrt48aNE7p06SIUFBQIgvDgn7cgCEJQUJAwd+5c3eu0tDRBoVAIkyZNEjQaja79/PnzgkKhEIKCgvT+bSoqKgzOX11dLfzlL38RwsPD9ca3fPlyg+Pr1P2+/frrr7q2jz76SAgKChK+//57vX3r/n2WLVtmcPzIkSMFpVKpa79+/brQpUsX4bXXXjM4553qPqP333//rvuNHz9e6Ny5s5CUlKRr02q1wquvvioEBQUJJ06cEARBEJKSkoSgoCDhyy+/vGt/Tz31lDB06NB7jo+IjIspNERk1pycnDB69GiDdqlUqrtbqNFoUFJSgsLCQjz22GMAUG8KS30GDhyot8qNSCRCZGQk8vPzUVFR0ag+nn/+eb3XvXr1AgBcvXpV13bkyBFYWFhg0qRJevuOHTsW9vb2jTqPVqvF7NmzkZycjD179uCJJ57AnDlzsHPnTr393n77bXTp0qVROfFjxoxBdXU1tm/frmtLS0vD//73PwwYMEBXRNxcn/ftDh06BEEQMHnyZL2c9C5duqBPnz4G+9vY2Oh+ViqVKCoqQnFxMfr06YPy8nKkp6c3eQx1Dhw4AGdnZ4wfP16vffz48XB2dsbBgwcNjpkwYYJe2pK7uzv8/f1x5cqV+x7H7QoKCvD7779jwIABCA4O1rWLRCK8/PLLunED0P0OJSYmoqCgoME+7ezskJubi1OnTjXLGImoZTCFhojMmq+vb4MFh+vWrcPGjRuRmpoKrVart62kpKTR/d/JyckJAFBcXAxbW9sm91GXslFcXKxry8rKgpubm0F/UqkUPj4+KC0tved5Dh06hOPHj2PJkiXw8fHBJ598gpkzZ+LNN9+ERqPRpUmkpKQgJCSkUTnx0dHRcHBwwNatW/HSSy8BALZs2QIAuvSZOs3xed8uMzMTANCxY0eDbQEBATh+/LheW0VFBVasWIE9e/YgJyfH4JjGfIYNycrKQteuXWFpqf+/TUtLS3To0AEXLlwwOKah351r167d9zjuHBMABAYGGmzr2LEjxGKx7jP09vbG9OnT8eWXXyIqKgqdO3dGr169EBMTg27duumOe/311/HKK68gLi4Obm5uiIiIQL9+/TBkyJAm1VAQUctiAE9EZs3a2rre9q+//hr/+te/EBUVhUmTJsHNzQ0SiQS5ubmYN28eBEFoVP93W43kQfto7PGNVVd02bNnTwA1wf+KFSvw8ssvY/78+dBoNAgODsbZs2exaNGiRvUpk8kQGxuL9evX48yZMwgNDUVCQgI8PDzw+OOP6/Zrrs/7Qbzxxhs4evQoxo0bh549e8LJyQkWFhY4duwYvvnmG4NJRUtrrSUxG+u1117DmDFjcPToUZw6dQrx8fFYvXo1pk6dir/97W8AgLCwMBw4cADHjx9HYmIiEhMT8eOPP2LlypVYv369bvJKRMbFAJ6I2qQdO3bA29sbq1at0gukfvrpJyOOqmHe3t745ZdfUFFRoXcXXq1WIysrq1EPG6p7n9euXYOnpyeAmiD+888/x/Tp0/H222/D29sbQUFBeOqppxo9tjFjxmD9+vXYunUrSkpKkJ+fj+nTp+t9ri3xedfdwU5PT4efn5/etrS0NL3XpaWlOHr0KEaOHImFCxfqbTtx4oRB3yKRqMljuXz5MjQajd5deI1GgytXrtR7t72l1aV2paamGmxLT0+HVqs1GJevry8mTpyIiRMnQqlU4oUXXsBXX32FKVOmwMXFBQBga2uLIUOGYMiQIQBqvllZuHAh4uPjMXXq1BZ+V0TUGKZ1e4CIqJmIxWKIRCK9O78ajQarVq0y4qgaNmDAAFRXV+O7777Ta9+0aRPKysoa1Uffvn0B1Kx+cnt+u0wmw0cffQQHBwdkZWVhyJAhBqkgd9OlSxd07twZu3fvxrp16yASiQzWfm+Jz3vAgAEQiUT4+uuv9ZZE/PPPPw2C8rpJw513+vPy8gyWkQRu5cs3NrVn0KBBKCwsNOhr06ZNKCwsxKBBgxrVT3NycXFBWFgYjhw5gosXL+raBUHAl19+CQAYPHgwgJpVdO5cBlImk+nSk+o+h8LCQoPzdOnSRW8fIjI+3oEnojYpJiYGH374IV588UUMHjwY5eXl+PHHH5sUuLamsWPHYuPGjfj444+RkZGhW0Zy7969aN++vcG68/Xp06cPxowZg/j4eAwfPhwjR46Eh4cHMjMzsWPHDgA1wdhnn32GgIAADB06tNHjGzNmDP7+97/j559/RkREhMGd3Zb4vAMCAhAXF4fvv/8ezz33HKKjo1FQUIB169YhODhYL+/czs4Offr0QUJCAqysrBASEoJr167hhx9+gI+Pj169AQCEhoYCAJYuXYoRI0ZAJpOhU6dOCAoKqncsU6dOxd69e7Fw4UJcuHABnTt3RlJSEuLj4+Hv799id6bPnz+Pzz//3KDd0tISL730EhYsWICJEyciLi4OEyZMgKurK44cOYLjx48jNjYWvXv3BlCTXvX2228jOjoa/v7+sLW1xfnz5xEfH4/Q0FBdID9s2DB0794d3bp1g5ubG/Lz87Fp0yZIJBIMHz68Rd4jETWdaf6fjIjoAb3wwgsQBAHx8fFYtGgRXF1dMXToUDz99NMYNmyYsYdnQCqV4ttvv8XixYtx6NAh7NmzB926dcM333yDBQsWoKqqqlH9LFq0CBEREdi4cSNWr14NtVoNb29vxMTEYMqUKZBKpRg/fjz+9re/wd7eHlFRUY3qd8SIEVi8eDGUSqVB8SrQcp/3ggUL0K5dO2zatAmLFy9Ghw4d8M477+Dq1asGhaNLlizBhx9+iMOHD2Pbtm3o0KEDXnvtNVhaWmL+/Pl6+/bo0QNz5szBxo0b8fbbb0Oj0WDmzJkNBvD29vbYsGEDli9fjsOHD2Pr1q1wcXHBM888g1mzZjX56b+Ndfbs2XpX8JFKpXjppZcQEhKCjRs3Yvny5diwYQNu3rwJX19fzJkzB1OmTNHtr1AoMHjwYJw8eRI7d+6EVquFp6cnpk2bprfflClTcOzYMaxduxZlZWVwcXFBaGgopk2bprfSDREZl0hojcoiIiK6L9XV1ejVqxe6det23w9DIiKitoU58EREJqK+u+wbN25EaWlpveueExHRw4kpNEREJuKtt96CSqVCWFgYpFIpfv/9d/z4449o3749xo0bZ+zhERGRiWAKDRGRidi+fTvWrVuHK1eu4ObNm3BxcUHfvn0xe/ZstGvXztjDIyIiE8EAnoiIiIjIjDAHnoiIiIjIjDCAJyIiIiIyIyxibaKiogpota2fdeTiYoeCgvJWPy8R0YPi9YuIzJkxrmFisQhyuW2D2xnAN5FWKxglgK87NxGROeL1i4jMmaldw5hCQ0RERERkRhjAExERERGZEQbwRERERERmhAE8EREREZEZYQBPRERERGRGuApNC6isrEB5eQmqq9XN1mdenhharbbZ+iPjsrCQwM7OEdbWDS8RRURERFQfBvDNTK1WoaysCE5O7SCRyCASiZqlX0tLMTQaBvBtgSAIUKuVKC6+AUtLCSQSqbGHRERERGaEKTTNrKysGHZ2jpBKrZoteKe2RSQSQSq1gq2tI8rLi409HCIiIjIzDOCbmUajgkxmbexhkBmwsrKGWq0y9jCIiIjIzDCFpplptdUQiy2MPQwyA2KxBbTaamMPg4iIiOpx8voZJKTtRbGyGE4yJzwZEIMIj3BjDwsAA/gWwdQZagz+nhAREZmmk9fPYH3yFqi1NQuSFCmLsT55CwCYRBDPFBoiIiIiolrqajW2XvpRF7zr2rVqJKTtNdKo9PEOPJmEmTNfAgCsWPFlqx5LREREDzetoEVm2TUkF15CSlEq0kuuQK3V1LtvkdI0Fp9gAE93FRX1aKP227w5AZ6eXi08GiIiIqIHIwgCcm/mI6UoFSmFl3CxOB2VmkoAgJetB6K8e+G367+jXF1hcKxc5tTaw60XA3i6q7ffXqj3etOmDcjNzcGsWa/rtTs5yR/oPMuWfWaUY4mIiKjtK1aWIKUwFSlFqUguvIQSVSkAwNlKju6uXREsD0SQcyAcpPYAAD97H70ceACQiCV4MiDGKOO/EwN4uqshQ4bpvT569BBKSooN2u9UVVUFKyurRp9HIpHc1/ge9FgiIiJqe26qb+JicbouaM+9mQcAsJXYIEgeiGB5IBTyTmhn7VzvohJ1hapchYbarJkzX0J5eTnefPP/8Omny5CSkoy4uEl44YVp+Pnno0hI2IaLF1NQWloCV1c3DBs2AhMnToaFhYVeH8CtPPYzZ07h1VenY9Gixbh8OR3bt29BaWkJQkJC8be//R98fHyb5VgA2LJlEzZuXIeCghsICAjAzJmvYdWqlXp9EhERkelSVauRXnKlNi0mFRllWRAgQCqWINCpIx7z6gmFvBO87TwgFjVuDZcIj3BEeITD1dUe+fllLfwOmoYBvBn45c/r2PpTOgpKquDiIMPovgHo3cXD2MPSU1xchDfffA3R0TGIiRkOd/ea8e3e/SOsrW0wfnwcbGyscfr0KXz11X9QUVGBV16Zfc9+v/12NcRiC0yYMAllZaXYsGEt3n//Laxa9W2zHLttWzyWLVuM7t3DMX78s8jJycH8+XNgb28PV1e3+/9AiIiIqMVoBS0yyrKQUpiK5NrCU41WA7FIjA4OfojpMBAKeSD8Hf1gKW574W7be0dtzC9/Xse3e5Kh0mgBAAWlSny7JxkATCqIv3EjH/PmvY3Y2JF67e+99w/IZLdSaZ56agyWLPkntm3bjBdffBlSqfSu/Wo0GqxZ8y0sLWt+VR0cHPHJJ0uRnp6Kjh0DH+hYtVqNr75aiS5dQvDxx5/r9gsM7IRFi95jAE9ERGQiagpP85BclIqLham4WJyGSk0VgJrC0ye8e0MhD0Sgkz+sLBufwmuujBrAq1QqfPLJJ9ixYwdKS0sRHByM1157Db17977rcQkJCYiPj0daWhpKSkrg5uaGyMhIzJw5E97e3gb7b968GWvWrEFWVha8vLwwadIkxMXFtdTbMvDfP3Jw/FzOfR2bll0CTbWg16bSaPH17iT89L/sJvUV1c0TfUI872sc92JlZYWYmOEG7bcH7zdvVkClUiM0NAw7dmzF1atX0KlT0F37HT78SV1gDQChod0BANnZ1+4ZwN/r2OTkCygpKcGMGaP09hs8OAbLl390176JiIioZRVVFdekxNSmxdQVnrpYyRHmGgKFcycEyQN0hacPE6MG8PPmzcP+/fsxadIktG/fHtu2bcOLL76ItWvXIiwsrMHjkpOT4e7ujr59+8LR0RHZ2dnYtGkTjh49ioSEBLi6uur23bhxI959913ExMRg8uTJOHXqFBYuXAilUokpU6a0xtt8IHcG7/dqNxZXVze9ILhOenoaVq1aiTNnfkNFhf5yTBUV5ffsty4Vp469vQMAoKzs3rlo9zr2+vWaSdWdOfGWlpbw9GyZiQ4RERHV71bh6aXawtN8AICdxBZB8gAo5IEIdu6EdtYuRh6p8RktgD937hx27dqF+fPn4/nnnwcAPPXUU4iNjcXSpUuxbt26Bo998803DdoGDhyI0aNHIyEhAS+88AKAmpVQli1bhoEDB+KTTz4BAIwbNw5arRYrVqzA2LFjYW/f8rO2PiH3f+f7b5//FwWlSoN2FwcZ5saZRiU0oH+nvU5ZWRlmzXoJNjZ2eOGF6fD29oFUKsXFi8lYufJTaLXae/YrFlvU2y4I957APMixRERE1LJuLzxNLryEzLJrtwpP5R3xmFdEkwtPHxZGC+D37t0LiUSCsWPH6tpkMhnGjBmDZcuWIS8vD25ujc9B9vKqeYhQaWmpri0xMRHFxcWYMGGC3r5xcXHYuXMnfvrpJwwfbpj2YUpG9w3Qy4EHAKmlGKP7BhhxVI3z+++nUVJSgkWLlqB791uTjZycpqX+tBQPj5pJVVZWJkJDb33jo9FokJOTg4CAu6foEBERUeNVa6uRUXZNlxZzZ+Hp0A4DoXDuhA4Ovm2y8LQ5Ge3TSUpKgr+/P2xtbfXau3XrBkEQkJSUdM8Avri4GNXV1cjOzsZnn9U8zOf2/PkLFy4AALp27ap3XJcuXSAWi3HhwgWTD+DrClVNfRWa+ojFNbPl2+94q9VqbNu22VhD0hMc/AgcHR2RkLANQ4YM06UAHTiwF2Vlpfc4moiIiO5GV3hauxb7pdsKT73tPB+6wtPmZLQAPj8/H+7u7gbtdfnreXl59+xjyJAhKC4uBgA4OTnhnXfeQa9evfTOIZVK4eSk/9jburbGnMMU9O7igcdDvaDR3DvlxJSEhHSDvb0DFi16D2PGjIdIJMK+fbthKhksEokEU6a8hGXLluCvf52B/v0HIicnB3v27IS3t0+9D3YgIiKihtUVniYXpuJi0SWUqGrqzlysnBHm2g0K50Ao5IGwl9oZeaTmzWgBfFVVVb1P0JTJZAAApdIw7/tOK1aswM2bN3H58mUkJCQYFEk2dI668zTmHHdycbn7L1xenhiWli2Tp9VS/TZFXVB7+1hEIhFEIsPxubg448MPP8Hy5R9h1ar/wMHBHkOGDEPPnhGYPfsVWFjc+qzu7NfCou5vkV6/de1isahZjh0//lmIRCKsX78Wn332CQIDg7Bkycf46KPFkMlkLf6Zi8ViuLo+fNXz9PDh7zlR21SuqsCfeRfxR24y/shNRk5Zzc1Re5kdQtwV6OoejBB3BdztXO/Rk2kztWuYSDBSRV9sbCzc3d2xevVqvfbU1FQMHz4c//jHP/Ty4+8lMzMTI0aMwJw5c/CXv/wFALBw4UJs2rQJ58+fN9i/d+/eiIqKwpIlS5o07oKCcmi1DX9k169fhYdH+yb12RiWlmKzuwNvrrRaLWJjB6Nv3/6YO/etFj1XS/2+EJkSU3yKIRHdH1W1Gmkll5FSmxajKzy1kCLQyR/B8k5QyAPh1YYKT41xDROLRXe9aWy0O/Curq71prDk59csGdSUAlYA8PX1RZcuXbBz505dAO/q6gq1Wo3i4mK9NBqVSoXi4uImn4PaHqVSqfvWp87evbtQWlqCsLAeRhoVERGRaagpPM3SrcWeXnpVV3jqz8JTozHaJx0cHIy1a9eioqJCr5D17Nmzuu1NVVVVhcrKSt3rzp07AwDOnz+PqKgoXfv58+eh1Wp12+nhde7c/7By5afo128AHBwccfFiMnbtSkDHjgHo33+QsYdHRETUqgRBwPWbeUgpTEVy0SVcKkpHVbV+4WmwcycEOPrDylJ2j96opRgtgI+JicGaNWuwefNm3TrwKpUKW7duRXh4uK7ANTs7G5WVlQgIuLVsYmFhIZydnfX6O3/+PJKTkzFs2DBdW69eveDk5IT169frBfAbNmyAjY0NnnjiiRZ8h2QOvLy80a6dK+Ljf0BpaQkcHBwREzMc06fPbLB+goiIqC0pqipGcu0d9tsLT9tZOaOHezco5IEIYuGpSTFaAB8aGoqYmBgsXboU+fn58PPzw7Zt25CdnY0PPvhAt9/cuXNx8uRJpKSk6Nr69++PoUOHIigoCDY2NkhNTcWWLVtga2uLGTNm6PazsrLCq6++ioULF2L27NmIiorCqVOnkJCQgDlz5sDBwaFV3zOZHm9vHyxevMzYwyAiImo1FeqbuFiUVrse+yXk3bwBoOaJpwp5YO1KMZ3Qztr5Hj2RsRg1WWnx4sX4+OOPsWPHDpSUlEChUODLL79Ejx53zz2eMGECfvnlFxw8eBBVVVVwdXVFTEwMZsyYAV9fX7194+LiIJFIsGbNGhw6dAienp5YsGABJk2a1JJvjYiIiMgkqKpVSCu5Ult4egmZZdm6wtNOTh3xuFcvKJw7wdPWvc0UnrZ1RluFxlxxFRpqTlyFhh4GXIWGqHXVFZ4m1wbsl0uuQiNUw0JkgQ4Ofrq12Fl42jhchYaIiIiImpUgCMipyNWlxFwquqwrPPWx80Jfnz5QOAey8LQNYQBPREREZGYKq4p0a7GnFKWiVK/wNLS28DSAhadtFAN4IiIiIhNXrq7QFZ5eLExFXmVN4am9xA5B8gAEO9c8QMmFhacPBQbwRERERCZGVa1CWvEVJBddQkpRKrJqC09ldYWn3jWFp162HhCJRMYeLrUyBvBERERERlatrcbVsizdSjG3F576O/phmP8gKOQ1Tzy1EFsYe7hkZAzgqdXt3r0T//zn+9i8OQGenl4AgDFjRiAsrAcWLHivycc+qDNnTuHVV6dj+fL/IDz80Wbpk4iI6G4MC0/TUVWtBFBbeOrbBwp5JwQ6+UNmITXyaMnUMICne3rzzddw5sxv2LnzAKytrevd5/XXZ+LPP/9AQsJ+yGSmWeF+8OA+FBYWYNy4CcYeChERPYQKq4p0SzteLEq7VXhq7YIe7t0R7NwJQU4BsJPaGnmkZOoYwNM9DR48BCdO/Izjx49h8OAYg+1FRYU4ffo3REcPve/gff36LRCLW/bhEYcO7celSxcNAvju3cNx6NB/IZFIWvT8RET0cNEVnhbW5LHnVxYAqCk8rVuLnYWndD8YwNM9Pf54P1hb2+DgwX31BvCHDx9EdXU1oqMNtzWWVGq8rwfFYrHJfmtARETmQ1mtQlrx5Zq0mMJLyCrPua3wNABP+DwGhTyQhaf0wBjA0z1ZWVnh8cf74siRgygtLYWDg4Pe9oMH98HFxQW+vu2xdORotZcAACAASURBVOm/cPr0SeTm5sLKygrh4Y/ilVdm3zNfvb4c+PT0NHz88RKcP/8HHB0dMXLkaLRr52pw7M8/H0VCwjZcvJiC0tISuLq6YdiwEZg4cTIsLGoKfWbOfAn/+98ZAEBUVE2eu4eHJ+LjdzaYA3/o0H58//03uHr1CmxsbNGnz+N4+eVX4eTkpNtn5syXUF5ejnfeWYiPPlqMpKQ/YW/vgLFjn0Fc3HNN+6CJiMis1BSeZurWY08vuYrq2wpPh/sPhsI5EO3tWXhKzYsBvBk4ef0MdqbvRWFVMeQyJzwZEIMIj/BWHcPgwTHYv38Pjh49hCefHKVrv349B+fPn8OYMc8gKelPnD9/DoMGDYGrqxtycrKxffsWzJo1Dd9/vxlWVlaNPl9BwQ28+up0aLVa/OUvz8HKyhoJCdvqvVO+e/ePsLa2wfjxcbCxscbp06fw1Vf/QUVFBV55ZTYA4LnnpqCyshK5uTmYNet1AIC1tU2D568rlu3SJQQvv/wq8vJysWXLD0hK+hOrVn2nN47S0hK88car6N9/IAYOjMaRIwexcuWn6NgxEL1792n0eyYiItNWV3iaXHQJKYWpSC2uKTwVQQQfO0/0942CQh6IABaeUgtjAG/iTl4/g/XJW6DWqgEARcpirE/eAgCtGsT37BkJJyc5Dh7cpxfAHzy4D4IgYPDgIQgICET//oP0juvT5wlMnz4ZR48eQkzM8Eafb926b1FSUoyvvloLhSIYADB0aCyefXaUwb7vvfcPyGS3JgdPPTUGS5b8E9u2bcaLL74MqVSKnj17YevWzSgpKcaQIcPuem6NRoOVKz9FYGAQPv30C116j0IRjPfeW4CdO7dhzJhndPvn5eXi3Xf/oUsvio0diTFjYrFr1w4G8EREZq6gski3UkxKUSrKVOUAAFdrFzzq3h0KFp6SETCAbwWJOafxS85v93Xs5ZIMaASNXptaq8a6pHicyD7ZpL56e/ZEpGeP+xqHpaUlBgwYhO3bt+DGjRto164dAODgwf3w8fHFI4901dtfo9GgoqIcPj6+sLOzx8WLyU0K4H/55b8ICQnVBe8AIJfLMXjwUGzbtllv39uD95s3K6BSqREaGoYdO7bi6tUr6NQpqEnvNTn5AoqKCnXBf50BAwbjs88+wYkT/9UL4O3s7DBo0BDda4lEgs6duyA7+1qTzktERMZXrqrAxeKawtPkolTcqCs8ldrVFp3WPfFUbuSR0sOMAbyJuzN4v1d7Sxo8OAZbt27G4cP7MW7cBFy5chmpqRcxefKLAAClsgpr136D3bt3Ij8/D4Ig6I4tLy9v0rlyc68jJCTUoN3Pr71BW3p6GlatWokzZ35DRUWF3raKiqadF6hJC6rvXGKxGD4+vsjNzdFrd3NzNyhGsrd3QFpaapPPTURErUtZrUJq8eWapR0LU3WFp1YWMnSSd0Q/nz5QyAPhaWt4rScyFgbwrSDSs8d93/l+67//RJGy2KBdLnPCX8OnP+jQmiQkJBSent44cGAvxo2bgAMH9gKALnVk2bIl2L17J8aOfRZdu4bAzs4OgAjvvfd/esF8cyorK8OsWS/BxsYOL7wwHd7ePpBKpbh4MRkrV34KrVbbIue9nbiBwqSWes9ERHT/6gpPk2uXdrxckoFqoRqWIgv4O7bHcP/o2sJTHxaeksliAG/ingyI0cuBBwCJWIInA+5/ycYHMWhQNNau/RpZWZk4dGg/FIrOujvVdXnus2a9pttfqVQ2+e47ALi7eyArK9OgPSPjqt7r338/jZKSEixatATdu9+qCcjJya6n18bdOfHw8NSd6/Y+BUFAVlYm/P0DGtUPEREZnyAIyK64rlva8VJxOpTVqprCU3sv9PeNQrC8EwKcOkDKwlMyEwzgTVxdoaqxV6GpEx09FGvXfo0VK5YhKytTL1iv7070li0/oLq6usnn6d27DzZv3oiUlGRdHnxRUREOHNijt1/dw59uv9utVqsN8uQBwNraulGTieDgRyCXO2P79ngMHRqre8DTkSOHkJ+fh7i4SU1+P0RE1HoKKgtrC09TkVKYijJ1zbXfzbodenqEQyEPRJA8AHYSFp6SeWIAbwYiPMLxmM+j0GhaPh3kXvz9OyIwMAjHj/8EsViMgQNvFW8+9lgU9u3bDVtbO3To4I8///wDp06dhKOjY5PPM2HCc9i3bzdef/0VjBnzDGQyKyQkbIO7uyfKyy/p9gsJ6QZ7ewcsWvQexowZD5FIhH37dqO+7BWFIhj79+/Bp59+hODgR2BtbYOoqCcM9rO0tMTLL8/CP//5PmbNmoZBg6KRl5eL+Pgf0LFjAEaMMFwJh4iIjKdcVXFbwH4JN6oKAdQUngY71xSdKpwD4WzFwlNqGxjAU5NFR8cgNfUiwsJ66FajAYDZs+dALBbjwIE9UCpVCAkJxccff4bXX5/V5HO0a9cOy5d/gWXLFmPt2m/0HuT0r3/9Xbefo6MTFi9ehhUrPsaqVSthb++A6OihePTRCLz++ky9PkeOfBoXLyZj9+4f8cMP6+Hh4VlvAA8Aw4aNgFQqxbp13+Kzzz6Bra0tBg+OwfTps/jUViIiI9MVntbmsWeV16RN6gpPa9djZ+EptVUigZV2TVJQUA6ttuGP7Pr1q/DwMFwp5UFZWopN4g48Na+W+n0hMiWurvbIzy8z9jDIjFVrq3GlNBMpRZeQXJiKK6X6hacKeScEOwfCj4Wn1AKMcQ0Ti0VwcbFrcDvvwBMREZFJ0Qpa5FTk6tZiT72t8NTX3gsDfB+vfeIpC0/p4cQAnoiIiIzuRmVhzdNOC2ty2cvVNc/1cLNuhwiPHrrCU1uJjZFHSmR8DOCJiIio1ZWpynHxtpVi6gpPHaT26OwcBIVzJwTLAyG3cjLySIlMDwN4IiIianFVGiXSSi7rHqB0rbzmqdZWFla6wtNg507wsHFj4SnRPTCAJyIiomZXra3G5dIM3dKOl0szoBW0sBRZoKNjB4zoOAQKOQtPie4HA3giIiJ6YFpBi+zy67r12C8Vp0OlKzz1xkDfJ6BwDkSAIwtPiR4UA3giIiK6LzcqC3VrsesVntq0Q6RHDwTLA9GJhadEzY4BfAsQBIH5e3RPfAQDEZmbusLT5NqVYgpqC08dpfbo7KyAwjmQhadErYABfDOzsLCEWq2CVMqnddLdqdUqWFjwP0EiMl1VGiVSi9N1d9jrCk+tLa3QySkAA3wfR7BzINxZeErUqhg9NDM7OycUF+fDyckVEomUFzQyIAgC1GoViovzYW8vN/ZwiIh0NFpNzRNPa9NiDAtPY2oLT71ZeEpkRAzgm5m1tS0AoKTkBqqrNc3Wr1gshlarbbb+yLgsLCxhby/X/b4QERlDXeFpclFNwJ5afFmv8HSQX18o5IHo6NgBUguJsYdLRLUYwLcAa2vbZg/MXF3tkZ9f1qx9EhHRw+dGZQFSClORXHQJF4vSdIWn7jau6OXRAwrnTghy6ggbFp4SmSwG8ERERG1Ymapc97TTlKJLKKgqAgA4Sh3wiIsCCnkgFCw8JTIrDOCJiIjakCpNFVKLL9dbeBrkFIABfk8gWM7CUyJzxgCeiIjIjNUVnibXFp5eqSs8FVuio2MHPNkxBgrnQPjasfCUqK1gAE9ERGRGtIIW18qvI6XoElIKU5Facqvw1M/eh4WnRA8BBvBEREQmTBCEmiee1q4Uo1946oZeHo9C4RzIwlOihwgDeCIiIhNTqirDxdqnndY88fRW4WkXl+CawlPnQDjJHI08UiIyBgbwRERERlalqcKluieeFqYiu+I6gFuFpwNr02LcbVxZeEpEDOCJiIham0arweWSjNo77JdwpTRTV3ga4NgBT7rHINi5E3ztvSEWiY09XCIyMQzgiYiIWlhN4WmO7g57anE6VFp1TeGpAwtPiahpGMATERE1M0EQkF9ZoMthv1iUigr1TQA1hae9vXpCIQ9EJ6cA2EisjTxaIjI3DOBN3MnrZ5CQthfFymI4yZzwZEAMIjzCjT0sIiK6Q13haXJt0F5YW3jqJHNEV5fOLDwlombDAN6Enbx+BuuTt0CtVQMAipTFWJ8cD2W1Cr09H4WlmP98RETG0nDhqTWC5AEYXJsW48bCUyJqZkaNAFUqFT755BPs2LEDpaWlCA4OxmuvvYbevXvf9bj9+/dj9+7dOHfuHAoKCuDp6Yn+/ftjxowZsLe319tXoVDU28d7772HZ599ttneS0tISNurC97rqLUabEzZio0pW2EhsoCVhQxSCylkljLILKSQWchgZVH3c81rmW67TK/Nqp42TgqIiOqn1mpwpeSqLi2mrvBUIrZEgKM/erqH1TzxlIWnRNTCjBqtzZs3D/v378ekSZPQvn17bNu2DS+++CLWrl2LsLCwBo97++234ebmhpEjR8LLywspKSlYu3Ytfv75Z2zZsgUymUxv/6ioKDz55JN6baGhoS3ynppTkbK4wW0jOsZAWa2s+aNR1f6sQlW1EgXqCiirb7WpqlWNPqelyAKyOyYFNROCOyYFlvqBv27iYGnYxkd3E5E5qis8TS6seYBSavFlqGsLT9s7+GKwX7/awtP2kLDwlIhakdEC+HPnzmHXrl2YP38+nn/+eQDAU089hdjYWCxduhTr1q1r8Njly5cjMjJSr61r166YO3cudu3ahdGjR+tt69ixI0aOHNns76GlyWVO9QbxcpkTYjoMaHQ/WkELVbVKL6iv0ih1P99qV976+Y5JQXkzTgqsLO4M/hv4hqBu4sBJARG1gluFp5eQUpiKi8VpusJTDxs3POYVUVt42pGFp0RkVEYL4Pfu3QuJRIKxY8fq2mQyGcaMGYNly5YhLy8Pbm5u9R57Z/AOAIMGDQIApKWl1XtMVVUVRCKRwd15U/ZkQIxeDjwASMQSPBkQ06R+xCIxrCytYGVp1Wxje5BJQVVtm96kQKOE6o50obtpzklBXRsnBUQPnxJlGS4WpSK5Nmivu2lSV3ga7NwJQfIAFp4SkUkxWgCflJQEf39/2Nra6rV369YNgiAgKSmpwQC+Pjdu3AAAyOVyg23x8fFYu3YtBEFAUFAQXn31VQwePPjB3kArqFttxhRXoWmNSUHVHd8ENDQpqLqtTTcpqJ1M3O+koL76gAbThnRpRYZtnBQQmZZKTRVSi9ORUlgTtOdU5AIAbGoLT6Pl/aBw7gQ363YsPCUik2W0AD4/Px/u7u4G7a6urgCAvLy8JvW3atUqWFhYIDo6Wq89LCwMw4YNg4+PD3JycvDdd99h5syZ+PDDDxEbG3v/b6CVRHiEI8IjHK6u9sjPLzP2cFpUS08KquqpGajv75pvElT6k4Lb2u5nUlBf8H8r6K/nG4LbJgV3tnFSQNR4aq0Gl+sKTwtTcbVMv/A0wiMcCjkLT4nIvBgtgK+qqoJEYlj0U5fiolQqG93Xzp07ER8fj2nTpsHPz09v28aNG/Vejxo1CrGxsViyZAmGDx/e5DssLi52Tdq/Obm62t97J2pxWq0WymoVKjVVqNIoUaWuCfpr/lTd9nPNn0q1YVuJuhhVlbdeK5tSUyC2hLWlDFa3/5HIILO0Mmy3tIK1xLDNSqL/2pKTAmphrXX90gpaXCnKwh+5yTifl4yk/FSoqtUQiUQIlLfHU52j0dUtGEHtOvKJp0TUaKYWgxktgLeysoJabXgnsy5wb2yu+qlTp7BgwQL069cPs2fPvuf+NjY2eOaZZ/Dhhx8iPT0dAQEBTRp3QUE5tFqhScc0h4fhDrz5sYAENpDABvYiAJLaP/dBK2gNvxHQ3JkyVP83BMpqJSqqqlBYXfpg3xQ0UDMgveObAsN6A1ltypGU3xRQvVry+lVTeHoDKUWpSC5MxaWiNFRoagtPbd3R2zMCwfJAdJJ3hLXlrcLTksIqAFUtMiYialuMEYOJxaK73jQ2WgDv6upab5pMfn4+ADQq/z05ORkvv/wyFAoFli1bBguLxgUMnp6eAICSkpImjJio5YhFYlhbWsG6mdOHDCcFdwb/dxYf3/63Ui99qKpaafBcgruxFFs2WDNw+6TAIG2ooRoETgqoVomyrGalmNq0mLrCU7nMCSHtHoHCOZCFp0TUphktgA8ODsbatWtRUVGhV8h69uxZ3fa7ycjIwNSpU+Hs7IwvvvgCNjY2jT53ZmYmAMDZ2fk+Rk5kHlplUlBP8G9YfKy/T5m6HErNrdWIHmRScHvwL9WrGbj3NwScFJiPSk0lLhWl6x6gpF94GohoeX8EOwfClYWnRPSQMFoAHxMTgzVr1mDz5s26deBVKhW2bt2K8PBwXYFrdnY2Kisr9VJd8vPzMWXKFIhEIqxevbrBQLywsNBgW1FREdavXw8fHx906NChRd4bUVvV4pOCetKDqnSThbtPCm7/JsF4k4KanzkpeDC6wtPaByhdLcuqLTyVIMCxAyI9ekAhD4SPvRcLT4nooWS0AD40NBQxMTFYunQp8vPz4efnh23btiE7OxsffPCBbr+5c+fi5MmTSElJ0bVNnToVmZmZmDp1Kk6fPo3Tp0/rtvn5+eme4rpu3TocOnQI/fr1g5eXF3Jzc/HDDz+gsLAQn332Weu9WSJqkN6koJke03C3ScHty44a1hnc+rtUVabXdr+TgjuDf6le8H/HxOEhnRRoBS2yyrJr89gvIa3kCtRaNcQiMdrb+yDar2ZpR3/H9pCIjfoAcSIik2DUK+HixYvx8ccfY8eOHSgpKYFCocCXX36JHj163PW45ORkAMBXX31lsG3UqFG6AD4sLAxnzpzB5s2bUVJSAhsbG3Tv3h3Tpk275zmIyHy13KTg9tShO74huMekoErTPJOC+moG9AuQ75g4WBpOBlprUnDy+pl6n2MhCALyKm8gpbAmJeZiUSpuaioBAJ627ujjFYFg504IdPLXKzwlIqIaIkEQWn9JFTPGVWiIqLlUa6uh0qr0JgVV9X0jUF9qUT1tymol1FpNo89vKbasNz2oOSYFJ6+fMXiStIXIAh3s/VCoLNIrPFU4B0Ihr/njKHNo3g+ZiOgBcRUaIiLSsRBbwFpsXXOXuZm+KbhzUmDwDYFeWtGdxcc1P+t/U3B/k4Kb6kpoodUfm1CN9NIr6O7aFUOc+0MhZ+EpEdH9YABPRNSGtPSkoN5lR/Xaatp/uvZLvX0JEDA1ZGLzDIyI6CHFAJ6IiO7qfiYFf9xI0qXJ3E4uc2rm0RERPXy4/hYRETW7JwNiIBHrP5pYIpbgyYAYI42IiKjt4B14IiJqdhEe4QBQ7yo0RET0YBjAExFRi4jwCEeERzhX0SIiamZMoSEiIiIiMiMM4ImIiIiIzAgDeCIiIiIiM8IAnoiIiIjIjDCAJyIiIiIyIwzgiYiIiIjMCAN4IiIiIiIzwgCeiIiIiMiMMIAnIiIiIjIjDOCJiIiIiMwIA3giIiIiIjNiaewB0N398ud1bD2WhsJSJZwdZBjdNwC9u3gYe1hEREREZCQM4E3YL39ex7d7kqHSaAEABaVKfLsnGQAYxBMRERE9pJhCY8K2HkvTBe91VBotth5LM9KIiIiIiMjYGMCbsIJSZZPaiYiIiKjtYwBvwlwcZA1uW7H1D6RdK2nF0RARERGRKWAAb8JG9w2A1FL/n0hiKUb3Ti5IySjCorWn8cH3p/G/SzegFQQjjZKIiIiIWhOLWE1YXaFqfavQVKk0+PlsDvb/loHlW87B08UGMRF+6NXFAxJLzsuIiIiI2iqRIPDWbVMUFJRDq239j8zV1R75+WUG7ZpqLU4l52FvYgYy8srhaCfF4Ed90a+7F2ysJK0+TiKiOzV0/SIiMgfGuIaJxSK4uNg1uJ0BfBOZWgBfRxAEXLhShD2JV3HhShGspBbo290Lgx/1hbODVSuOlIhIHwN4IjJnphjAM4WmjRCJROji74wu/s64er0Me09m4MBvWTh4KguRj7gjJtIPPq4N/yIQERERkXngHfgmMtU78PW5UVyJ/b9l4qdz2VCptQjp6IKhkX5Q+DlBJBK10EiJiPTxDjwRmTNTvAPPAL6JzCmAr1NeqcaRM1k4eDoLZTfV8Pe0R0xke/QIcoVYzECeiFoWA3giMmcM4NsAcwzg66jU1Thx/jr2nsxAXlEl3JysMSTCF31CPCGVWDTTSImI9DGAJyJzxgC+DTDnAL6OVivg90v52JOYgfTsUthZSzCohw/6h3vD3kbaLOcgIqrDAJ6IzBkD+DagLQTwdQRBwKWsEuz59SrOphVAainG4928EB3hC1cn62Y9FxE9vBjAE5E5M8UAnqvQPMREIhGCfJ0Q5OuEazcqsC8xA0f/dw2Hf89Cz2A3xET6oYOHg7GHSURERES34R34JmpLd+DrU1SmxMFTmTj6v2uoVFajc3s5hkb6oYu/M1euIaL7wjvwRGTOTPEOPAP4JmrrAXydm1Ua/HQ2G/t/y0BxuQo+rnaIifRFRGd3WFqIW20cRGT+GMATkTljAN8GPCwBfB1NtRaJF3KxNzED125UwNlBhuhHffF4qBesZczAIqJ7YwBPROaMAXwb8LAF8HW0goA/0gqwNzEDKZnFsJFZon+4Nwb18IGjncxo4yIi02fs6xcR0YMwxQCet1CpUcQiEUID2yE0sB3Ss0uxN/Eqdv9yFftOZuCxrh4YEuEHTxdbYw+TiIiIqM1jAE9N1tHLATNGhSC36Cb2n8zE8T9y8PPZHHTv1A5DI9sj0MfR2EMkIiIiarOYQtNED2sKzd2UVqhw6HQWDp/JQkWVBoHejhga6YfQTu0g5so1RA89U75+ERHdiymm0DCAbyIG8A1Tqqrx87ls7P8tEzdKquDhbIOYSD/07uIOiaWFsYdHREZiDtcvIqKGMIBvAxjA31u1VotTyfnYk3gVGbnlcLSVYtCjPugX5g1bK4mxh0dErcycrl9ERHdiAN8GMIBvPEEQkHS1CHsSM/Dn5ULIpBboG+qFwY/6wsXRytjDI6JWYo7XLyKiOqYYwLOIlVqMSCTCIx2c8UgHZ2TklmHvyQwcPJWFQ6ezENHZHTGRfvB1a/iXk4iIiIgMGfUOvEqlwieffIIdO3agtLQUwcHBeO2119C7d++7Hrd//37s3r0b586dQ0FBATw9PdG/f3/MmDED9vb2Bvtv3rwZa9asQVZWFry8vDBp0iTExcXd15h5B/7B3CipxIHfsvDT2Wwo1dXo2tEZQyP8ENxeDhELXonapLZy/SKih5Mp3oE3agD/+uuvY//+/Zg0aRLat2+Pbdu24fz581i7di3CwsIaPC4yMhJubm4YNGgQvLy8kJKSgo0bN6JDhw7YsmULZLJbDxbauHEj3n33XcTExKBPnz44deoUduzYgblz52LKlClNHjMD+OZRUaXGkTPXcPBUJkpvqtHewx5DI/3QQ+EKC7HY2MMjombU1q5fRPRwYQB/m3PnzmHs2LGYP38+nn/+eQCAUqlEbGws3NzcsG7dugaPTUxMRGRkpF7b9u3bMXfuXHzwwQcYPXo0AKCqqgp9+/ZFjx498Pnnn+v2nTNnDg4fPoxjx47Ve8f+bhjANy+1phonzl/H3pOZyC28iXaOVhgS4YeoEE/IpFy5hqgtaKvXLyJ6OJhiAG+0W5179+6FRCLB2LFjdW0ymQxjxozB6dOnkZeX1+CxdwbvADBo0CAAQFpamq4tMTERxcXFmDBhgt6+cXFxqKiowE8//fSgb4MekMTSAn27e2PRi5GYOToEjnZSrDtwEX9beQLbf05H6U2VsYdIREREZFKMVsSalJQEf39/2Nra6rV369atZvWSpCS4ubk1ur8bN24AAORyua7twoULAICuXbvq7dulSxeIxWJcuHABw4cPv9+3QM1ILBIhPMgV4UGuuJRVjD2/ZiDhv1ewJzEDUd08MaSnL9zkNsYeJhEREZHRGS2Az8/Ph7u7u0G7q6srANz1Dnx9Vq1aBQsLC0RHR+udQyqVwsnJSW/furamnoNaRycfJ3Qa44TsGxXYdzIDP5/NxtHfr6GHwg1DI/3g7+lg7CESERERGY3RAviqqipIJIYP9akrQFUqlY3ua+fOnYiPj8e0adPg5+d3z3PUnacp56hzt3yklubq2rR8fXPn6mqP0M4eKCytws6f07HnxGWcSs5DSEA7jO4fiB7Bbly5hshMPGzXLyJqW0ztGma0AN7KygpqtdqgvS6ovn0lmbs5deoUFixYgH79+mH27NkG51Cp6s+hViqVjT7H7VjEahzDInzRP9QTP53Nxv7fMvH+V7/C29UWMRF+iHzEHZYWXLmGyFQ97NcvIjJvLGK9jaura70pLPn5+QDQqPz35ORkvPzyy1AoFFi2bBksLPRXLXF1dYVarUZxcbFeu0qlQnFxcZNy7Mn4rGWWGBLhh39P742psZ0BAKt3JWHuf37B3sQMVCo1Rh4hERERUctrlgBeo9Fg37592LRpky4Av5fg4GBcvnwZFRUVeu1nz57Vbb+bjIwMTJ06Fc7Ozvjiiy9gY2NY4Ni5c02Qd/78eb328+fPQ6vV6raTebG0EOOxrp5YOCUCfx0bCne5NTYdScWcz09g89FUFJU1PTWKiIiIyFw0OYBfvHgxnn76ad1rQRAwefJk/PWvf8U777yDESNGICMj4579xMTEQK1WY/Pmzbo2lUqFrVu3Ijw8XFfgmp2drbc0JFBzl37KlCkQiURYvXo1nJ2d6z1Hr1694OTkhPXr1+u1b9iwATY2NnjiiSca/b7J9IhEInQLcMGbE8Lx9nOPoqu/M/YmZuDNlSewZncSsm9U3LsTIiIiIjNj8d57773XlAP+9a9/ITIyEo8//jgA4PDhw1i1ahWmTp2KuLg4/PTTTygqKsKAAQPu2o+HhwdSU1Oxbt06VFRUICsrCx988AHS0tKwZMkSeHl5AQBmzJiBxYsXY9asWbpjJ0yYgPT0dDz77LNQqVRISUnR/amsrISnpycAwNLSEjY2Nvjmm2+QmpqKRI4nkAAAIABJREFU8vJyfPfdd9ixYwdmz56Nxx57rClvHQBQWamCMR59ZWsrw02uid4gub0MPYPd0LuLOzRaAb+ev44Dp7Jw9XoZ5PYyODvIWPBKZCS8fhGROTPGNUwkEsHGRtrg9iYXsV6/fh3t27fXvT5y5Ah8fHwwZ84cAMClS5ewc+fORvW1ePFifPzxx9ixYwdKSkqgUCjw5ZdfokePHnc9Ljk5GQDw1VdfGWwbNWoUwsLCdK/j4uIgkUiwZs0aHDp0CJ6enliwYAEmTZrUqDGSeXGT22BitAIjo/xx+HQWDp+5hn+tO4MALwfERLZHWKd2EIsZyBMREZH5anIAr1arYWl567DExES9O9m+vr6NzoOXyWSYO3cu5s6d2+A+a9euNWhLSUlpwoiBcePGYdy4cU06hsybg40UTz3eEUN7tcfxcznYdzIDn237A+7ONhgS4Ys+XT0gsbS4d0dEREREJqbJOfAeHh74/fffAdTcbc/MzETPnj112wsKCuotKCUyBpnEAgN7+OCDab0wfWQXWEkt8N3eFPxt5S/YeeIKyisNlzIlIiIiMmVNvgM/fPhwfP755ygsLMSlS5dgZ2eHvn376rYnJSXpPUyJyBRYiMWI6OyOnsFuSM4oxp7Eq9j2Uzp2/3IVj4d6IrqnL9o5Wht7mERERET31OQAftq0acjJycGhQ4dgZ2eHf//733BwqHm0fVlZGQ4fPoznn3++ucdJ1CxEIhE6t5ejc3s5MvPKsTcxA0fOXMPh09cQ0dkNMZF+8HM3raetEREREd1OJAjNt6aKVqtFRUUFrKysIJFImqtbk8InsbY9haVV2P9bJo6dzYZSVY0u/s6IifTDI+3lXLmGqBnw+kVE5swUn8TarAG8SqWCVNrwkjdtAQP4tutmlRpHfr+Gg6eyUFKhgp+7HYZGtsejwa6wEBvtocVEZo/XLyIyZ6YYwDc5Kjl27Bg+/fRTvbZ169YhPDwc3bt3xxtvvAG1moWBZH5srCQY3rsDFr/8GJ4fGgyVWosvEv7E/C9+xYFTmVCqqo09RCIiIqKm58CvXr0aLi4uutdpaWn45z//CV9fX/j4+GD37t0ICQlhHjyZLYmlGE+EeiGqmyfOpt7AnsQMbDh4CQnHL2NAuA8G9vCBg23b/qaJiIiITFeTA/j09HS9VWd2794NmUyG+Ph42NnZ4Y033sD27dsZwJPZE4tECOvkirBOrkjNKsGexKv48cQV7D2ZgT4hnhgS4Qt3OZdMJSIiotbV5AC+pKQEcrlc9/rEiRPo1asX7Oxq8nQiIiJw7Nix5hshkQkI9HHELJ9uyCmowL6TmTh+LhvHfr+GcIUrYiL9EODlaOwhEhER0UOiyQG8XC5HdnY2AKC8vBx//PEHXn/9dd12jUaD6mrmClPb5Olii+eHBmPU4/44ePr/27v3+KjqO2/gn7lPMjO5z0xuMyEESCDkxiUhgoogNSAWpbLUG9W2VKvuVrrtS12f7dNu1+KjWKVueVS0y8KDi4UNpkUJEaECogkQSLgEkBAzuWeSkPtlJpl5/hhywjQBGUg4M5PP+x9f+c05c37Hlh8ff/me76nG/uIaHDtnxRRTCHKyzEhNCIeUnWuIiIhoDHkc4NPT07Ft2zZMmjQJBw4cwMDAAO644w7h88rKShgMhlGdJJG3Cdaq8L07E7BkThwOltSi4GgV/rCjFNERGuRkmjEn2Qi5jJ1riIiIaPR53EbywoULWLVqFVpaWgAADzzwANauXQsAcDqdWLhwIbKysoQxf8M2kjSS/gEHjpQ1YnehBdXWToRolVg024Q702IQqPb4v5OJ/ArXLyLyZd7YRvKG+sC3traiuLgYOp0Os2fPFsbb2trw0UcfISsrC0lJSTc2Yy/HAE/X4nQ6cbqiBbsLLSirvIQAlQx3psdg0SwTQnUqsadHJAquX0Tky/wmwI9nDPB0vSrrO7C7sBJHzjZCKpFgTrIROZlmxOiv/geSyB9x/SIiX+ZXAd5iseCzzz5DVVUVAMBkMmHhwoUwm803NlMfwQBPnrK29qCgqAoHS2th63cgNSEci7PMmGIKgYQPvNI4wPWLiHyZ3wT4N998Exs3bhzWbUYqleLJJ5/Ez372M89n6iMY4OlGdXTbsL+4BnuPVaOzx474qCAszjJjxhQ9pFIGefJfXL+IyJd5Y4D3+Om6HTt24O2330ZGRgZ+/OMfY/LkyQCAr7/+Gu+//z7efvttmEwmLF++/MZnTeSHdIFKfHdePO7JMuPwyTrkF1mw4aNTMIQG4J5MM+ZOj4RSIRN7mkREROTlPN6BX758ORQKBbZu3Qq53D3/9/f345FHHoHdbkdubu6oTtRbcAeeRovD4UTxeSt2F1aioq4DukAFFs6MxYIZsdAGKMSeHtGo4fpFRL7MG3fgPW5UXV5ejiVLlgwL7wAgl8uxZMkSlJeXe/q1ROOOVCrBrCQD/teqWXj+4QzERwXho4MV+MWGL/DBp+fR1Noj9hSJiIjIC3lcQqNQKNDd3X3Vz7u6uqBQcPeQ6HpJJBIkmkORaA5FtbUTewot2H+8BvuKazB7qgE5mWbERerEniYRERF5CY934FNSUvDhhx+iqalp2GfNzc3485//jLS0tFGZHNF4E6vX4kdLp+H/PJWN78w2oeRCE36z6QjWbTuOUxXNYNdXIiIi8rgG/siRI3j88ceh0Wjwve99D5MmTQLgekNrbm4uurq6sGnTJsyaNWtMJiw21sDTrdTd24/PT9Sg4GgV2jptMBm0yMkyY3aSAXKZx//9TSQKrl9E5Mu8sQb+htpI7tu3D7/97W9RV1fnNh4dHY1f/epXmD9/vscT9RUM8CQGe78DX52pR36hBXXN3QgPUuE7s824PS0KaqXHlXBEtxTXLyLyZX4T4AHA4XDg1KlTqK6uBuB6kVNycjL+/Oc/Y/Pmzfjkk09ubMZejgGexORwOlFa3oz8rypxvroNGrUcd82IwcKZJgRrlGJPj2hEXL+IyJd5Y4C/4a07qVSK1NRUpKamuo1funQJFRUVN/q1RHQNUokE6ZMikD4pAuU1bcgvtODjw5XIL6zC3JRI3JNpRmRYoNjTJCIiojHE370T+aiEmGA8szwF9S3dKCiy4NDJehw4UYuMKXoszjIjISZY7CkSERHRGGCAJ/JxkWGBWJWThGW3T8Rnx6qxv7gaxeetmBwbjMVZcUidFA6pRCL2NImIiGiUMMAT+YlgjRLL75iIJXPMOFhah4IiC/7wP6WICg9ETqYZc5IjoZCzcw0REZGvY4An8jNqpRyLZplwV0YMjp5tRH6hBf+5+yxyD17EolkmzE+PRqCaL1sjIiLyVdcV4P/zP//zur+wuLj4hidDRKNHLpNiTnIksqYZceabS9hdWIkdfyvHrsPf4M70aCyaZUJYkFrsaRIREZGHrquNZFJSkmdfKpGgrKzshiflzdhGknxZZX0H8ossOFLWCIkEyJpmRE6mGbGGq7eqIrpZXL+IyJd5YxvJ6wrwRUVFHl84MzPT43N8AQM8+YOm1h4UHKnCgdJa2OwOpEwMx+IsMxLNIZDwgVcaZVy/iMiX+WyApyEM8ORPOnvs2F9cjb3HqtHRbUd8lA45WXGYOUUPqZRBnkYH1y8i8mUM8H6AAZ78kc0+gMOn6rGnyIKGSz0whATgO5kmzE2JgkohE3t65OO4fhGRL2OA9wMM8OTPHA4njn9txe5CCy7WtkMboMDCmbFYMCMGukCl2NMjH8X1i4h8mTcGeLaRJCKBVCrBzEQDZkzR4+vqNuz+qhJ5hyqw+6tKzEuNwncyzTCEBIg9TSIionGNAZ6IhpFIJJhiCsEUUwhqmrqwp9CCz0/UYv/xGsxOMiAny4wJkUFiT5OIiGhcYgmNh1hCQ+PVpY4+7D1ahb+dqEFP3wCmxoUiJ8uM6fFh7FxD18T1i4h8mTeW0DDAe4gBnsa77t5+HCipRcERC1o7bYjVa5CTZUbmVCPkMqnY0yMvxPWLiHwZA7wfYIAncukfcKDwTAPyCy2oaepCWJAK35llwu1p0QhQsTqPhnD9IiJfxgDvBxjgidw5nE6cLG9GfqEF56paEaiS464ZMbh7ZiyCtSqxp0degOsXEfkybwzw3CYjopsilUiQNikCaZMicLG2HfmFlfjky0rsKbLgtumRuCfTjKhwjdjTJCIi8hsM8EQ0aiZGB+HpB1LQcKkbBUVVOHSyDgdL6pA+OQI5WWZMjg0Re4pEREQ+jyU0HmIJDdH1a++y4bNj1dhXXI2u3n5MignG4iwz0iZHQMrONeMG1y8i8mXeWEIjaoC32WxYv3498vLy0N7ejqSkJKxZswbZ2dnXPK+0tBS5ubkoLS3F+fPnYbfbce7cuWHHVVdXY+HChSN+x8aNG3HHHXd4PGcGeCLP9dkGcLC0FgVHqtDU1ovIsEDkZJmRnWyEQi4Te3o0xrh+EZEv88YAL2oJzQsvvICCggKsWrUKcXFx2LlzJ1avXo0tW7YgIyPjqud9/vnn2L59OxITE2EymXDx4sVrXue73/0u5s2b5zaWlJQ0KvdARN9OpZTh7lkm3DUjBkfPWpFfaMGm3WeRe+AiFs2KxfyMGGjUCrGnSURE5BNE24EvLS3FihUr8OKLL+Lxxx8HAPT19WHp0qUwGAzYunXrVc9tamqCVquFWq3Gyy+/jM2bN19zB/7Ka9ws7sAT3Tyn04myykvIL7TgVEULVEoZ7kyLxqJZJoQHq8WeHo0yrl9E5Mu4A3+F/Px8KBQKrFixQhhTqVR48MEH8cYbb6CxsREGg2HEcyMiIjy+Xnd3N+RyOZRK5Q3PmYhGh0QiwbQJYZg2IQyWhg7kF1mw92g1PjtWjcypBuRkxcFkuPrCRURENJ6J9trEsrIyxMfHQ6Nxby+Xmprq2p0rKxu1a61fvx4ZGRlITU3FypUrceTIkVH7biK6OWajDj+5LxmvPDUHC2bEovh8E/73n4rw+w9PoOybFvA5eyIiInei7cBbrVYYjcZh43q9HgDQ2Nh409eQSqWYN28eFi1aBIPBgMrKSrz//vt44oknsGnTJsyaNcvj77zWrzPGml6vE+3aRGNNr9dh6iQDfrhsOj45/A3+evAiXtt2ApNig7F8/mTclhoFmUy0PQe6SVy/iMiXedsaJlqA7+3thUIx/KE1lcr15sa+vr6bvkZ0dDTef/99t7ElS5bg3nvvxbp167Bt2zaPv5M18ERj7660KMxLNuDwqXrkF1Xh1f93FBHBatyTaca8lCiolOxc40u4fhGRL/PGGnjRtrPUajXsdvuw8cHgPhjkR5vRaMS9996LkpIS9PT0jMk1iOjmKeQy3Jkeg5dXZ+HZ5SkI1iqx9dPz+OX/PYyPDl5Ee7dN7CkSERGJQrQdeL1eP2KZjNVqBYCrPsA6GqKiouBwONDe3o6AgIAxuw4R3TypRIIZU/SYMUWPr6tbsfsrC/7yxTfYXWjBvJQo3JNpgiE0UOxpEhER3TKiBfikpCRs2bIFXV1dbg+ylpSUCJ+PlaqqKshkMgQHB4/ZNYho9E2ODcHkB0NQ29SFPUUWHCytxd9O1GBmogGLs8yIjwoSe4pERERjTrQSmpycHNjtdmzfvl0Ys9lsyM3NxYwZM4QHXGtra1FeXn5D12hpaRk2VllZiY8//hizZs2CWs1+00S+KDpCgyeWTMWrP70Ni7PicLqiBb/9r6N49YNilJY3sXMNERH5NdF24NPS0pCTk4N169bBarXCbDZj586dqK2txdq1a4Xjnn/+eRQVFbm9qKmmpgZ5eXkAgJMnTwIANmzYAMC1c79gwQIAwGuvvYaqqirMmTMHBoMBFotFeHD1+eefvyX3SURjJ0SrwoPzE3BvdhwOlNSi4EgV3txeihi9BjmZZmRNM0LOzjVERORnRHsTK+B6YPXNN9/EX//6V7S1tSExMRE///nPcdtttwnHPPbYY8MCfGFhIVatWjXidz7wwAN45ZVXAAC7du3Ctm3bcOHCBXR0dCAoKAiZmZl49tlnMXny5BuaM7vQEHmv/gEHisoasLvQghprF0J1KiyaZcKd6dEIUIm2XzHucf0iIl/mjV1oRA3wvogBnsj7OZ1OnLzYgvzCSpy1tCJAJcP8jBjcPdOEUN3YdLiiq+P6RUS+zBsDPLekiMjvSCQSpCaEIzUhHBV17cgvtCC/0IKCoipkT49ETqYZ0RGab/8iIiIiL8QAT0R+LT4qCD+9fzoaL3Vjz5EqfFFah0OldUifFIGcLDMmxwZDIpGIPU0iIqLrxhIaD7GEhsi3tXfbsO9YNfYV16Czx46E6CDkZMUhY3IEpFIG+bHA9YuIfJk3ltAwwHuIAZ7IP/TZB3CotA57iixoauuFMTQA92SZMXd6JBRymdjT8ytcv4jIlzHA+wEGeCL/MuBw4Ng5K3YXWlBZ34GgQAUWzjLhrowYaAMUYk/PL3D9IiJfxgDvBxjgifyT0+nEWUsrdhdW4tTFFqgUMtyeFoXvzDYhIjhA7On5NK5fROTLvDHA8yFWIiK4OtdMjQvF1LhQVDV2Ir/Qgv3FNdh3rAaZUw3IyTLDbNSJPU0iIiLuwHuKO/BE40dLey8KjlTh85Ja9NkGkBwfhpwsM6bFhbJzjQe4fhGRL/PGHXgGeA8xwBONP929duw/XoO9R6vR1mWD2ahFTpYZs5MMkEmlYk/P63H9IiJfxgDvBxjgicYve78DX56uR36hBfUt3YgIVmPRbBPuSI2GSsnONVfD9YuIfBkDvB9ggCcih9OJkgtN2F1owYXqNmjUctw1IxZ3z4xFkEYp9vS8DtcvIvJl3hjg+RArEZGHpBIJMibrkTFZjwvVbdhdWImPD3+DPUUWzE2Jwj2ZJhhDA8WeJhER+SkGeCKimzApNhj/GJuKuuYu7CmqwqHSWnx+vAYzEvXIyTIjITpY7CkSEZGfYQmNh1hCQ0TX0tbZh73HqrG/uAbdff2YYgpBTpYZqQnhkI7TzjVcv4jIl3ljCQ0DvIcY4InoevT09eNgaR0KjljQ0t6H6AgNcjLNmJNshFw2vjrXcP0iIl/GAO8HGOCJyBP9Aw4cKWvE7kILqq2dCNEqsWi2CXemxSBQPT6qGLl+EZEvY4D3AwzwRHQjnE4nTle0YHehBWWVl6BWyjA/IwaLZpkQqlOJPb0xxfWLiHyZNwb48bH9Q0QkMolEgukTwzF9Yjgq6zuwu7ASe4os+PRIFeYkG5GTaUaM/uqLNRER0SDuwHuIO/BENFqsrT0oKKrCwdJa2PodSE0Ix+IsM6aYQiDxowdeuX4RkS/zxh14BngPMcAT0Wjr6LZhf3EN9h6rRmePHfFRQVicZcaMKXpIpb4f5Ll+EZEvY4D3AwzwRDRW+uwDOHyyDvlFFlhbe2EIDcA9mWbMnR4JpUIm9vRuGNcvIvJlDPB+gAGeiMaaw+FE8XkrdhdWoqKuA7pABRbOjMWCGbHQBijEnp7HuH4RkS9jgPcDDPBEdKs4nU6cr2rF7kILSsuboVRIcXtqNO6ZbUJESIDY07tuXL+IyJd5Y4BnFxoiIi8lkUiQaA5FojkU1dZO7Cm04G/Ha7C/uAazkvRYnBWHuEid2NMkIqJbjDvwHuIOPBGJqaW9F3uPVuNvJ2rQaxvAtAmhyMkyI3lCmNd2ruH6RUS+zBt34BngPcQAT0TeoLu3H5+fqEHB0Sq0ddpgMmiRk2XG7CQD5DKp2NNzw/WLiHwZA7wfYIAnIm9i73fgqzP1yC+0oK65G+FBKiyabcYdaVFQK72jSpLrFxH5MgZ4P8AAT0TeyOF0orS8GflfVeJ8dRs0ajnmZ8Tg7lkmBGuUos6N6xcR+TJvDPDesT1DREQ3RSqRIH1SBNInRaC8pg35hRZ88mUl9hRVYW5KJO7JNCMyLFDsaRIR0ShggCci8jMJMcF4ZnkK6lu6UVBkwaGT9ThwohYZU/TIyTJjUkyw2FMkIqKbwBIaD7GEhoh8TVuXDZ8dq8b+4mp09fZjcmwwFmfFIXVSOKS3oHMN1y8i8mXeWELDAO8hBngi8lW9tn4cLK1DQZEFze19iAoPRE6mGXOSI6GQj13nGq5fROTLGOD9AAM8Efm6/gEHjp5tRH6hBZbGTgRrlVg0y4T56dEIVCtG/Xpcv4jIlzHA+wEGeCLyF06nE2e+uYT8wkqc/uYS1EoZ7kyPxqJZJoQFqUftOly/iMiXeWOA50OsRETjlEQiQXJ8GJLjw1BZ34H8Igs+PVKNvUerkTXNiJxMM2INV/8LhIiIxMEdeA9xB56I/FlTaw8KjlThQGktbHYHUiaGY3GWGYnmEEhu8IFXrl9E5Mu8cQeeAd5DDPBENB509tixv7gae49Vo6PbjgmROiyeE4eZU/SQSj0L8ly/iMiXMcD7AQZ4IhpPbPYBHD5Vjz1FFjRc6oE+RI17Ms2YmxIFlUJ2Xd/B9YuIfBkDvB9ggCei8cjhcOL411bsLrTgYm07tAEKLJwZiwUzYqALVF7zXK5fROTLvDHA8yFWIiL6VlKpBDMTDZgxRY+vq9uw+6tK5B2qwO6vKjEvNQrfyTTDEBIg9jSJiMYFBngiIrpuEokEU0whmGIKQU1TF/YUWvD5iVrsP16DWYkG5GSZER8VJPY0iYj8GktoPMQSGiIid5c6+rD3aBX+dqIGPX0DSDKHYPGcOHR027DzwEW0tPchLEiF5XcmIDs5UuzpEhF5xBtLaBjgPcQAT0Q0su7efhwoqUXBEQtaO22QALhytVTKpfjB4iSGeCLyKd4Y4KW3cC7D2Gw2vPbaa5g3bx5SU1PxD//wD/jyyy+/9bzS0lL8+te/xvLlyzF9+nQkJiZe9ViHw4GNGzdiwYIFSElJwX333YdPPvlkNG+DiIgABKrlyMky49Wf3gZNgBx/v9Vh63fgv/d+jbrmLji4d0REdMNErYF/4YUXUFBQgFWrViEuLg47d+7E6tWrsWXLFmRkZFz1vM8//xzbt29HYmIiTCYTLl68eNVj33jjDbz77rtYuXIlpk+fjs8++wxr1qyBVCpFTk7OWNwWEdG4JpdJ0dXTP+JnnT12vLSxECqFDLEGDcxGHcwGLcxGHWL1Gijk19eakohoPBOthKa0tBQrVqzAiy++iMcffxwA0NfXh6VLl8JgMGDr1q1XPbepqQlarRZqtRovv/wyNm/ejHPnzg07rqGhAQsXLsRDDz2El156CQDgdDrx6KOPoq6uDnv37oVU6tkvIVhCQ0T07X654Qs0t/cNGw/WKLH8zomoauiEpaEDlsZO9NoGAABSiQRREYFCoDcbtDAZddAGKG719ImIBN5YQiPaDnx+fj4UCgVWrFghjKlUKjz44IN444030NjYCIPBMOK5ERER13WNvXv3wm634+GHHxbGJBIJHnroIfzzP/8zSktLkZ6efnM3QkREwyy/MwH/tfssbP0OYUwpl+IfFkxyq4F3OJ1oau2BpaETlsYOWBo6UVZ5CV+ebhCOCQ9SwWzUwWTQIs6og8moRXiQGhKJZ2+EJSLyF6IF+LKyMsTHx0Oj0biNp6amwul0oqys7KoB3pNraLVaxMfHD7sGAJw5c4YBnohoDAyG9NzPy6/ZhUYqkcAQGghDaCBmJQ2t+e1dNlgaO1DV0InKhg5UNXbixNdNQl29Ri2HaXCn3uj6Z1R4IGQe/laViMgXiRbgrVYrjEbjsHG9Xg8AaGxsHJVrjLRbP5rXICKikWUnRyI7OfKGfv0cpFFienw4pseHC2N9tgFUW4dKbywNHdh/vAb2y7v8cpkUsXqNEOjNBh1iDRqolXzlCRH5F9FWtd7eXigUw+saVSoVAFc9/GhcQ6kc/orvm7nGteqRxpperxPt2kREN2O01q/YmBDMueLngQEHqq2dqKhpQ3lNGypq23D86yYcKKkDAEgkQHSEBhNjQhAfHYSEmBDExwQhVKcelfkQ0fjgbRlMtACvVqtht9uHjQ+G6sGQfbPXsNlso3oNPsRKROSZsV6/AmUSJJtDkGwOAeBqVnCpo89VenO5BKesohkHT9QI5wRrlTAbhspvzEYt9CEBkLKunoj+Dh9ivYJerx+xhMVqtQLATde/D17j6NGjY3oNIiLyLhKJBGFBaoQFqZExWS+Md/Xa3brfWBo6cLqiRehJr1bKXHX1VwT76AgNFHLW1RORdxEtwCclJWHLli3o6upye5C1pKRE+PxmTZ06Fdu3b0dFRYXbg6yD15g6depNX4OIiHyDRq1AUlwokuJChTF7/wBqmrpcXXAuB/tDp+rQV+xqbSmTShAVrkGc0dXSMs6ohcmgRaCarS2JSDyiBficnBz86U9/wvbt24U+8DabDbm5uZgxY4bwgGttbS16enqQkJDg8TUWLlyItWvX4oMPPnDrA79t2zZER0cjLS1t1O6HiIh8j0Iuw4TIIEyIDBLGHE4nrJd6hO43lQ0dOFXRgi9O1QvHRASrhzrgXN6xD9Wp2NqSiG4J0QJ8WloacnJysG7dOlitVpjNZuzcuRO1tbVYu3atcNzzzz+PoqIitxc11dTUIC8vDwBw8uRJAMCGDRsAuHbuFyxYAACIjIzEqlWr8Kc//Ql9fX1ISUnB3r17cfToUbzxxhsev8SJiIj8n1QigTEsEMawQGROHeqW1tbZJ5TeDO7YF5+3Cp9rAxRugd5s1CEyLBBSKUM9EY0uUXtrvfrqq3jzzTeRl5eHtrY2JCYm4t1338XMmTOveV51dTXWr1/vNjb48wMPPCAEeAD4xS9+geDgYHz44YfIzc1FfHw8Xn/9dSxZsmT0b4iIiPxWsFaFFK0KKROHWlv29PVfbm05VIKz91gV+gdcdfVKuRSxBq3wVlmzUYtYvRYqhUys2yAiPyBxOp23vqWKD2MXGiIiz4y39at/wIH65m6hBGdwx767rx+Aq7VlZFjgsBIcXeDwtsdEJD52oSEiIvJzcplr1z3WMPSXr9PpRHOEwnDrAAAXfklEQVRbr1sJztfVrSg80yAcE6pTCTv1gw/N6oPVrKsnomEY4ImIiMaYRCJBREgAIkICMGPKUGvLzh77UE19o6tvfenFZgz+bjxAJXe1tjRqEWfUwWTQIjpCA7mMz3ARjWcM8ERERCLRBigwbUIYpk0IE8Zsdldry8EXUVkaOnCgpBY2uwMAIJdJEB2hcZXgGFwPy5oMWgSo+Fc60XjBP+1EREReRKmQIT4qCPFRV7S2dDjRcKnb7WHZkgtNOFRaJxxjCA0QAr3ZqIXJoEOIVskSHCI/xABPRETk5aSXXygVFa5B1jRXa0un04nWTpvbm2UtDZ04em6otWVQoELofjP4sKwxlK0tiXwdAzwREZEPkkgkCNWpEKpTIW1ShDDe3etqbXllCU5BURUGLndQUylkiDVo3PrVx+o1UMjZ2pLIVzDAExER+ZFAtRxTTCGYYgoRxvoHHKht6nIrwfnqTD32Hx8A4Hp5VVRE4FAJzuVuONoAhVi3QUTXwABPRETk5+Qy6eXaeB2AKACAw+lEU1svLPVDJThnLa348vRQa8vwIJXwkGycUQeTUYvwILa2JBIbAzwREdE4JJVIYAgJgCEkALOSDMJ4e5dNeAHV4MuoTnzdhMFXGGrUg60th0pwosIDIZOytSXRrcIAT0RERIIgjRLJ8WFIjh9qbdlnG0C1tdPtYdn9x2tg7x9sbSlFrF4jBHqzQYdYgwZqJWMG0VjgnywiIiK6JpVShoSYYCTEBAtjAw4H6lt6YLn8sGxlQweOnbPiQImrtaUEgCEs0PVWWaEER4dgjVKkuyDyHwzwRERE5DGZVIqYCA1iIjTITnaNOZ1OXOroc3tY9mJtO4rKGoXzgrVKtw44ZqMW+pAASFlXT3TdGOCJiIhoVEgkEoQFqREWpEb65KHWll29dqGl5WAZzumKFjicrsp6tVLmqqu/IthHR2igkLOunmgkDPBEREQ0pjRqBZLiQpEUFyqM2fsHUNvULfSrr2zswKFTdegrdrW2lF1+eVWc0dXScrAUJ1DN1pZEDPBERER0yynkMsRF6hAXqRPGHE4nrJd63B6WPVXRgi9O1QvHRASrhzrgXN6xD9Wp2NqSxhUGeCIiIvIKUokExrBAGMMCMfuK1pZtnX1uod7S2Inj561Ca0ttgMIt0JuMOkSFBUIqZagn/8QAT0RERF4tWKtCilaFlInhwlhPXz9qrF2obOgQauv3HqtC/4Ar1ivlUsTotUIJjtmoRaxeC5VCJtZtEI0aBngiIiLyOQEqOSbFBmNS7FBry/4BB+qbu4UXUFkaOlBU1oi/nagFAEgkQGRY4LASHF0gW1uSb2GAJyIiIr8gl0kRa9Ai1qAVxpxOJ5rbet1KcC5Ut6LwTINwTKhOBbPhiodljTrog9WsqyevxQBPREREfksikSAiJAARIQGYMUUvjHf22FHV0IHKhk5UNbqC/cmLQ60tA1QymAzuO/XRERrIZWxtSeJjgCciIqJxRxugwNQJYZg6IUwYs9kHUNPUJbS2tDR04EBJLWx2BwBALpMgOkLj1q/eZNAiQMU4RbcW/x9HREREBECpkCE+KgjxUUHCmMPhRMOlbre3y5aUN+HQyTrhGENIgND9xtWvXocQrZIlODRmGOCJiIiIrkJ6+YVSUeEaZE0zAnDV1bd22oRAX3W5tv7oOatwXlCgQuh+M7hjbwxla0saHQzwRERERB6QSCQI1akQqlMhbVKEMN7T1y90v3H1q+9AQVEVBhyuunqVQoZYg3sJTqxeA4WcrS3JMwzwRERERKMgQCXHFFMIpphChLH+AQdqm7rcSnC+OlOP/ccHALheXhUVHugqwTEMdcHRBijEug3yAQzwRERERGNELpNe7juvAxAFAHA4nWhq64WlvkNob3nW0oovTw+1tgwPUg11wblcihMexNaW5MIAT0RERHQLSSUSGEICYAgJwKwkgzDe3m0Tut8MBvuSC01wXv5co5bDZNC6vYgqMjyQrS3HIQZ4IiIiIi8QFKhEcnwYkuOHWlv22QZQbe10exHV/uM1sPcPtraUIkavEbrfxBl1iDVooFYy4vkz/q9LRERE5KVUShkSYoKREBMsjA04HKhv6YHlcr/6yoYOHDtnxYESV2tLCQBDWCDMBu0VJTg6BGuUIt0FjTYGeCIiIiIfIpNKEROhQUyEBtnJrjGn04lLHX1uD8tW1LXjyNlG4bxgjXKo/Maog9mghT40AFLW1fscBngiIiIiHyeRSBAWpEZYkBrpk4daW3b32i+3tBwqwTnzTctQa0ulDCaDFnEGHUxGLeKMOkRHaKCQs67emzHAExEREfmpQLUCSXGhSIoLFcbs/QOobepG5WAJTmMHDp2qQ1+xq7Wl7PLLq67cqTcbtQhUs7Wlt2CAJyIiIhpHFHIZ4iJ1iIvUCWMOpxPWSz1uO/WnK1pw+FS9cExEsPqKQO8qxQnVqdjaUgQM8ERERETjnFQigTEsEMawQMy+orVlW2efW6i3NHbi+Hmr0NpSG6BwleAYXSU4ZqMOkWEBkElZgjOWGOCJiIiIaETBWhVStCqkTAwXxnpt/ahu7HKV4DR2oLKhE3uPVaN/wNXaUimXIkavdSvBiTVooVLIxLoNv8MAT0RERETXTa2UY1JsMCbFDrW27B9woL65G5bGDqETzpGyRnx+ohYAIJEAkWGBbiU4JqMWQYFsbXkjGOCJiIiI6KbIZVLEXt5pv226a8zpdKK5vXeotWVDJy5Ut6LwTINwXqhONfR2WYMW5kgd9MFq1tV/CwZ4IiIiIhp1EokEEcEBiAgOwIwpemG8s8eOqgZX6U3V5R37Uxdb4HC6KusDVDKYDO4Py0ZHaCCXsa5+EAM8EREREd0y2gAFpk4Iw9QJYcKYzT6AmqauKx6W7cCB0lrY7K66eplUgpgIjVB6E2fUwWTQIkA1PqPs+LxrIiIiIvIaSoUM8VFBiI8KEsYcDicaLnULgd7S0ImS8iYcOlknHGMICYDZqIXJqEOcUQuTQYcQrdLvS3AY4ImIiIjI60gvv1AqKlyDrGlGAK66+tZOm9D9puryjv3Rc1bhvKBABUyXS2/MBtc/jaGBkEr9J9QzwBMRERGRT5BIJAjVqRCqUyE1IUIY7+nrR5Vbv/oOFBRVYcDhqqtXKqQw6bVuJTgxERoor9Ha8svT9cj9vBwt7X0IC1Jh+Z0JyE6OHPN7vB4Sp9Pp/PbDaFBzcyccjlv/r0yv18Fq7bjl1yUiullcv4hIDP0DDtQ2dbmV4FQ1dqCnbwCA6+VVUeGBrhdQXd6pNxt10AYo8OXpevzX7rOw9TuE71PKpfjB4qRbEuKlUgnCw7VX/Zw78ERERETkd+Qy6eUuNjoAUQBcJTjWtt6hLjgNHThnacVXp4daW4YHqdDebYf9ivAOALZ+B3I/L/eKXXhRA7zNZsP69euRl5eH9vZ2JCUlYc2aNcjOzv7WcxsaGvC73/0OX3zxBRwOB+bMmYMXX3wRJpPJ7bjExMQRz//1r3+Nhx56aFTug4iIiIi8n0QigSEkAIaQAMxMNAjj7d02VF2xU39lr/orNbf33aqpXpOoAf6FF15AQUEBVq1ahbi4OOzcuROrV6/Gli1bkJGRcdXzurq6sGrVKnR1deGpp56CXC7Hpk2bsGrVKnz00UcIDg52O37evHn47ne/6zaWlpY2JvdERERERL4lKFCJ5PgwJMe7WlteqG4dMayHB6lu9dRGJFqALy0txccff4wXX3wRjz/+OADg/vvvx9KlS7Fu3Tps3br1qud+8MEHqKysRG5uLqZNmwYAuP3223Hfffdh06ZN+NnPfuZ2/MSJE7Fs2bIxuxciIiIi8h/L70wYsQZ++Z0JIs5qiGivtMrPz4dCocCKFSuEMZVKhQcffBDHjh1DY2PjVc/ds2cP0tPThfAOAAkJCcjOzsbu3btHPKe3txd9fd7xaw8iIiIi8l7ZyZH4weIkhAepIIFr5/1WPcB6PUTbgS8rK0N8fDw0Go3beGpqKpxOJ8rKymAwGIad53A4cO7cOaxcuXLYZykpKfjiiy/Q09ODgIAAYXzHjh3YsmULnE4npkyZgn/6p3/CokWLRv+miIiIiMgvZCdHIjs50is7aYm2A2+1WkcM6Hq9HgCuugPf2toKm80mHPf35zqdTlitQ838MzIysGbNGmzYsAG/+tWvYLPZ8Oyzz2LXrl2jdCdERERERLeOaDvwvb29UCgUw8ZVKtfDAVcrdxkcVyqVVz23t7dXGNu2bZvbMQ888ACWLl2K1157Dffee6/Hr9q9Vk/OsabX60S7NhHRzeD6RUS+zNvWMNECvFqtht1uHzY+GNAHw/jfGxy32WxXPVetVl/1uoGBgfj+97+P119/HRcvXkRCgmcPI/BFTkREnuH6RUS+TIw17Nte5CRaCY1erx+xTGaw/GWk8hoACAkJgVKpdCuTufJciUQyYnnNlaKiXM3829raPJ02EREREZGoRAvwSUlJqKioQFdXl9t4SUmJ8PlIpFIppkyZglOnTg37rLS0FHFxcW4PsI6kqqoKABAWFnYjUyciIiIiEo1oAT4nJwd2ux3bt28Xxmw2G3JzczFjxgwYjUYAQG1tLcrLy93Oveeee3DixAmcOXNGGLt48SK++uor5OTkCGMtLS3Drnvp0iV88MEHiI2NxYQJE0b5roiIiIiIxpZoNfBpaWnIycnBunXrYLVaYTabsXPnTtTW1mLt2rXCcc8//zyKiopw7tw5Yezhhx/G9u3b8ZOf/ARPPPEEZDIZNm3aBL1eL7wUCgC2bt2Kzz77DPPnz0d0dDQaGhrw4YcfoqWlBX/84x9v5e0SEREREY0K0QI8ALz66qt48803kZeXh7a2NiQmJuLdd9/FzJkzr3meVqvFli1b8Lvf/Q4bNmyAw+FAVlYWXnrpJYSGhgrHZWRkoLi4GNu3b0dbWxsCAwORnp6OJ5988luvQURERETkjSROp/PWt1TxYexCQ0TkGa5fROTLvLELjag78L5IKvWsb7y/XJuI6GZw/SIiX3ar17Bvux534ImIiIiIfIhoXWiIiIiIiMhzDPBERERERD6EAZ6IiIiIyIcwwBMRERER+RAGeCIiIiIiH8IAT0RERETkQxjgiYiIiIh8CAM8EREREZEPYYAnIiIiIvIhDPBERERERD5ELvYEaGSNjY3YvHkzSkpKcOrUKXR3d2Pz5s3IysoSe2pERNdUWlqKnTt3orCwELW1tQgJCUFGRgaee+45xMXFiT09IqJrOnnyJN5++22cOXMGzc3N0Ol0SEpKwjPPPIMZM2aIPT0ADPBeq6KiAhs3bkRcXBwSExNx/PhxsadERHRd3nvvPRQXFyMnJweJiYmwWq3YunUr7r//fuzYsQMJCQliT5GI6KqqqqowMDCAFStWQK/Xo6OjA3/961/x6KOPYuPGjZg7d67YU4TE6XQ6xZ4EDdfZ2Qm73Y7Q0FDs3bsXzzzzDHfgicgnFBcXY/r06VAqlcLYN998g/vuuw/33nsvXnnlFRFnR0TkuZ6eHtx9992YPn063nnnHbGnwx14b6XVasWeAhHRDRnpV8wTJkzA5MmTUV5eLsKMiIhuTkBAAMLCwtDe3i72VADwIVYiIroFnE4nmpqaEBoaKvZUiIiuS2dnJ1paWnDx4kX8/ve/x/nz55GdnS32tABwB56IiG6Bv/zlL2hoaMCaNWvEngoR0XX5l3/5F+zZswcAoFAo8P3vfx9PPfWUyLNyYYAnIqIxVV5ejn/7t3/DzJkzsWzZMrGnQ0R0XZ555hmsXLkS9fX1yMvLg81mg91ud3u+RywsoSEiojFjtVrx5JNPIjg4GOvXr4dUyr92iMg3JCYmYu7cufje976H999/H6dPn8aLL74o9rQAMMATEdEY6ejowOrVq9HR0YH33nsPer1e7CkREd0QhUKBhQsXoqCgAL29vWJPhwGeiIhGX19fH5566il88803eOeddzBx4kSxp0REdFN6e3vhdDrR1dUl9lQY4ImIaHQNDAzgueeew4kTJ7B+/Xqkp6eLPSUiouvW0tIybKyzsxN79uxBVFQUwsPDRZiVOz7E6sU2bNgAAELf5Ly8PBw7dgxBQUF49NFHxZwaEdFVvfLKK9i3bx/uuusutLa2Ii8vT/hMo9Hg7rvvFnF2RETX9txzz0GlUiEjIwN6vR51dXXIzc1FfX09fv/734s9PQB8E6tXS0xMHHE8JiYG+/btu8WzISK6Po899hiKiopG/IzrFxF5ux07diAvLw8XLlxAe3s7dDod0tPT8cMf/hCZmZliTw8AAzwRERERkU9hDTwRERERkQ9hgCciIiIi8iEM8EREREREPoQBnoiIiIjIhzDAExERERH5EAZ4IiIiIiIfwgBPRERERORDGOCJiMjrPfbYY1iwYIHY0yAi8gpysSdARETiKCwsxKpVq676uUwmw5kzZ27hjIiI6HowwBMRjXNLly7FHXfcMWxcKuUvaYmIvBEDPBHRODdt2jQsW7ZM7GkQEdF14vYKERFdU3V1NRITE/HWW29h165duO+++5CSkoL58+fjrbfeQn9//7Bzzp49i2eeeQZZWVlISUnBkiVLsHHjRgwMDAw71mq14t///d+xcOFCTJ8+HdnZ2XjiiSfwxRdfDDu2oaEBP//5zzF79mykpaXhRz/6ESoqKsbkvomIvBV34ImIxrmenh60tLQMG1cqldBqtcLP+/btQ1VVFR555BFERERg3759+I//+A/U1tZi7dq1wnEnT57EY489BrlcLhy7f/9+rFu3DmfPnsXrr78uHFtdXY2HHnoIzc3NWLZsGaZPn46enh6UlJTg8OHDmDt3rnBsd3c3Hn30UaSlpWHNmjWorq7G5s2b8fTTT2PXrl2QyWRj9G+IiMi7MMATEY1zb731Ft56661h4/Pnz8c777wj/Hz27Fns2LEDycnJAIBHH30Uzz77LHJzc7Fy5Uqkp6cDAF5++WXYbDZs27YNSUlJwrHPPfccdu3ahQcffBDZ2dkAgN/85jdobGzEe++9h9tvv93t+g6Hw+3nS5cu4Uc/+hFWr14tjIWFheG1117D4cOHh51PROSvGOCJiMa5lStXIicnZ9h4WFiY28+33XabEN4BQCKR4Mc//jH27t2LTz/9FOnp6Whubsbx48exaNEiIbwPHvvTn/4U+fn5+PTTT5GdnY3W1lYcPHgQt99++4jh++8fopVKpcO65syZMwcAUFlZyQBPROMGAzwR0TgXFxeH22677VuPS0hIGDY2adIkAEBVVRUAV0nMleNXmjhxIqRSqXCsxWKB0+nEtGnTrmueBoMBKpXKbSwkJAQA0Nrael3fQUTkD/gQKxER+YRr1bg7nc5bOBMiInExwBMR0XUpLy8fNnbhwgUAgMlkAgDExsa6jV/p4sWLcDgcwrFmsxkSiQRlZWVjNWUiIr/EAE9ERNfl8OHDOH36tPCz0+nEe++9BwC4++67AQDh4eHIyMjA/v37cf78ebdj3333XQDAokWLALjKX+644w4cOHAAhw8fHnY97qoTEY2MNfBEROPcmTNnkJeXN+Jng8EcAJKSkvCDH/wAjzzyCPR6PT777DMcPnwYy5YtQ0ZGhnDcSy+9hMceewyPPPIIHn74Yej1euzfvx+HDh3C0qVLhQ40APCv//qvOHPmDFavXo37778fycnJ6OvrQ0lJCWJiYvDLX/5y7G6ciMhHMcATEY1zu3btwq5du0b8rKCgQKg9X7BgAeLj4/HOO++goqIC4eHhePrpp/H000+7nZOSkoJt27bhD3/4A/77v/8b3d3dMJlM+MUvfoEf/vCHbseaTCb8z//8D/74xz/iwIEDyMvLQ1BQEJKSkrBy5cqxuWEiIh8ncfJ3lEREdA3V1dVYuHAhnn32WfzjP/6j2NMhIhr3WANPRERERORDGOCJiIiIiHwIAzwRERERkQ9hDTwRERERkQ/hDjwRERERkQ9hgCciIiIi8iEM8EREREREPoQBnoiIiIjIhzDAExERERH5EAZ4IiIiIiIf8v8BdiFJn41KIQ4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C--5u9xt5du0"
      },
      "source": [
        "While the the training loss is going down with each epoch, the validation loss is increasing. This suggests that we are training our model too long, and it is over-fitting on the training data.\n",
        "\t\t\t\n",
        "Validation loss is a more precise measure than accuracy, because with accuracy we do not care about the exact output value, but just which side of a threshold it falls on. If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7mkkuXoGVZ_"
      },
      "source": [
        "Last step is to save the fine-tuned model as well as the training arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "safVP_6TBr7n"
      },
      "source": [
        "def save_json(path, file):\n",
        "    with open(path, \"w\") as outfile:\n",
        "        json.dump(file, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gNPJgkmbYwO"
      },
      "source": [
        "print('Saving model...')\n",
        "torch.save(bert_classifier.state_dict(), sentiment_dir/'pytorch_model.pt')\n",
        "\n",
        "print('Saving tokenizer data...')\n",
        "tokenizer.save_pretrained(sentiment_dir)\n",
        "\n",
        "print('Saving training arguments...')\n",
        "save_json(sentiment_dir/'training_args.json', args)\n",
        "\n",
        "print('Saving training statistics..')\n",
        "save_json(sentiment_dir/'training_stats.json', trainer.training_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvizxatWVn-R"
      },
      "source": [
        "And if we want to load it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af4Zxg15Vqyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a788f3c1-7d5f-4398-a76e-85027771167e"
      },
      "source": [
        "'''path = '/content/drive/MyDrive/Degree/TFG/Models/BertForSentimentAnalysis/pytorch_model.pt'\n",
        "\n",
        "bert_classifier = BertClassifier()\n",
        "bert_classifier.load_state_dict(torch.load(path))\n",
        "bert_classifier.to(device)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=50, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDi8plm1iAp6"
      },
      "source": [
        "## 5.6 - Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2WZqXed64Bu"
      },
      "source": [
        "Once our model is fine-tuned, we can evaluate it with the test dataset. We need to define the prediction function which is going to be almost equal to the previous evaluation function, but applying a **softmax** to return the probabilities per class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4beq2q02L13"
      },
      "source": [
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Predictions\n",
        "    all_logits = []\n",
        "\n",
        "    # Set time\n",
        "    t0_test = time.time()\n",
        "\n",
        "    # Tracking variables\n",
        "    test_accuracy = []\n",
        "    test_loss = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    info_device()\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to device\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        test_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean()\n",
        "        test_accuracy.append(accuracy)\n",
        "    \n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    test_loss = np.mean(test_loss)\n",
        "    test_accuracy = np.mean(test_accuracy)\n",
        "\n",
        "    # Compute elapsed time\n",
        "    time_elapsed = format_time(time.time() - t0_test)\n",
        "\n",
        "    # Calculate probabilities\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    test_stats = {\n",
        "        'Test Loss': test_loss,\n",
        "        'Accuracy': test_accuracy,\n",
        "        'Test time': time_elapsed\n",
        "    }\n",
        "\n",
        "    print(f\"{'Test Loss':^12} | {'Accuracy':^10} | {'Test time':^11}\")\n",
        "    print(\"-\"*40)\n",
        "    print(f\"{test_loss:^12.6f} | {test_accuracy:^10.6f} | {time_elapsed:^11}\")\n",
        "    print(\"-\"*40)\n",
        "  \n",
        "    return probs, test_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgDYuFTztwfN"
      },
      "source": [
        "From `BertTrainer` we get the `model` and the `test_dataloader`. Using last function, we get the corresponding probabilities for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy4fJdpU2ep1",
        "outputId": "f2bd823f-4d8f-453b-aba3-5cfca60f7a01"
      },
      "source": [
        "# Compute probabilities in test set\n",
        "probs, test_stats= bert_predict(bert_classifier, generate_data_loaders(32, test=True))\n",
        "\n",
        "# Compute predictions\n",
        "preds = np.argmax(probs, axis=1)\n",
        "\n",
        "# Test labels\n",
        "test_df = datasets['test']\n",
        "y_true = test_df.label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using GPU Tesla P100-PCIE-16GB. \n",
            "\n",
            " Test Loss   |  Accuracy  |  Test time \n",
            "----------------------------------------\n",
            "  0.068871   |  0.981924  |   0:00:46  \n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14_4pt8LdERy",
        "outputId": "5c17e135-c560-4f5b-ca9b-3cc4e6f95a0f"
      },
      "source": [
        "print('Saving test statistics..')\n",
        "save_json(sentiment_dir/'test_stats.json', test_stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving test statistics..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsP8WSWyaoW9"
      },
      "source": [
        "To get a fast intuition on the result, we can plot some predicted sentences. Remember that the label 1 corresponds with positive sentiment while label 0 with negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Jfc4r_BWMoGm",
        "outputId": "72644d43-68c8-4bc0-db17-abe9fa6cad38"
      },
      "source": [
        "num_examples = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "df = test_df.sample(num_examples)\n",
        "df['real'] = np.where(df.label==0, 'negative', 'positive')\n",
        "df['predicted'] = np.where(preds[df.index]==0, 'negative', 'positive')\n",
        "df['probability'] = np.amax(probs, axis=1)[df.index]\n",
        "pd.set_option(\"max_colwidth\", 150)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>real</th>\n",
              "      <th>predicted</th>\n",
              "      <th>probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15717</th>\n",
              "      <td>a look at the `` wild ride '' that ensues when brash young men set out to conquer the online world with laptops , cell phones and sketchy business...</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.993305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20709</th>\n",
              "      <td>it 's rare to find a film to which the adjective ` gentle ' applies , but</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.998857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15685</th>\n",
              "      <td>a cutesy romantic tale with a twist .</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.999536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20266</th>\n",
              "      <td>with a tighter editorial process and firmer direction this material could work , especially since the actresses in the lead roles are all more tha...</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.530009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1776</th>\n",
              "      <td>get another phone call warning you that if the video is n't back at blockbuster before midnight , you 're going to face frightening late fees</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.998161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                    sentence  ...  probability\n",
              "15717  a look at the `` wild ride '' that ensues when brash young men set out to conquer the online world with laptops , cell phones and sketchy business...  ...     0.993305\n",
              "20709                                                                             it 's rare to find a film to which the adjective ` gentle ' applies , but   ...     0.998857\n",
              "15685                                                                                                                 a cutesy romantic tale with a twist .   ...     0.999536\n",
              "20266  with a tighter editorial process and firmer direction this material could work , especially since the actresses in the lead roles are all more tha...  ...     0.530009\n",
              "1776          get another phone call warning you that if the video is n't back at blockbuster before midnight , you 're going to face frightening late fees   ...     0.998161\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3HkKh0_YJoK"
      },
      "source": [
        "### 5.6.1 - Variable Threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsSlCGCAajmD"
      },
      "source": [
        "Sentiment classification task is even difficult for human. Therefore, define a threshold is going to provide a safer margin to classify one class. \n",
        "\n",
        "For example, if we define that positive sentiment sample are the only ones where probability of being *positive* is bigger than 0.9, samples classified as positive are going to have surely positive sentiment. The main drawback here is all samples wich are positive and are classified as negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yvLZpyAYp1A"
      },
      "source": [
        "To get a better intuiton about the performance, we can plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8-eUICKC5ks"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        title = \"Normalized confusion matrix\"\n",
        "    else:\n",
        "        title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.min() + ((cm.max() - cm.min()) / 2)\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.grid(False)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "saeayM_oD1ng",
        "outputId": "b5850f29-f087-40e2-e691-9b0b9c348f68"
      },
      "source": [
        "plot_confusion_matrix(confusion_matrix(preds, y_true), ('positive', 'negative'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFXyQR063Z4M"
      },
      "source": [
        "A useful tool to determine an optimal threshold  is the **Receiver Operating Characteristic curve (ROC)**. It is a plot of the false positive rate (x-axis) versus the true positive rate (y-axis) for a number of different candidate threshold values between 0.0 and 1.0.\n",
        "\n",
        "The **true positive rate** is calculated as the number of true positives divided by the sum of the number of true positives and the number of false negatives. It is also called as **hit rate** and describes how good the model is at predicting the positive class when the actual outcome is positive. It is also known as **sensitivity** or **recall**.\n",
        "\n",
        "\\begin{equation}\n",
        "    TPR = \\frac{TP}{TP \\ + \\ FN}\n",
        "\\end{equation}\n",
        "\n",
        "The **false positive rate** is calculated as the number of false positives divided by the sum of the number of false positives and the number of true negatives. It is also called the **false alarm rate** as it summarizes how often a positive class is predicted when the actual outcome is negative.\n",
        "\n",
        "\\begin{equation}\n",
        "    FPR = \\frac{FP}{FP \\ + \\ TN}\n",
        "\\end{equation}\n",
        "\n",
        "The complement of the FPR is the **specificity** and it is calculated as:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\text{Specificity} = 1 - FPR\n",
        "\\end{equation}\n",
        "\n",
        "The Geometric Mean or G-Mean is a metric for imbalanced classification that, if optimized, will seek a balance between the sensitivity and the specificity.\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{G-Mean} = \\sqrt{\\text{Sensitivity} \\cdot \\text{Specificity}}\n",
        "\\end{equation}\n",
        "\n",
        "One approach to determine the optimized threshold would be to test the model with each threshold and select the one with the largest G-Mean value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdRopsSbtvBh"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, probs[:, 1])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "    \n",
        "    # title\n",
        "    plt.title(f'Receiver Operating Characteristic\\nAUC = {roc_auc:.2f}, Best G-Mean = {gmeans[ix]:.2f}')\n",
        "    # plot ROC curve\n",
        "    plt.plot([0, 1], [0, 1],'--', label='No skill')\n",
        "    plt.plot(fpr, tpr, marker='.', label='Bert Classifier')\n",
        "    plt.plot(fpr[ix], tpr[ix], marker='o', color='black', label=f'Best threshold = {thresholds[ix]:.2f}')\n",
        "    # show legend\n",
        "    plt.legend(loc = 'lower right')\n",
        "    # axis labels\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    # show plot\n",
        "    plt.show()\n",
        "    return tpr, fpr, thresholds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "ojBpEORfuTfI",
        "outputId": "4a7c4d71-e952-492a-92a4-bc1a46ec4075"
      },
      "source": [
        "tpr, fpr, thresholds = evaluate_roc(probs, y_true)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXWo7a4bZpKs"
      },
      "source": [
        "An excellent model has AUC near to the 1 which means it has a good measure of separability. A poor model has AUC near to the 0 which means it has the worst measure of separability. In fact, it means it is reciprocating the result. It is predicting 0s as 1s and 1s as 0s. And when AUC is 0.5, it means the model has no class separation capacity whatsoever."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDdnlu47DubS"
      },
      "source": [
        "To confirm the result we can check it with the [Youden's J statistic](https://en.wikipedia.org/wiki/Youden%27s_J_statistic) which is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\begin{split}\n",
        "        &J = \\text{Sensitivity} + \\text{Specificity} - 1 = \\\\\n",
        "        &TPR + (1 - FPR) - 1 = TPR - FPR\n",
        "    \\end{split}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILv2twvdv7OE",
        "outputId": "974d4a93-a1a7-4efb-d7d5-8f9a61c14fe6"
      },
      "source": [
        "# get the best threshold\n",
        "J = tpr - fpr\n",
        "ix = np.argmax(J)\n",
        "best_thres = thresholds[ix]\n",
        "print('Best threshold = %.2f' % (best_thres))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best threshold = 0.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPu5KLWpl7B5"
      },
      "source": [
        "Another way to evaluate the skill of a prediction model is with the **Precision-Recall** curve.\n",
        "\n",
        "Precision is a ratio of the number of true positives divided by the sum of the true positives and false positives. It describes how good a model is at predicting the positive class. Precision is referred to as the positive predictive value.\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{Precision} = \\frac{TP}{TP \\ + \\ FP}\n",
        "\\end{equation}\n",
        "\n",
        "As it has been mentioned, **recall** is the same as TPR.\n",
        "\n",
        "F-Measure or **F1 score** is defined as the harmonic mean of precision (P) and recall (R).\n",
        "\n",
        "\\begin{equation}\n",
        "    F1 = \\frac{2PR}{P \\ + \\ R}\n",
        "\\end{equation}\n",
        "\n",
        "As in the ROC curve, the approach to finding the optimal threshold would be to calculate the F-measure for each threshold and select the largest one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5pEb0H4pmE4"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "def evaluate_prec_recall(probs, preds, y_true):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, probs[:, 1])\n",
        "\n",
        "    # convert to f score\n",
        "    fscore = (2 * precision * recall) / (precision + recall)\n",
        "    # locate the index of the largest f score\n",
        "    ix = np.argmax(fscore)\n",
        "\n",
        "    # title\n",
        "    plt.title(f'Precision-Recall\\nBest F1 score = {fscore[ix]:.2f}')\n",
        "    # plot the precision-recall curves\n",
        "    no_skill = len(y_true[y_true==1]) / len(y_true)\n",
        "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No skill')\n",
        "    plt.plot(recall, precision, marker='.', label='Bert Classifier')\n",
        "    plt.plot(recall[ix], precision[ix], marker='o', color='black', label=f'Best threshold = {thresholds[ix]:.2f}')\n",
        "    # show legend\n",
        "    plt.legend()\n",
        "    # axis labels\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    # show the plot\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "AixYhUNZmycW",
        "outputId": "ff6316d7-28d3-4d38-e11d-b72e57cff277"
      },
      "source": [
        "evaluate_prec_recall(probs, preds, y_true)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bXiLFZnBvmk"
      },
      "source": [
        "A model with perfect skill is depicted as a point at (1,1). A skilful model is represented by a curve that bows towards (1,1) above the flat line of no skill."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwA726ILA6kv"
      },
      "source": [
        "ROC curves should be used when there are roughly equal numbers of observations for each class. Precision-Recall curves should be used when there is a moderate to large class imbalance. The reason for this recommendation is that ROC curves present an optimistic picture of the model on datasets with a class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkcwMyOGJX-M"
      },
      "source": [
        "Finally, we can predict test samples with the optimized threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "OUPJwQ5K2cS1",
        "outputId": "4e65436b-f05a-40a7-f91e-a82b6c417a8f"
      },
      "source": [
        "# Get new predictions respect best threshold\n",
        "preds_thres = np.where(probs[:, 1] > best_thres, 1, 0)\n",
        "\n",
        "num_examples = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "df = test_df.sample(num_examples)\n",
        "df['real'] = np.where(df.label==0, 'negative', 'positive')\n",
        "df['predicted'] = np.where(preds_thres[df.index]==0, 'negative', 'positive')\n",
        "df['positive probability'] = probs[df.index, 1]\n",
        "df['negative probability'] = probs[df.index, 0]\n",
        "pd.set_option(\"max_colwidth\", 150)\n",
        "print(f'Threshold: {best_thres:.2f}')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Threshold: 0.49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>real</th>\n",
              "      <th>predicted</th>\n",
              "      <th>positive probability</th>\n",
              "      <th>negative probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16384</th>\n",
              "      <td>is , more often then</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.986948</td>\n",
              "      <td>0.013052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6678</th>\n",
              "      <td>shafer 's feature does n't offer much in terms of plot or acting .</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.002193</td>\n",
              "      <td>0.997807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4883</th>\n",
              "      <td>relays its universal points without lectures or confrontations</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.999343</td>\n",
              "      <td>0.000657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5945</th>\n",
              "      <td>clever and</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.999556</td>\n",
              "      <td>0.000444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13757</th>\n",
              "      <td>many of the things that made the first one charming</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.999459</td>\n",
              "      <td>0.000541</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                  sentence  ...  negative probability\n",
              "16384                                                is , more often then   ...              0.013052\n",
              "6678   shafer 's feature does n't offer much in terms of plot or acting .   ...              0.997807\n",
              "4883       relays its universal points without lectures or confrontations   ...              0.000657\n",
              "5945                                                           clever and   ...              0.000444\n",
              "13757                 many of the things that made the first one charming   ...              0.000541\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA2b-qLbJb3v"
      },
      "source": [
        "And check the new results in the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "imFdzQGPtlKv",
        "outputId": "608a035d-bc8c-409f-f372-cab67c907a36"
      },
      "source": [
        "plot_confusion_matrix(confusion_matrix(preds_thres, y_true), ('positive', 'negative'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNmIMT68s2az"
      },
      "source": [
        "### 5.6.2 - Pipeline for Custom Sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HysJTFYCToL"
      },
      "source": [
        "In order to get a fast intuiton about the application, let's define a pipeline to process and classify a custom sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nAtUId96-N1"
      },
      "source": [
        "def bert_classification(model, sequence):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Load batch to device\n",
        "    b_input_ids, b_attn_mask = (sequence['input_ids'].to(device), \n",
        "                                sequence['attention_mask'].to(device))\n",
        "\n",
        "    # Compute logits\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8byVLP5CCkJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "521fc832-677b-4279-da24-25029af27f8a"
      },
      "source": [
        "#@title { vertical-output: true }\n",
        "\n",
        "#@markdown Insert here a sentence in English\n",
        "sentence = \"After all this process, we can claim this model is super\" #@param {type:\"string\"}\n",
        "\n",
        "# Preprocess sentence\n",
        "encoded_sentence = dict()\n",
        "encoded_sentence['input_ids'], encoded_sentence['attention_mask'] = preprocessing_for_sa(pd.Series(sentence), tokenizer, len(tokenizer.encode(sentence)))\n",
        "\n",
        "# Compute probabilities\n",
        "final_probs = bert_classification(bert_classifier, encoded_sentence)\n",
        "\n",
        "# Print results\n",
        "print(f\"{'Sentiment':^11} | {'Probability':^13}\")\n",
        "print(27*'-')\n",
        "print(f\"{'Positive':^11} | {final_probs[0][1]:^13.5f}\")\n",
        "print(27*'-')\n",
        "print(f\"{'Negative':^11} | {final_probs[0][0]:^13.5f}\")\n",
        "print(27*'-')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sentiment  |  Probability \n",
            "---------------------------\n",
            " Positive   |    0.98319   \n",
            "---------------------------\n",
            " Negative   |    0.01681   \n",
            "---------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz6PyX0Enxw-"
      },
      "source": [
        "Finally, to download the whole folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFIwC28TnxWa"
      },
      "source": [
        "def download_folder(dir): \n",
        "    !zip -r $dir\\.zip $dir\n",
        "    files.download(f'{dir}.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJkPGEDmn86P"
      },
      "source": [
        "#download_folder(sentiment_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zJIwTuBQKmU"
      },
      "source": [
        "# 6 - Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_vCUke1zRjx"
      },
      "source": [
        "A more challenged task is **Question Answering**, which corresponds to extract the answer to a question from a given context. In this case the model answers the question by taking a substring of a context, not by generating new text.\n",
        "\n",
        "We are going to use [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) (Stanford Question Answering Dataset), a collection of 100k crowdsourced question/answer pairs. Given a question and a passage from Wikipedia containing the answer, the task is to predict the answer text span in the passage. This corresponds with SQuAD 1.1. In SQuAD 2.0 the problem definition is extended allowing for the possibility\n",
        "that no short answer exists in the provided paragraph, making the problem more realistic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReMEq5Ja3w9t"
      },
      "source": [
        "![Q&A](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/question_answering.png)\n",
        "\n",
        "> Image from [Hugging Face models](https://huggingface.co/models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egdBStwB4KQl"
      },
      "source": [
        "> For this task it is followed Hugging Face notebook's [question_answering](https://github.com/huggingface/notebooks/blob/master/examples/question_answering.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHhkbyihMiix"
      },
      "source": [
        "## 6.1 - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7m050pfMpz6"
      },
      "source": [
        "As before, the option to change the runtime type to a GPU is a good option."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pGcZbjzMyvX",
        "outputId": "f336e640-be0a-4ff9-dd48-b4cfeca5da60"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Oz5y8fM0ka"
      },
      "source": [
        "## 6.2 - Load SQuAD Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hEJMkm3NNj_"
      },
      "source": [
        "We are going to use [Hugging Face Datasets](https://huggingface.co/docs/datasets/v1.4.1/index.html), so running next cell we install the libraries in Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I7zzOdSNcn6",
        "outputId": "9032a05a-5f89-4bff-9862-7fe0674febf1"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/f8/ff7cd6e3b400b33dcbbfd31c6c1481678a2b2f669f521ad20053009a9aa3/datasets-1.7.0-py3-none-any.whl (234kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.0.1)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 12.4MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 11.8MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/32/a1/7c5261396da23ec364e296a4fb8a1cd6a5a2ff457215c6447038f18c0309/huggingface_hub-0.0.9-py3-none-any.whl\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: fsspec, xxhash, huggingface-hub, datasets\n",
            "Successfully installed datasets-1.7.0 fsspec-2021.5.0 huggingface-hub-0.0.9 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YenkcQigPzwK"
      },
      "source": [
        "With method [`load_dataset`](https://huggingface.co/docs/datasets/v1.4.1/package_reference/loading_methods.html#datasets.load_dataset) and specifying the name of the datasets we can load the required data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCsWZXIlOTTK",
        "outputId": "08926abc-81bf-4def-ae35-e8de6331cd20"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# This flag is the difference between SQUAD v1 or 2 \n",
        "# if you're using another dataset, it indicates if impossible answers are allowed or not).\n",
        "squad_v2 = False\n",
        "original_datasets = load_dataset('squad_v2' if squad_v2 else 'squad')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn_QnL6WQpOf"
      },
      "source": [
        "The loaded dataset is an object of [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict). It is a dictionary which contains train and validation samples, with the correspondig `context`, `question` and `answers`. As in the previous task, SQuAD is also used in competitions. In this case, there are not original test data. For this reason, as before, one third of training set is going to be used as test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDlay57Q0xL8"
      },
      "source": [
        "new_split = original_datasets['train'].train_test_split(test_size=0.33)\n",
        "original_datasets['train'] = new_split['train']\n",
        "original_datasets['test'] = new_split['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfGCw5Gk1o0I"
      },
      "source": [
        "With next function we can show random elements in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3j8APAoIrI3"
      },
      "source": [
        "from datasets import ClassLabel, Sequence\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
        "    display(HTML(df.to_html()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGqxi4rE3j6e"
      },
      "source": [
        "For a fast intuition on the model, we can remove some data, since the original size of the dataset has more than 80k samples only in training. With `perc` we select the percentage of data we are going to use. Removed sample are selected randomly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "s4Ww8dtnQsSu",
        "outputId": "9fe7717b-a69c-40ea-b392-b54eb57c891a"
      },
      "source": [
        "#@markdown Select a split\n",
        "split = \"train\" #@param [\"train\", \"validation\", \"test\"]\n",
        "#@markdown Select number of examples to visualize it\n",
        "num_examples = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "print(f'Some sentences of {split} split, which has a length of {original_datasets[split].num_rows}\\n')\n",
        "show_random_elements(original_datasets[split], num_examples)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some sentences of train split, which has a length of 58691\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'answer_start': [41], 'text': ['Dell 2.0']}</td>\n",
              "      <td>Dell announced a change campaign called \"Dell 2.0,\" reducing the number of employees and diversifying the company's products. While chairman of the board after relinquishing his CEO position, Michael Dell still had significant input in the company during Rollins' years as CEO. With the return of Michael Dell as CEO, the company saw immediate changes in operations, the exodus of many senior vice-presidents and new personnel brought in from outside the company. Michael Dell announced a number of initiatives and plans (part of the \"Dell 2.0\" initiative) to improve the company's financial performance. These include elimination of 2006 bonuses for employees with some discretionary awards, reduction in the number of managers reporting directly to Michael Dell from 20 to 12, and reduction of \"bureaucracy\". Jim Schneider retired as CFO and was replaced by Donald Carty, as the company came under an SEC probe for its accounting practices.</td>\n",
              "      <td>570fd59c5ab6b8190039105d</td>\n",
              "      <td>What was the name of Dell's change campaign?</td>\n",
              "      <td>Dell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'answer_start': [381], 'text': ['2004']}</td>\n",
              "      <td>The Times is the originator of the widely used Times Roman typeface, originally developed by Stanley Morison of The Times in collaboration with the Monotype Corporation for its legibility in low-tech printing. In November 2006 The Times began printing headlines in a new font, Times Modern. The Times was printed in broadsheet format for 219 years, but switched to compact size in 2004 in an attempt to appeal more to younger readers and commuters using public transport. The Sunday Times remains a broadsheet.</td>\n",
              "      <td>5705e06c52bb891400689646</td>\n",
              "      <td>In what year did The Times change its broadsheet format to a compact size?</td>\n",
              "      <td>The_Times</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'answer_start': [610], 'text': ['by subtracting 1/3 exposure stop']}</td>\n",
              "      <td>The Weston Cadet (model 852 introduced in 1949), Direct Reading (model 853 introduced 1954) and Master III (models 737 and S141.3 introduced in 1956) were the first in their line of exposure meters to switch and utilize the meanwhile established ASA scale instead. Other models used the original Weston scale up until ca. 1955. The company continued to publish Weston film ratings after 1955, but while their recommended values often differed slightly from the ASA film speeds found on film boxes, these newer Weston values were based on the ASA system and had to be converted for use with older Weston meters by subtracting 1/3 exposure stop as per Weston's recommendation. Vice versa, \"old\" Weston film speed ratings could be converted into \"new\" Westons and the ASA scale by adding the same amount, that is, a film rating of 100 Weston (up to 1955) corresponded with 125 ASA (as per ASA PH2.5-1954 and before). This conversion was not necessary on Weston meters manufactured and Weston film ratings published since 1956 due to their inherent use of the ASA system; however the changes of the ASA PH2.5-1960 revision may be taken into account when comparing with newer ASA or ISO values.</td>\n",
              "      <td>57264e6f5951b619008f6f71</td>\n",
              "      <td>How were Weston values changed to ASA values?</td>\n",
              "      <td>Film_speed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBP-0Z5w5R3t"
      },
      "source": [
        "As before, for a fast intuition on the model, we can remove some data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNZtBVZxA-SQ"
      },
      "source": [
        "from datasets import DatasetDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj7Kp7aAaBTO",
        "outputId": "106ab074-35c7-439d-ed53-74758f558ba7"
      },
      "source": [
        "#@title 6.2.1 Resize dataset { vertical-output: true }\n",
        "#@markdown Percentage of dataset to use %\n",
        "perc = 100 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "datasets = DatasetDict()\n",
        "\n",
        "for key, dataset in original_datasets.shuffle().items():\n",
        "    if perc != 100:\n",
        "        datasets[key] = dataset.select(np.arange(0, round(dataset.num_rows*(perc/100)+1)))\n",
        "        print(f'{key:<10}\\t', f'From: {original_datasets[key].num_rows:<10}', f'To: {datasets[key].num_rows:<10}')\n",
        "    else:\n",
        "        datasets[key] = original_datasets[key]\n",
        "        print(f'{key:<10}\\t', f'size: {len(original_datasets[key]):<10}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train     \t size: 58691     \n",
            "validation\t size: 10570     \n",
            "test      \t size: 28908     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-LZ1teNUeFY"
      },
      "source": [
        "## 6.3 - Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8q68IuPU1_l"
      },
      "source": [
        "In this task the structure of the input differs from sentiment analysis. Now we have two sentences:\n",
        "\n",
        "\\begin{matrix}\n",
        "    [CLS] & \\text{Sentence A} & [SEP] & \\text{Sentence B}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZInR1JVXVn4V"
      },
      "source": [
        "In this case we are going to use [`BertTokenizerFast`](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertTokenizerFast). This one is a [Fast Tokenizer](https://huggingface.co/transformers/main_classes/tokenizer.html#tokenizer), which according to Hugging Face implies \n",
        "\n",
        "- A significant speed-up in particular when doing batched tokenization.\n",
        "- Additional methods to map between the original string (character and words) and the token space.\n",
        "\n",
        "As before, we choose [`bert-base-uncased`](https://huggingface.co/bert-base-uncased) as pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198,
          "referenced_widgets": [
            "1e9725e1ba544d3d9203eae5a2d0e475",
            "8788bfb0ccd445f6ba3ad9bb7be74bc9",
            "0c3f9948aac948d293c398cf5a417e32",
            "f4c57e72e00d40948ba36dc6adf08cd1",
            "126c4d2b672e4a5cbfcd9d512abae2c6",
            "56f2e3acc95648f7a782b9722841c366",
            "e69d18b335ba46b4b5c1d162230bf4c7",
            "ac6bf0402d8044da90bb8d9f0d1984e0",
            "fe0432f9218b4c12bc35c922b536f195",
            "1a76be72a95d465496f4d8cea582f535",
            "6f0069b280dc40c4bcb9ccc5abb2f885",
            "5d00075a0c3643d18d26f22561a274c2",
            "a35acaf71359436caad40f1e32ef29b4",
            "2d50b5a17d804e068a774a62adb25538",
            "71e3380df79249df9080c49c5b461c9c",
            "f794ffbf82484c6d9d0a960bf295cf93",
            "2b7ac193b8154a51bad7914a00b0a3d9",
            "80ad8ae47c7043eca3f4cff4a7d12d93",
            "f316730905274844a1f91871c0b16e76",
            "f969fcb81223486f8c7a4e7a7b0f4627",
            "7f428cd9bf384cb8b71c2e42a75b76cb",
            "a9b57a531a8d44e7902c7677657b68c9",
            "e518741636ae442aa5d6524980626779",
            "756fffb49b884e5c969ef125903f05b3"
          ]
        },
        "id": "yvPgC4STfI7f",
        "outputId": "15f02580-be8f-4288-86f9-377412bc808b"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "MODEL_NAME = 'bert-base-uncased'\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...\\n')\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e9725e1ba544d3d9203eae5a2d0e475",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe0432f9218b4c12bc35c922b536f195",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b7ac193b8154a51bad7914a00b0a3d9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul-6neG4ki-Q"
      },
      "source": [
        "As before, we can check its attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phbxf9K_kvXW",
        "outputId": "42e33936-86ec-43c0-f0c6-0851e7fa8518"
      },
      "source": [
        "#@markdown Select an option to visualize it\n",
        "attribute = \"vocab_size\" #@param [\"vocab_size\", \"model_max_length\", \"padding_side\", \"sep_token\", \"pad_token\", \"cls_token\", \"mask_token\", \"unk_token\"]\n",
        "\n",
        "print(getattr(tokenizer, attribute))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD1KrbgIAknD"
      },
      "source": [
        "One problem is how manage long documents. The \n",
        "usual truncation process could carry in losing the answer we are looking for. To deal with it, we truncate the context into features, text shorter than maximum length allowed, and allow some overlap between them in case the answer lies at the point we split a long context\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4lwrtz5C3QR"
      },
      "source": [
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two parts of the context when splitting it is needed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UohhB81oTEIh"
      },
      "source": [
        "Let's find an example whose length is longer than `max_length`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgCCZ_EGC354",
        "outputId": "f7707305-c9d2-4c59-bbc2-84c44775b42f"
      },
      "source": [
        "for i, example in enumerate(datasets[\"train\"]):\n",
        "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > max_length:\n",
        "        break\n",
        "example = datasets[\"train\"][i]\n",
        "example"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': {'answer_start': [593], 'text': ['Charles Horace Mayo']},\n",
              " 'context': 'The Feinberg School of Medicine (previously the Northwestern University Medical School) has produced a number of notable graduates, including Mary Harris Thompson, Class of 1870, ad eundem, first female surgeon in Chicago, first female surgeon at Cook County Hospital, and founder of the Mary Thomson Hospital, Roswell Park, Class of 1876, prominent surgeon for whom the Roswell Park Cancer Institute in Buffalo, New York, is named, Daniel Hale Williams, Class of 1883, performed the first successful American open heart surgery; only black charter member of the American College of Surgeons, Charles Horace Mayo, Class of 1888, co-founder of Mayo Clinic, Carlos Montezuma, Class of 1889, one of the first Native Americans to receive a Doctor of Medicine degree from any school, and founder of the Society of American Indians, Howard T. Ricketts, Class of 1897, who discovered bacteria of the genus Rickettsia, and identified the cause and methods of transmission of rocky mountain spotted fever, Allen B. Kanavel, Class of 1899, founder, regent, and president of the American College of Surgeons, internationally recognized as founder of modern hand and peripheral nerve surgery, Robert F. Furchgott, Class of 1940, received a Lasker Award in 1996 and the 1998 Nobel Prize in Physiology or Medicine for his co-discovery of nitric oxide, Thomas E. Starzl, Class of 1952, performed the first successful liver transplant in 1967 and received the National Medal of Science in 2004 and a Lasker Award in 2012, Joseph P. Kerwin, first physician in space, flew on three skylab missions and later served as director of Space and Life Sciences at NASA, C. Richard Schlegel, Class of 1972, developed the dominant patent for a vaccine against human papillomavirus (administered as Gardasil) to prevent cervical cancer, David J. Skorton, Class of 1974, a noted cardiologist became president of Cornell University in 2006, and Andrew E. Senyei, Class of 1979, inventor, venture capitalist, and entrepreneur, founder of biotech and genetics companies, and a university trustee.',\n",
              " 'id': '572816beff5b5019007d9ce6',\n",
              " 'question': 'Which graduate of The Feinburg School of Medicine co-founded the Mayo Clinic?',\n",
              " 'title': 'Northwestern_University'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKprbGPFgPF6",
        "outputId": "d3e6cffb-8049-4f64-94db-27159bf09a52"
      },
      "source": [
        "print(f'Original length \\t{len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"])}')\n",
        "print(f'Truncated length \\t{len(tokenizer(example[\"question\"], example[\"context\"], max_length=max_length, truncation=\"only_second\")[\"input_ids\"])}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original length \t419\n",
            "Truncated length \t384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yGs3fWPVsUO"
      },
      "source": [
        "Only the context should be truncated, specifying `truncation=only_second`. The tokenizer will return a lisf of features capped by a certain maximum length, with the overlap we talked above. We just have to declare `return_overflowing_tokens=True` and `stride=doc_stride` to pass the stride.\n",
        "\n",
        "Mention we need to find in which of those features the answer actually is, and where exactly in that feature, the start and end positions. The tokenizer we're using can help us with that by returning an `offset_mapping`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_Y6IdUoC8_W"
      },
      "source": [
        "tokenized_example = tokenizer(\n",
        "    example[\"question\"],\n",
        "    example[\"context\"],\n",
        "    max_length=max_length,\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        "    stride=doc_stride\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmrd83ymaf_s"
      },
      "source": [
        "We can plot each of the features in order to see the overlapping part:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7Jy6J3XadOn",
        "outputId": "4081e1ea-773d-4bcb-cac1-5112d974f611"
      },
      "source": [
        "for i, x in enumerate(tokenized_example[\"input_ids\"]):\n",
        "    print(f'Feature {i+1} with {len(x)} tokens')\n",
        "    print(tokenizer.convert_ids_to_tokens(x), '\\n') # or tokenizer.decode(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature 1 with 384 tokens\n",
            "['[CLS]', 'which', 'graduate', 'of', 'the', 'fein', '##burg', 'school', 'of', 'medicine', 'co', '-', 'founded', 'the', 'mayo', 'clinic', '?', '[SEP]', 'the', 'fein', '##berg', 'school', 'of', 'medicine', '(', 'previously', 'the', 'northwestern', 'university', 'medical', 'school', ')', 'has', 'produced', 'a', 'number', 'of', 'notable', 'graduates', ',', 'including', 'mary', 'harris', 'thompson', ',', 'class', 'of', '1870', ',', 'ad', 'eun', '##de', '##m', ',', 'first', 'female', 'surgeon', 'in', 'chicago', ',', 'first', 'female', 'surgeon', 'at', 'cook', 'county', 'hospital', ',', 'and', 'founder', 'of', 'the', 'mary', 'thomson', 'hospital', ',', 'ro', '##swell', 'park', ',', 'class', 'of', '1876', ',', 'prominent', 'surgeon', 'for', 'whom', 'the', 'ro', '##swell', 'park', 'cancer', 'institute', 'in', 'buffalo', ',', 'new', 'york', ',', 'is', 'named', ',', 'daniel', 'hale', 'williams', ',', 'class', 'of', '1883', ',', 'performed', 'the', 'first', 'successful', 'american', 'open', 'heart', 'surgery', ';', 'only', 'black', 'charter', 'member', 'of', 'the', 'american', 'college', 'of', 'surgeons', ',', 'charles', 'horace', 'mayo', ',', 'class', 'of', '1888', ',', 'co', '-', 'founder', 'of', 'mayo', 'clinic', ',', 'carlos', 'monte', '##zu', '##ma', ',', 'class', 'of', '1889', ',', 'one', 'of', 'the', 'first', 'native', 'americans', 'to', 'receive', 'a', 'doctor', 'of', 'medicine', 'degree', 'from', 'any', 'school', ',', 'and', 'founder', 'of', 'the', 'society', 'of', 'american', 'indians', ',', 'howard', 't', '.', 'rick', '##ett', '##s', ',', 'class', 'of', '1897', ',', 'who', 'discovered', 'bacteria', 'of', 'the', 'genus', 'rick', '##ett', '##sia', ',', 'and', 'identified', 'the', 'cause', 'and', 'methods', 'of', 'transmission', 'of', 'rocky', 'mountain', 'spotted', 'fever', ',', 'allen', 'b', '.', 'kan', '##ave', '##l', ',', 'class', 'of', '1899', ',', 'founder', ',', 'regent', ',', 'and', 'president', 'of', 'the', 'american', 'college', 'of', 'surgeons', ',', 'internationally', 'recognized', 'as', 'founder', 'of', 'modern', 'hand', 'and', 'peripheral', 'nerve', 'surgery', ',', 'robert', 'f', '.', 'fur', '##ch', '##go', '##tt', ',', 'class', 'of', '1940', ',', 'received', 'a', 'las', '##ker', 'award', 'in', '1996', 'and', 'the', '1998', 'nobel', 'prize', 'in', 'physiology', 'or', 'medicine', 'for', 'his', 'co', '-', 'discovery', 'of', 'ni', '##tric', 'oxide', ',', 'thomas', 'e', '.', 'star', '##z', '##l', ',', 'class', 'of', '1952', ',', 'performed', 'the', 'first', 'successful', 'liver', 'transplant', 'in', '1967', 'and', 'received', 'the', 'national', 'medal', 'of', 'science', 'in', '2004', 'and', 'a', 'las', '##ker', 'award', 'in', '2012', ',', 'joseph', 'p', '.', 'ke', '##rwin', ',', 'first', 'physician', 'in', 'space', ',', 'flew', 'on', 'three', 'skyla', '##b', 'missions', 'and', 'later', 'served', 'as', 'director', 'of', 'space', 'and', 'life', 'sciences', 'at', 'nasa', ',', 'c', '.', 'richard', 'sc', '##hl', '##ege', '##l', ',', 'class', 'of', '1972', ',', 'developed', 'the', 'dominant', 'patent', 'for', 'a', 'vaccine', 'against', 'human', 'pa', '##pi', '##llo', '##ma', '##virus', '(', '[SEP]'] \n",
            "\n",
            "Feature 2 with 215 tokens\n",
            "['[CLS]', 'which', 'graduate', 'of', 'the', 'fein', '##burg', 'school', 'of', 'medicine', 'co', '-', 'founded', 'the', 'mayo', 'clinic', '?', '[SEP]', 'fur', '##ch', '##go', '##tt', ',', 'class', 'of', '1940', ',', 'received', 'a', 'las', '##ker', 'award', 'in', '1996', 'and', 'the', '1998', 'nobel', 'prize', 'in', 'physiology', 'or', 'medicine', 'for', 'his', 'co', '-', 'discovery', 'of', 'ni', '##tric', 'oxide', ',', 'thomas', 'e', '.', 'star', '##z', '##l', ',', 'class', 'of', '1952', ',', 'performed', 'the', 'first', 'successful', 'liver', 'transplant', 'in', '1967', 'and', 'received', 'the', 'national', 'medal', 'of', 'science', 'in', '2004', 'and', 'a', 'las', '##ker', 'award', 'in', '2012', ',', 'joseph', 'p', '.', 'ke', '##rwin', ',', 'first', 'physician', 'in', 'space', ',', 'flew', 'on', 'three', 'skyla', '##b', 'missions', 'and', 'later', 'served', 'as', 'director', 'of', 'space', 'and', 'life', 'sciences', 'at', 'nasa', ',', 'c', '.', 'richard', 'sc', '##hl', '##ege', '##l', ',', 'class', 'of', '1972', ',', 'developed', 'the', 'dominant', 'patent', 'for', 'a', 'vaccine', 'against', 'human', 'pa', '##pi', '##llo', '##ma', '##virus', '(', 'administered', 'as', 'ga', '##rda', '##sil', ')', 'to', 'prevent', 'cervical', 'cancer', ',', 'david', 'j', '.', 'sk', '##ort', '##on', ',', 'class', 'of', '1974', ',', 'a', 'noted', 'card', '##iol', '##ogist', 'became', 'president', 'of', 'cornell', 'university', 'in', '2006', ',', 'and', 'andrew', 'e', '.', 'sen', '##ye', '##i', ',', 'class', 'of', '1979', ',', 'inventor', ',', 'venture', 'capitalist', ',', 'and', 'entrepreneur', ',', 'founder', 'of', 'bio', '##tech', 'and', 'genetics', 'companies', ',', 'and', 'a', 'university', 'trustee', '.', '[SEP]'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUvWR31SbRIH"
      },
      "source": [
        "And how the tokenizer can provide us the positions of each token:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IDygx3Cb4Vb",
        "outputId": "9abe5484-a90a-4e5e-b8c8-a283738aaeef"
      },
      "source": [
        "rnd_index = random.randint(0, len(tokenized_example[\"input_ids\"][0])-1)\n",
        "token_id = tokenized_example[\"input_ids\"][0][rnd_index]\n",
        "offsets = tokenized_example[\"offset_mapping\"][0][rnd_index]\n",
        "\n",
        "print(f'Token {rnd_index} \\t{tokenizer.convert_ids_to_tokens(token_id)}\\n')\n",
        "\n",
        "print(f'Start position \\t{offsets[0]}')\n",
        "print(f'End position \\t{offsets[1]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token 74 \tlibyan\n",
            "\n",
            "Start position \t271\n",
            "End position \t277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyKmuAv3wz79"
      },
      "source": [
        "To distinguish which parts of the offsets correspond to the question and which part correspond to the context, we can use [`sequence_ids`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.BatchEncoding.sequence_ids) method. It returns `None` for the special tokens, then 0 or 1 depending on whether the corresponding token comes from the first sentence past (the question) or the second (the context)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dLSn6Z4ej8N",
        "outputId": "eb850382-3e02-4508-f0f8-8349ef1dee4c"
      },
      "source": [
        "sequence_ids = tokenized_example.sequence_ids()\n",
        "print(sequence_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-FZScaFfq92"
      },
      "source": [
        "With all of this, the last step is to check if the answer is in the feature or in the next one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_T4P94NfqPa",
        "outputId": "6845c29b-9d11-49ce-9dbb-adeb9328b8ac"
      },
      "source": [
        "answers = example[\"answers\"]\n",
        "start_char = answers[\"answer_start\"][0]\n",
        "end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "# Start token index of the current span in the text.\n",
        "token_start_index = 0\n",
        "while sequence_ids[token_start_index] != 1:\n",
        "    token_start_index += 1\n",
        "\n",
        "# End token index of the current span in the text.\n",
        "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
        "while sequence_ids[token_end_index] != 1:\n",
        "    token_end_index -= 1\n",
        "\n",
        "# Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "offsets = tokenized_example[\"offset_mapping\"][0]\n",
        "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "    # Move the token_start_index and token_end_index to the two ends of the answer.\n",
        "    # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "        token_start_index += 1\n",
        "    start_position = token_start_index - 1\n",
        "    while offsets[token_end_index][1] >= end_char:\n",
        "        token_end_index -= 1\n",
        "    end_position = token_end_index + 1\n",
        "    print(f'Original answer \\t{answers[\"text\"][0]}', '\\n')\n",
        "    print(f'Start position \\t\\t{start_position}')\n",
        "    print(f'End position \\t\\t{end_position}')\n",
        "    print(f'In feature \\t\\t{tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1])}')\n",
        "else:\n",
        "    print(\"The answer is not in this feature.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original answer \t€50 million \n",
            "\n",
            "Start position \t\t245\n",
            "End position \t\t247\n",
            "In feature \t\t€50 million\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt4b2eCbrz-Y"
      },
      "source": [
        "Once all steps are explained, we can integrate them in a whole function to preprocess whole data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQz2mF7fwz8A"
      },
      "source": [
        "def preprocessing_for_qa(examples):\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],               #tokenize question\n",
        "        examples[\"context\"],                #tokenize context\n",
        "        truncation=\"only_second\",           #truncate only context if necessary\n",
        "        max_length=max_length,              #variable max_length\n",
        "        stride=doc_stride,                  #overlap to stride\n",
        "        return_overflowing_tokens=True,     #return overflowing tokens\n",
        "        return_offsets_mapping=True,        #return offsets mapping\n",
        "        padding=\"max_length\"                #pad to max length\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != 1:\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != 1:\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd0323JyKkoZ"
      },
      "source": [
        "Now, we only have to apply the function to the different splits. We can use the [`map`](https://huggingface.co/docs/datasets/v1.4.1/package_reference/main_classes.html?highlight=map#datasets.Dataset.map) method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "b1090b21d25245f88b2a72c6a01b4ac0",
            "41c0f0756da845f494f8e8e3ef16b36c",
            "e9afe269498c4253903288d39941238c",
            "451ee635bd094208b3143a981b0cd7e5",
            "2e22473163684c44815186e59b577aad",
            "25f2426e7bc249adbedeb9284fd5be54",
            "4259839021854589a8c8ceb2ef06d768",
            "a88431e2e3db465bb2a53f401641a682",
            "ddbfc0a78ac546babe28623be113d2bb",
            "31eff7bd4d874f2ca17d25340452a87f",
            "7062d92bec54453f86a6d74276521993",
            "7718d264c80f490f82a0969770e12b07",
            "a69380d978664da89cdf6ca98f287e12",
            "ccb247d7e9354ddb987e94ae00e7b6ee",
            "a3bc6944b18c4e0a937043a5e9eb8b2e",
            "08598375abb64fc1a3ef663393bad0dd",
            "a0598196dd17457db1b77b9e618c2413",
            "fe724a5b17424057b4735eb93199da54",
            "3a311de2a4154f3ab0af1d2dee560d37",
            "513310f02c3d4c7d98c626ea8468cf9f",
            "bf3ff96fce274888beb6c61993c54d04",
            "ba16af5336214c97ba6f5991448df2ed",
            "126f777ee99448f0a084ea777be9f5e7",
            "21df018008614224afa5c3f6f94443cd"
          ]
        },
        "id": "fUC0DNfzNJIW",
        "outputId": "7f83ad49-7982-43f2-a0a0-2470258e6831"
      },
      "source": [
        "tokenized_datasets = datasets.map(preprocessing_for_qa, \n",
        "                                  batched=True, \n",
        "                                  remove_columns=datasets[\"train\"].column_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1090b21d25245f88b2a72c6a01b4ac0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddbfc0a78ac546babe28623be113d2bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0598196dd17457db1b77b9e618c2413",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voWiw8C7IrJV"
      },
      "source": [
        "The results are automatically cached by the [Datasets](https://huggingface.co/docs/datasets/v1.4.1/index.html) library to avoid spending time on this step the next time you run your notebook. With `load_from_cache_file=False` in the call to [`map`](https://huggingface.co/docs/datasets/v1.4.1/package_reference/main_classes.html?highlight=map#datasets.Dataset.map), the cached files are not used and the preprocessing is applied again.\n",
        "\n",
        "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGeN3Ju3WZzQ"
      },
      "source": [
        "Once the original datasets are tokenizer, we get another [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), but with different columns than the original one: `attention_mask`, used to indicate words from additional padding, `input_ids`, tokens as integers, and `token_type_ids`, indicating to which sentence words belongs. Finally the start and end positions of the answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "OauAJlyHWtpQ",
        "outputId": "77cdf361-178a-4341-cbef-204b96ab1673"
      },
      "source": [
        "#@markdown Select a split\n",
        "split = \"train\" #@param [\"train\", \"validation\", \"test\"]\n",
        "#@markdown Select number of examples to visualize it\n",
        "num_examples = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "print(f'Some sentences of {split} split, which has a length of {tokenized_datasets[split].num_rows}\\n')\n",
        "show_random_elements(tokenized_datasets[split], num_examples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some sentences of train split, which has a length of 59315\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>end_positions</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>start_positions</th>\n",
              "      <th>token_type_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
              "      <td>92</td>\n",
              "      <td>[101, 2096, 2002, 2001, 1999, 3905, 2082, 1010, 2054, 4066, 1997, 16841, 2106, 28924, 2490, 1029, 102, 28924, 4114, 13616, 1998, 5500, 14921, 21289, 1996, 12078, 1012, 1999, 2255, 3777, 1010, 2002, 2419, 1037, 10467, 21248, 7795, 1005, 1055, 22965, 2013, 1996, 2142, 5424, 3072, 1012, 2076, 2023, 2027, 3631, 3645, 1997, 1037, 2334, 3309, 5496, 1997, 3529, 6544, 1012, 9105, 1996, 4614, 1005, 3086, 1010, 2027, 10016, 2010, 2155, 2013, 11200, 1012, 28924, 2333, 2000, 28616, 14660, 1010, 2045, 7052, 28616, 14660, 3905, 2082, 1012, 8498, 2010, 3037, 1999, 5424, 8986, 16841, 1010, 2002, 4188, 2000, 3693, 2151, 1997, ...]</td>\n",
              "      <td>90</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
              "      <td>154</td>\n",
              "      <td>[101, 2129, 2106, 28924, 2903, 1996, 3956, 1011, 8976, 4736, 2323, 2022, 10395, 1029, 102, 1037, 8050, 2112, 1997, 28924, 1005, 1055, 13165, 2001, 3424, 1011, 19999, 2964, 1012, 2002, 3373, 2008, 1996, 2110, 1997, 3956, 2323, 2025, 4839, 1010, 1998, 2008, 2151, 5424, 12014, 2007, 1996, 5611, 2231, 2001, 1037, 14583, 1997, 1996, 5424, 2111, 1012, 1999, 2312, 2112, 2349, 2000, 2037, 2490, 1997, 3956, 1010, 28924, 26626, 1996, 2142, 2163, 1010, 6195, 1996, 2406, 2000, 2022, 4461, 2923, 1998, 12559, 14083, 2075, 2009, 2004, 1000, 1996, 7861, 5092, 21341, 1997, 4763, 1012, 1000, 8320, 2075, 2114, 5181, 1999, ...]</td>\n",
              "      <td>148</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
              "      <td>0</td>\n",
              "      <td>[101, 1999, 2054, 2095, 2106, 1037, 2413, 2932, 6235, 1996, 2224, 1997, 16295, 1029, 102, 15486, 1999, 2605, 2127, 1996, 4329, 1997, 9500, 1012, 2059, 1010, 1999, 1996, 20400, 1010, 2045, 2001, 1037, 12058, 1997, 3037, 1010, 1998, 16295, 2150, 4235, 2109, 1000, 2005, 14271, 2015, 1010, 4257, 15753, 1010, 1998, 1996, 14834, 1997, 20199, 16451, 2015, 1010, 1998, 1999, 2563, 1010, 2070, 2224, 1997, 2009, 2018, 2042, 2081, 1997, 2009, 2005, 2714, 5682, 1000, 1012, 2049, 4125, 1999, 2885, 2001, 1000, 1037, 5573, 9575, 1000, 1010, 2044, 3019, 10042, 2020, 2179, 1000, 1999, 2605, 2012, 9808, 8193, 2078, 1006, ...]</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQBsd8ivQ8cX"
      },
      "source": [
        "## 6.4 - Generate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_mjlVIIncTf"
      },
      "source": [
        "To fine tune on **Question Answering**, it is introduced a start vector $ S \\in \\mathbb R^{H} $ and an end vector $ E \\in \\mathbb R^{H} $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPARYgkTSI7X"
      },
      "source": [
        "![Fine tune Q&A](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/question_answering_fine_tune.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb12e17xqRSr"
      },
      "source": [
        "To compute the probability of a word $ i $ being the start or the end of the answer, we compute the dot product between $ S $ and $ T_i $ followed by a softmax over all the words in the sequence.\n",
        "\n",
        "\\begin{equation}\n",
        "    P_i = \\frac{e^{S \\cdot T_i}}{\\sum_{j} e^{S \\cdot T_j}}\n",
        "\\end{equation} \n",
        "\n",
        "The score for a candidate is defined as $ S \\cdot T_i \\ + \\ E \\cdot T_j $, where $ i $ is the start position and $ j $ the final position. The maximum scoring span: $ \\hat{s_{i, j}} = max_{j \\geq i} S \\cdot T_i \\ + \\ E \\cdot T_j $ is used as prediction, where the training objective is the sum of the log-likelihoods of the correct start and end positions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwmIElx_DKBV"
      },
      "source": [
        "![Model Q&A](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/bert-qa.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URbe2r4LuNkG"
      },
      "source": [
        "To extend to SQuAD 2.0, questions which do not have an answer have an span with start and end at the $ [CLS] $ token. It is compared the score of the null answer span: $ s_{null} = S \\cdot C \\ + E \\cdot C $ with $ \\hat{s_{i, j}} $. It is predicted a non-null answer if $ \\hat{s_{i, j}} > s_{null} \\ + \\ \\tau$, where threshold $ \\tau $ i selected on the validation set to maximize F1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4iHhaveC1HX"
      },
      "source": [
        "In this task we are going to use the model designed by Hugging Face [`BertForQuestionAnswering`](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertForQuestionAnswering)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "8d0a2ebe953f42da803bdac9c2595734",
            "2ed81205538b46edabca7dbfe1184f47",
            "81fec09cc1af446cae82b34350949c6a",
            "165ea7b45b8c40319c559ec964e7659c",
            "a0a2f12911184da1ae63d10792997f9d",
            "b09aa3ef534d44fd9118eadfa57bf2d1",
            "c518782401cf4f3a9fca433d2263456b",
            "b1f40d992aaf47c3b43f3e353969eecd",
            "dbaa2c0e8ca0482bba6b292e95d80d24",
            "5898b35a148a45ceb873c5a62bcf5d8e",
            "1cecf2c992324159987be5e3b7fd396c",
            "e43481a6687445b6850721c1b2744596",
            "1e0ac7b4346041daae56916fbc3d2202",
            "0e17eed2f91b4171bd43cbfcbf4c47c1",
            "ce18f6c4c8aa47c9b037482aa7bf05a6",
            "de668dd4988049efa6240a16ea941d35"
          ]
        },
        "id": "eddDHjFJ_6zq",
        "outputId": "22737c77-2213-441f-862f-cf1abc0ee9c1"
      },
      "source": [
        "from transformers import BertForQuestionAnswering\n",
        "\n",
        "bert_qa = BertForQuestionAnswering.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d0a2ebe953f42da803bdac9c2595734",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbaa2c0e8ca0482bba6b292e95d80d24",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtD_B4OnAGJP",
        "outputId": "87883ae5-55e1-45d5-b363-eee70db6fec0"
      },
      "source": [
        "#@markdown Select whole model, only pretrained BERT or the question & answer outputs\n",
        "block = \"model\" #@param [\"model\", \"bert\", \"qa_outputs\"]\n",
        "if block == 'model':\n",
        "    print(bert_qa)\n",
        "else:\n",
        "    print(getattr(model, block))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertForQuestionAnswering(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvBPQ9ytQLkS"
      },
      "source": [
        "## 6.5 - Fine-Tune on SQuAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKMFi-Oy3JHL"
      },
      "source": [
        "Now it is the moment to train the model for our specific task. We can use an instance of [`Trainer`](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainer#transformers.Trainer) class in order to avoid many lines of code. The most important is the [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUKFtfhi58BY"
      },
      "source": [
        "from transformers import TrainingArguments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNvT62_G3SMm"
      },
      "source": [
        "#@title 6.5.1 - Hyperparameters Selection\n",
        "batch_size =  16#@param {type:\"integer\"}\n",
        "learning_rate = 5e-5 #@param {type:\"number\"}\n",
        "epochs =  3#@param {type:\"integer\"}\n",
        "epsilon = 1e-8 #@param {type:\"number\"}\n",
        "weight_decay=0.01 #@param {type:\"number\"}\n",
        "qa_dir = Path('question_answering')\n",
        "strategy = 'epoch'\n",
        "\n",
        "args = TrainingArguments(\n",
        "    qa_dir,\n",
        "    evaluation_strategy = strategy,\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=epochs,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_dir= 'squad_logs',\n",
        "    logging_strategy=strategy,\n",
        "    load_best_model_at_end=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzb8iZf5LQQg"
      },
      "source": [
        "For example, in this case we set the evaluation to be done at the end of each epoch in `evaluation_strategy`. Customize batch size per GPU core for training `per_device_train_batch_size` and evaluation `per_device_eval_batch_size`. In addition to give values for the total number of epochs to perform `num_train_epohs`, `learning_rate` and `weight_decay`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DUzYVcWPV5Z"
      },
      "source": [
        "Then it is only needed to pass the arguments and dataset to [`Trainer`](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainer#transformers.Trainer). The data collator will batch our processed examples together. The tokenizer is used again in order to perfom padding according to the model's preferences: rigth or left and with which token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRjT5yTnZDI6"
      },
      "source": [
        "from transformers import Trainer, default_data_collator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcSaL_qe6HI9"
      },
      "source": [
        "trainer = Trainer(\n",
        "    bert_qa,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=default_data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDFqOt-4QW8q"
      },
      "source": [
        "In order to fine-tune the model it is only required to call the [`train`](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainer#transformers.Trainer.train) method for [`Trainer`](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainer#transformers.Trainer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "-kiqohIHQc2R",
        "outputId": "61abedef-7431-4473-c7ef-79dd470361d4"
      },
      "source": [
        "info_device()    \n",
        "out = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using GPU Tesla V100-SXM2-16GB. \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11124' max='11124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11124/11124 1:23:20, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.329400</td>\n",
              "      <td>1.086206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.718000</td>\n",
              "      <td>1.077027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.408300</td>\n",
              "      <td>1.287688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFsuoranIfjQ"
      },
      "source": [
        "Now it is necesary to perform some operation to get the final results. We need to load the saved checkpoint and extract the information. Mention Hugging Face does not provide the training time per epoch, only total one. Due to that, we assume an equal distribution of time in each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHbVFmrCCOqc"
      },
      "source": [
        "checkpoint = qa_dir/f'checkpoint-{out.global_step}/trainer_state.json'\n",
        "\n",
        "with open(checkpoint) as json_file:\n",
        "    train_dic = json.load(json_file)\n",
        "\n",
        "total_train_time = out.metrics['train_runtime']\n",
        "training_stats = []\n",
        "for i in range(epochs):\n",
        "    training_stats.append(\n",
        "                {\n",
        "                    'epoch': i + 1,\n",
        "                    'Training Loss': train_dic['log_history'][i*2]['loss'],\n",
        "                    'Validation Loss': train_dic['log_history'][i*2+1]['eval_loss'],\n",
        "                    'Validation Time':  format_time(train_dic['log_history'][i*2+1]['eval_runtime'])\n",
        "                }\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfjbYPTqDt4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c21e4e66-fbc8-4106-c11d-d1709f926d9a"
      },
      "source": [
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats['Training Time'] = format_time(total_train_time/epochs)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats = df_stats[['Training Loss', 'Validation Loss', 'Training Time', 'Validation Time']]\n",
        "\n",
        "# Save data frame\n",
        "df_stats.to_excel(qa_dir/'training_stats.xlsx')\n",
        "\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.3294</td>\n",
              "      <td>1.086206</td>\n",
              "      <td>0:27:47</td>\n",
              "      <td>0:01:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7180</td>\n",
              "      <td>1.077027</td>\n",
              "      <td>0:27:47</td>\n",
              "      <td>0:01:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4083</td>\n",
              "      <td>1.287688</td>\n",
              "      <td>0:27:47</td>\n",
              "      <td>0:01:16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Validation Loss Training Time Validation Time\n",
              "epoch                                                              \n",
              "1             1.3294         1.086206       0:27:47         0:01:16\n",
              "2             0.7180         1.077027       0:27:47         0:01:16\n",
              "3             0.4083         1.287688       0:27:47         0:01:16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzyvvSLKHdGF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "004e3837-d6f6-495f-ec09-8b839c21e506"
      },
      "source": [
        "plot_loss_curves(df_stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w13kj3lHKLIv"
      },
      "source": [
        "Save the model and the corresponding state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4KKmHUcJeQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7dfcc2-b315-475d-98ac-43669434c88a"
      },
      "source": [
        "print('Saving model, tokenizer and training arguments...')\n",
        "trainer.save_model()\n",
        "trainer.save_state()\n",
        "\n",
        "print('Saving training statistics..')\n",
        "save_json(qa_dir/'training_stats.json', training_stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model and training arguments...\n",
            "Saving training statistics..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2R7Zlxw_JCf"
      },
      "source": [
        "And if we want to load it again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUK3eaRs_Lum"
      },
      "source": [
        "bert_qa = BertForQuestionAnswering.from_pretrained(qa_dir)\n",
        "bert_qa.to(device)\n",
        "trainer = Trainer(\n",
        "    bert_qa,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=default_data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv56bYwLH1IG"
      },
      "source": [
        "## 6.6 - Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xr8LoOJWdpV"
      },
      "source": [
        "Once the model is trained, in order to perform the predictions and get an intuition about the result, we need to map the predictions back to parts of the context. The model itself predicts logits for the start and end position of our answers. The output of the model is a dict-like object that contains the loss (since we provided labels), the start and end logits. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ2CpVHdH5Ic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3a01c7-eb94-4184-a3b3-8a082a1c11af"
      },
      "source": [
        "for batch in trainer.get_test_dataloader(tokenized_datasets['test']):\n",
        "    break\n",
        "batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n",
        "with torch.no_grad():\n",
        "    output = bert_qa(**batch)\n",
        "\n",
        "print('Output of the model')\n",
        "print(output.keys())\n",
        "print('\\nDimension start and end logits')\n",
        "print(tuple(output.start_logits.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output of the model\n",
            "odict_keys(['loss', 'start_logits', 'end_logits'])\n",
            "\n",
            "Dimension start and end logits\n",
            "(16, 384)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_dH31wtYt8U"
      },
      "source": [
        "There is one logit per feature and token. One idea to predict an answer is to take the index for the maximum of the start logits as a star position and the index of the maximum of the ends logits as an end position. The problem is if this prediction gives us an impossible result, as a greater start position than the end one.\n",
        "\n",
        "To classify the answer, we add the start and end logits to obtain a score. With hyper-parameter `n_best_size` we limit the possible answers. Best indices in the start and end logits are picked and gather all the answers this predicts. After checking if each one is valid, we will sort them by their score and keep the best one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mwi1uEyE7Fo"
      },
      "source": [
        "And then we can sort the `valid_answers` according to their `score` and only keep the best one. The only point left is how to check a given span is inside the context (and not the question) and how to get back the text inside. To do this, we need to add two things to our validation features:\n",
        "- the ID of the example that generated the feature (since each example can generate several features, as seen before);\n",
        "- the offset mapping that will give us a map from token indices to character positions in the context.\n",
        "\n",
        "That's why we will re-process the validation set with the following function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQVj0dCbNJbl"
      },
      "source": [
        "def prepare_test_features(examples):\n",
        "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
        "        # position is part of the context or not.\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == 1 else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1oLfP50bSAU"
      },
      "source": [
        "And like before, we can apply that function to our test set easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ysa43PrQhhE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "64d974ee29b34346a1e23ab84e83da29",
            "a81b4db3b21f4787aacaabe2ee5b7589",
            "79dead5fec0d40a0be9b5e3cbac3cb78",
            "30e2db9525fa446db58f4f62531c8252",
            "d35ad4cc26194ae989ec0a43a935439a",
            "c8538d594f594a7caa35aaec126c89f1",
            "9c015fc852ad4c13882d5c2e6dda7d7a",
            "883a8c99d8214c9ab23d505bec2386ea"
          ]
        },
        "outputId": "b77b510d-ff5d-4248-b047-a44b188805e2"
      },
      "source": [
        "test_features = datasets['test'].map(\n",
        "    prepare_test_features,\n",
        "    batched=True,\n",
        "    remove_columns=datasets['test'].column_names\n",
        ")\n",
        "test_features = test_features.add_column('start_positions', tokenized_datasets['test']['start_positions'])\n",
        "test_features = test_features.add_column('end_positions', tokenized_datasets['test']['end_positions'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64d974ee29b34346a1e23ab84e83da29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnN3-DI6bXG2"
      },
      "source": [
        "Now we can get the predictions and the metrics for all features by using the [`predict`](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainer%20predict#transformers.Trainer.predict)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7aw7mq9RM0F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "984dfa3a-12b8-4ad2-cbed-74ef3498fafc"
      },
      "source": [
        "info_device()\n",
        "print('Testing\\n')\n",
        "raw_predictions = trainer.predict(test_features)\n",
        "\n",
        "test_stats = {\n",
        "    'test_loss': raw_predictions.metrics['test_loss'],\n",
        "    'test_runtime': format_time(raw_predictions.metrics['test_runtime'])\n",
        "}\n",
        "\n",
        "print('\\n')\n",
        "print(f\"{'Test Loss':^12} | {'Test time':^11}\")\n",
        "print(\"-\"*27)\n",
        "print(f\"{test_stats['test_loss']:^12.6f} | {test_stats['test_runtime']:^11}\")\n",
        "print(\"-\"*27)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using GPU Tesla V100-SXM2-16GB. \n",
            "\n",
            "Testing\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1826' max='1826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1826/1826 03:49]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Test Loss   |  Test time \n",
            "---------------------------\n",
            "  1.022919   |   0:03:49  \n",
            "---------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tq29b5KZJQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83dd848a-9230-473a-c4d4-3f9b21a54e37"
      },
      "source": [
        "print('Saving test statistics...')\n",
        "save_json(qa_dir/'test_stats.json', test_stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving test statistics...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbG4KyzJbut_"
      },
      "source": [
        "The `Trainer` *hides* the columns that are not used by the model (here `example_id` and `offset_mapping` which we will need for our post-processing), so we set them back:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0d33x7Me3OW"
      },
      "source": [
        "test_features.set_format(type=test_features.format[\"type\"], columns=list(test_features.features.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkeV1CEqcHsW"
      },
      "source": [
        "We set `None` in the offset mappings when it corresponds to a part of the question, so it's easy to check if an answer is fully inside the context. We also eliminate very long answers from our considerations with hyper-parameter `max_answer_length`.\n",
        "\n",
        "We also need a map between examples and their corresponding features. Also, we gather together all the answers in all the features generated by a given example, then pick the best one.\n",
        "\n",
        "The last bit to deal with is the impossible answer (when `squad_v2 = True`). We need to also grab the score for the impossible answer (which has start and end indices corresponding to the index of the CLS token). When one example gives several features, we have to predict the impossible answer when all the features give a high score to the impossible answer, since one feature could predict the impossible answer just because the answer isn't in the part of the context it has access too. We then predict the impossible answer when that score is greater than the score of the best non-impossible answer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpR-1V_cwz8O"
      },
      "source": [
        "import collections\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def postprocess_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
        "    m = nn.Softmax(dim=1)\n",
        "    all_start_logits, all_end_logits = raw_predictions\n",
        "    # Build a map example to its corresponding features.\n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = collections.defaultdict(list)\n",
        "    for i, feature in enumerate(features):\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "    # The dictionaries we have to fill.\n",
        "    predictions = collections.OrderedDict()\n",
        "\n",
        "    # Logging.\n",
        "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
        "\n",
        "    # Let's loop over all the examples!\n",
        "    for example_index, example in enumerate(tqdm(examples)):\n",
        "        # Those are the indices of the features associated to the current example.\n",
        "        feature_indices = features_per_example[example_index]\n",
        "\n",
        "        min_null_score = None # Only used if squad_v2 is True.\n",
        "        valid_answers = []\n",
        "        \n",
        "        context = example[\"context\"]\n",
        "        # Looping through all the features associated to the current example.\n",
        "        for feature_index in feature_indices:\n",
        "            # We grab the predictions of the model for this feature.\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
        "            # context.\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            # Update minimum null prediction.\n",
        "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
        "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
        "            if min_null_score is None or min_null_score < feature_null_score:\n",
        "                min_null_score = feature_null_score\n",
        "\n",
        "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
        "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                    # to part of the input_ids that are not in the context.\n",
        "                    if (\n",
        "                        start_index >= len(offset_mapping)\n",
        "                        or end_index >= len(offset_mapping)\n",
        "                        or offset_mapping[start_index] is None\n",
        "                        or offset_mapping[end_index] is None\n",
        "                    ):\n",
        "                        continue\n",
        "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                        continue\n",
        "\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    valid_answers.append(\n",
        "                        {\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                            \"text\": context[start_char: end_char]\n",
        "                        }\n",
        "                    )\n",
        "        \n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
        "\n",
        "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
        "        if not squad_v2:\n",
        "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
        "        else:\n",
        "            predictions[example[\"id\"]] = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else ''\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MbIqiaakkbH"
      },
      "source": [
        "And we can apply our post-processing function to our raw predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trrh8PkOerpE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "7b2925cf924a4c1b9ed4e9c04946eac9",
            "628dc2219a0c433e94a47ed23abcdb8a",
            "110fb8ae4b8b4d769a06ed28d865bfd7",
            "8fffe27c5aaa49d1940455a2a74fee22",
            "9ccdda2c8aba44598cf3f3d37f59acfc",
            "60419ef214d64c19ac613ac1c64f40c0",
            "93809beebdce4b5fa05b601e1f7caf1c",
            "8a6966989e534c0e8e6b7fcaecd8983c"
          ]
        },
        "outputId": "a1cd2591-54b8-4d1d-f9c2-a831d0623aa5"
      },
      "source": [
        "final_predictions = postprocess_predictions(datasets['test'], test_features, raw_predictions.predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Post-processing 28908 example predictions split into 29209 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b2925cf924a4c1b9ed4e9c04946eac9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28908.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHwf6B2iNKDI"
      },
      "source": [
        "Now it is necessary to indicate how to compute metrics from the predictions. We use a [`metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric) which is in charge of compute the corresponding metrics for each model. We load it using the class method [`load_metric`](https://huggingface.co/docs/datasets/v1.4.1/package_reference/loading_methods.html?highlight=load_metric#datasets.load_metric)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu29AdtVe-kd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577,
          "referenced_widgets": [
            "8484a0bfcf0841f093c1ce69d348ca1d",
            "cf69768a777b4f4b9258c86fc062f079",
            "24c9f41ff2c64a5c8bc6506a65ddb14a",
            "ca73b6a35d3446fc9284816e830de84c",
            "b0d0f0b646534c7da04db2eb0fc79930",
            "84ad0a35fb024434bf8677841d8a96e3",
            "55bca16ee108408f921a5b59124fc3f2",
            "f2edf729d2a44cc28fbecd5d481accc6",
            "8f10d3549f244fc386416f0befdfcf78",
            "777a4312aaec410aa65e1fd60bef3dc8",
            "24ff47fed31942fa944c14a7de11f3d6",
            "30c283d72bfb4023a9ef6010f47a1aae",
            "d684d83cd49a4b6e8f95ca9384a3b99e",
            "8e929ea257f441a0a0311bd26f44c350",
            "3c252d2d260643aaad00da4a543d3a6e",
            "7c95955470ee42c69473bcf647ce1e86"
          ]
        },
        "outputId": "a5d0ecdc-28b2-44fb-b7b1-1f6c62587f5f"
      },
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")\n",
        "metric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8484a0bfcf0841f093c1ce69d348ca1d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1726.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f10d3549f244fc386416f0befdfcf78",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1119.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metric(name: \"squad\", features: {'predictions': {'id': Value(dtype='string', id=None), 'prediction_text': Value(dtype='string', id=None)}, 'references': {'id': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}}, usage: \"\"\"\n",
              "Computes SQuAD scores (F1 and EM).\n",
              "Args:\n",
              "    predictions: List of question-answers dictionaries with the following key-values:\n",
              "        - 'id': id of the question-answer pair as given in the references (see below)\n",
              "        - 'prediction_text': the text of the answer\n",
              "    references: List of question-answers dictionaries with the following key-values:\n",
              "        - 'id': id of the question-answer pair (see above),\n",
              "        - 'answers': a Dict in the SQuAD dataset format\n",
              "            {\n",
              "                'text': list of possible texts for the answer, as a list of strings\n",
              "                'answer_start': list of start positions for the answer, as a list of ints\n",
              "            }\n",
              "            Note that answer_start values are not taken into account to compute the metric.\n",
              "Returns:\n",
              "    'exact_match': Exact match (the normalized answer exactly match the gold answer)\n",
              "    'f1': The F-score of predicted tokens versus the gold answer\n",
              "Examples:\n",
              "\n",
              "    >>> predictions = [{'prediction_text': '1976', 'id': '56e10a3be3433e1400422b22'}]\n",
              "    >>> references = [{'answers': {'answer_start': [97], 'text': ['1976']}, 'id': '56e10a3be3433e1400422b22'}]\n",
              "    >>> squad_metric = datasets.load_metric(\"squad\")\n",
              "    >>> results = squad_metric.compute(predictions=predictions, references=references)\n",
              "    >>> print(results)\n",
              "    {'exact_match': 100.0, 'f1': 100.0}\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrcNU7OykqAU"
      },
      "source": [
        "We just need to format predictions and labels a bit as it expects a list of dictionaries and not one big dictionary. In the case of squad_v2, we also have to set a `no_answer_probability` argument which we set to 0.0.\n",
        "\n",
        "Metrics computation returns:\n",
        "    \n",
        "- `exact_match`: exact match (the normalized answer exactly match the gold answer).\n",
        "\n",
        "- `f1`: the F-score of predicted tokens versus the gold answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXzmbIchfLgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42dd3c0b-bf35-4e39-ab8e-773ec4607b67"
      },
      "source": [
        "if squad_v2:\n",
        "    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
        "else:\n",
        "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
        "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets['test']]\n",
        "scores = metric.compute(predictions=formatted_predictions, references=references)\n",
        "\n",
        "print(f\"{'Exact match':^13} | {'f1 score':^10}\")\n",
        "print(26*'-')\n",
        "print(f\"{scores['exact_match']:^13.5f} | {scores['f1']:^10.5f}\")\n",
        "print(26*'-')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Exact match  |  f1 score \n",
            "--------------------------\n",
            "  67.40349    |  80.89019 \n",
            "--------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z70BC9qnnH2I"
      },
      "source": [
        "def show_predictions(dataset, predictions, num_examples):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    df.drop(['id', 'title'], axis=1, inplace=True)\n",
        "    df['answers'] = df['answers'].map(lambda dic: dic['text'][0]).values\n",
        "    df['predicted answers'] = [predictions[idx]['prediction_text'] for idx in picks]\n",
        "    df = df[['context', 'question', 'answers', 'predicted answers']]\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
        "    display(HTML(df.to_html()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kojOMeuaoi5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "c1bca3ce-0453-4d76-cb80-e52a80fb8420"
      },
      "source": [
        "#@markdown Select number of examples to visualize it\n",
        "num_examples = 3 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "show_predictions(datasets['test'], formatted_predictions, num_examples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "      <th>predicted answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The city also has a number of other, smaller newspapers and magazine in circulation such as the Philadelphia Tribune, which serves the African-American community, the Philadelphia, a monthly regional magazine; Philadelphia Weekly, an weekly-printed alternative newspaper; Philadelphia City Paper another weekly-printed newspaper; Philadelphia Gay News, which services the LGBT community; The Jewish Exponent a weekly-printed newspaper servicing the Jewish community; Philadelphia Metro, free daily newspaper; and Al Día, a weekly newspaper servicing the Latino community.</td>\n",
              "      <td>Name a smaller newspaper?</td>\n",
              "      <td>Philadelphia Tribune</td>\n",
              "      <td>all current commercial and laboratory lines are considered to have originated from this population.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Boston was an early port of the Atlantic triangular slave trade in the New England colonies, but was soon overtaken by Salem, Massachusetts and Newport, Rhode Island. Eventually Boston became a center of the abolitionist movement. The city reacted strongly to the Fugitive Slave Law of 1850, contributing to President Franklin Pierce's attempt to make an example of Boston after the Anthony Burns Fugitive Slave Case.</td>\n",
              "      <td>What movement did Boston become the center of after it stopped slave trade?</td>\n",
              "      <td>the abolitionist movement</td>\n",
              "      <td>December 2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Von Braun and his team were sent to the United States Army's White Sands Proving Ground, located in New Mexico, in 1945. They set about assembling the captured V2s and began a program of launching them and instructing American engineers in their operation. These tests led to the first rocket to take photos from outer space, and the first two-stage rocket, the WAC Corporal-V2 combination, in 1949. The German rocket team was moved from Fort Bliss to the Army's new Redstone Arsenal, located in Huntsville, Alabama, in 1950. From here, von Braun and his team would develop the Army's first operational medium-range ballistic missile, the Redstone rocket, that would, in slightly modified versions, launch both America's first satellite, and the first piloted Mercury space missions. It became the basis for both the Jupiter and Saturn family of rockets.</td>\n",
              "      <td>Von Braun and his associates were sent to  United States Army's White Sands Proving Ground in what year?</td>\n",
              "      <td>1945</td>\n",
              "      <td>one or both parents</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5RmM7PStRs8"
      },
      "source": [
        "### 6.6.1 - Pipeline for Custom Sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2UW-J8ZtZrZ"
      },
      "source": [
        "In order to get a fast intuiton about the application, let's define a pipeline to process and try to answer to a question from our own text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXsY72rh1NF_"
      },
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "def bert_for_qa(context, question, trainer, id='0'):\n",
        "    # Generate dataset from input data\n",
        "    dataset = Dataset.from_dict(\n",
        "        {'id': [id], 'context': [context], 'question': [question]}\n",
        "    )\n",
        "    # Preprocess data\n",
        "    features = dataset.map(\n",
        "        prepare_test_features,\n",
        "        batched=True,\n",
        "        remove_columns=dataset.column_names\n",
        "    )\n",
        "    # Predictions\n",
        "    predictions = trainer.predict(features)\n",
        "    # Postprocess data\n",
        "    processed_predictions = postprocess_predictions(dataset, features, predictions.predictions)\n",
        "    # Return answer\n",
        "    return processed_predictions[id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUQk4hhc1GYh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "a6e3d15baec24120b3c367ca80678568",
            "8f8268933c86452eb34abd1838a2ccbc",
            "26d33194cf9b4bf298e14a270e324bae",
            "c14e3520b77542159ebe28d15a7bbed8",
            "0474700018be4e4d970483e4fff94b1b",
            "5f2c3d64a809431f89e3ede6be9c39d1",
            "14bcd76be7d24a2fa51618074c92fec2",
            "8864580db2db4f9791d45bf8328919c1",
            "305834880de044beb14e8b89191710b1",
            "11d6a2566cd641c08e25491e01b2bd8a",
            "979984a1e3ad4d25a6e6698864bca662",
            "2d6fff80042c49479d6b134f74171541",
            "a066cf72c1064964ab21f2021a40f7c3",
            "d16af42af3b940afa8503bd5d4db2190",
            "85fa2f4f0a6f4b169966df5d7807f3b0",
            "3a1b45412cac469383e238a73ed356e6"
          ]
        },
        "cellView": "form",
        "outputId": "9497c348-4a58-4bc2-daf8-50dc804f9d4e"
      },
      "source": [
        "#@title { vertical-output: true }\n",
        "context = \"BERT is the best model for NLP, so much better than RNNs... I love it!\" #@param {type:\"string\"}\n",
        "question = \"Which model do I love?\" #@param {type:\"string\"}\n",
        "answer = bert_for_qa(context, question, trainer)\n",
        "\n",
        "print('\\nThe predicted answer is\\n')\n",
        "print(answer)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6e3d15baec24120b3c367ca80678568",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 29:29]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Post-processing 1 example predictions split into 1 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "305834880de044beb14e8b89191710b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The predicted answer is\n",
            "\n",
            "BERT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuyFHz59oCNt"
      },
      "source": [
        "To donwload it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhOP8g9MoBzP"
      },
      "source": [
        "download_folder(qa_dir)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
