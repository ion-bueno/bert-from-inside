{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bert_from_inside",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eed17105d92e44239e8dc9be5ea3c706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f08631001b6f465bb05c6607d47af343",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d53c15aaa60c4d3dac2c6798df06116f",
              "IPY_MODEL_f90870fe55f746e3a4bb6bf1f45aa5af"
            ]
          }
        },
        "f08631001b6f465bb05c6607d47af343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d53c15aaa60c4d3dac2c6798df06116f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96a3b0df54bd4a2da54d12fbb1734f8d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0418c437d03a4c6fbc080ff62d78369b"
          }
        },
        "f90870fe55f746e3a4bb6bf1f45aa5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_73f14a5f40014f9b9543e9cbf1047bca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 694B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_353bb1503d7b4e11b81a97db53c86518"
          }
        },
        "96a3b0df54bd4a2da54d12fbb1734f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0418c437d03a4c6fbc080ff62d78369b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73f14a5f40014f9b9543e9cbf1047bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "353bb1503d7b4e11b81a97db53c86518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d157f96fbda1481b902cc9928144f4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0573f5c28d734881a9b9d88b45384ec9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2203cd949c644eba9727edd11198d475",
              "IPY_MODEL_7513e90105be4df6bfc390fdd1bee470"
            ]
          }
        },
        "0573f5c28d734881a9b9d88b45384ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2203cd949c644eba9727edd11198d475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d5e319cf29b495d9e92725bd24e88fa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c69662f5bdb84b0d8587d2d43a0d3235"
          }
        },
        "7513e90105be4df6bfc390fdd1bee470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db735268868e43f190bdc99ed2ec8053",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:21&lt;00:00, 20.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_530b61cdc72e467a99a5f4134c94e8d6"
          }
        },
        "2d5e319cf29b495d9e92725bd24e88fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c69662f5bdb84b0d8587d2d43a0d3235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db735268868e43f190bdc99ed2ec8053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "530b61cdc72e467a99a5f4134c94e8d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ace10f1bac344bd097eeb4bf740f8190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_46448d09808e46d18c47dc56b43a48a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d78faaa864a487387a4a5f4cdee7c35",
              "IPY_MODEL_f75126cff7bd4761ba6b2d86f5cf81ac"
            ]
          }
        },
        "46448d09808e46d18c47dc56b43a48a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d78faaa864a487387a4a5f4cdee7c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6133a68ea3b243a794fddc44a9f14640",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_812090fb5d634ff2990df26c72ba32fa"
          }
        },
        "f75126cff7bd4761ba6b2d86f5cf81ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b98c6cb3c3254a40a9e0062d7f3818e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:05&lt;00:00, 44.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed10841c114f45ef8e614c6ea6515847"
          }
        },
        "6133a68ea3b243a794fddc44a9f14640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "812090fb5d634ff2990df26c72ba32fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b98c6cb3c3254a40a9e0062d7f3818e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed10841c114f45ef8e614c6ea6515847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d404716eddac4c9a9bcefbd580e77ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3894ec6f711944b2859240678c7e8c54",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c655b880806c42f09f40d43cc02157ab",
              "IPY_MODEL_07a5b51d786c4e90bfb8e798cbbff6e0"
            ]
          }
        },
        "3894ec6f711944b2859240678c7e8c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c655b880806c42f09f40d43cc02157ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39443ef61eb54a2f9dc970ef679deb55",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55f0863f26dd484f81466bf953d69f84"
          }
        },
        "07a5b51d786c4e90bfb8e798cbbff6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd0ed33b9ed04ae8899dab053f115f5d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:01&lt;00:00, 18.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_230462d1065c40d0aed8bda2bd96ebed"
          }
        },
        "39443ef61eb54a2f9dc970ef679deb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55f0863f26dd484f81466bf953d69f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd0ed33b9ed04ae8899dab053f115f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "230462d1065c40d0aed8bda2bd96ebed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97dda1f3205442ba9a717f2dd0dec45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_08ef3b639c434f12ae73d67fd78a875f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_27ac5f42541d4e9996feb4221a5eed66",
              "IPY_MODEL_7ee52677e4f645058711d4edf68de5a7"
            ]
          }
        },
        "08ef3b639c434f12ae73d67fd78a875f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27ac5f42541d4e9996feb4221a5eed66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f6c512a3be8d425996ba02c084714ecc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d43fe1a66e1842c3a7ff3abe07e542f0"
          }
        },
        "7ee52677e4f645058711d4edf68de5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_500520ae8d8a4b07a9d4ffbdac2d6747",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 834kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9eff15c520f64aa6a3ac6721bff56aba"
          }
        },
        "f6c512a3be8d425996ba02c084714ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d43fe1a66e1842c3a7ff3abe07e542f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "500520ae8d8a4b07a9d4ffbdac2d6747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9eff15c520f64aa6a3ac6721bff56aba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9682d236b1f14f6d9a5d466458beaf2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_47778129b21e4b1ab88750557e39e94f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c3a7fb759c124063ae0285bb32f2c1dc",
              "IPY_MODEL_bf771ae5914e49fc9ef88fc9c581cc4a"
            ]
          }
        },
        "47778129b21e4b1ab88750557e39e94f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3a7fb759c124063ae0285bb32f2c1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7165d4ad4e8e42aa89c2f21b38cb80da",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1947,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1947,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea8bab9736b04550830b373d4c2be1a9"
          }
        },
        "bf771ae5914e49fc9ef88fc9c581cc4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_de2728dda4f44ade9a3c7cd7d19ab3b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.29k/? [00:00&lt;00:00, 35.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81d3896278af46be83a0e30c1f62c605"
          }
        },
        "7165d4ad4e8e42aa89c2f21b38cb80da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea8bab9736b04550830b373d4c2be1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de2728dda4f44ade9a3c7cd7d19ab3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81d3896278af46be83a0e30c1f62c605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fda5d278f3b4f2b88ab1aa9d4e7a94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9bac08a97d654a06b730793e8ac2b644",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_74820ca738db4e8c96d66c828e9fded9",
              "IPY_MODEL_e2cc18176eef4f90ac0db167cce4f861"
            ]
          }
        },
        "9bac08a97d654a06b730793e8ac2b644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74820ca738db4e8c96d66c828e9fded9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b536b3f2aaca49b1b70c74915d8ed455",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1021,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1021,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bec704dba23e423bb09444a0ed868238"
          }
        },
        "e2cc18176eef4f90ac0db167cce4f861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_304d22a9fd2c4c1b955f919289af3de2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.36k/? [00:02&lt;00:00, 1.12kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99fef41754a646b4a531968196b7acab"
          }
        },
        "b536b3f2aaca49b1b70c74915d8ed455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bec704dba23e423bb09444a0ed868238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "304d22a9fd2c4c1b955f919289af3de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99fef41754a646b4a531968196b7acab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af2f5508bfbc4f6a96fda3101304b387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e4104d3257144f6a85fc3fdb817760c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3abf36e368e94f9c8e6820a8a3a60590",
              "IPY_MODEL_3638be53fa8145bdaf4208489d0b079b"
            ]
          }
        },
        "4e4104d3257144f6a85fc3fdb817760c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3abf36e368e94f9c8e6820a8a3a60590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_903d87fa836e473e9a31a8cf1c6a7601",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 8116577,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8116577,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c08438a1ecd141ed95c8809f7ddcf26a"
          }
        },
        "3638be53fa8145bdaf4208489d0b079b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d661376dd5c44332856da9a4cf9f1335",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30.3M/? [00:01&lt;00:00, 25.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3e9571a2e084e4b8ac16cfc38ddf1b4"
          }
        },
        "903d87fa836e473e9a31a8cf1c6a7601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c08438a1ecd141ed95c8809f7ddcf26a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d661376dd5c44332856da9a4cf9f1335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3e9571a2e084e4b8ac16cfc38ddf1b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56272bb483334c329af56692f981f050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_696bb5681ac14789a0fe45dc4d3a23a9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9861ef684f24462e8c1b03f13bfeb070",
              "IPY_MODEL_a9c62bbb8c2046d99685920827122b2a"
            ]
          }
        },
        "696bb5681ac14789a0fe45dc4d3a23a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9861ef684f24462e8c1b03f13bfeb070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb761a3d3d2b4c728355fff2da6eb0e1",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1054280,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1054280,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df3a2f22afba4d2f94299f8e24d20d3b"
          }
        },
        "a9c62bbb8c2046d99685920827122b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_59d29630173a443ca1f84f58bfbbe90d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.85M/? [00:00&lt;00:00, 19.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1395c770ef2c4eccacd3efd627f7ced1"
          }
        },
        "fb761a3d3d2b4c728355fff2da6eb0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df3a2f22afba4d2f94299f8e24d20d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59d29630173a443ca1f84f58bfbbe90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1395c770ef2c4eccacd3efd627f7ced1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "baf5d5a70d36492e80a67eb99ba37ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95439036f19a46e193e8c04380860f95",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3179ea28629f4313a06aca487eef4642",
              "IPY_MODEL_d181b174002f430bb165690b4ea29906"
            ]
          }
        },
        "95439036f19a46e193e8c04380860f95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3179ea28629f4313a06aca487eef4642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_00b68ebfab9241968a60d44cb5793d51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_580eac65ec364d73a8d960720d0848bc"
          }
        },
        "d181b174002f430bb165690b4ea29906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6b5c3c5f5315449884342c00676a7a5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87599/0 [00:06&lt;00:00, 17923.22 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9654cd217684f67b77d2849d320f7e8"
          }
        },
        "00b68ebfab9241968a60d44cb5793d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "580eac65ec364d73a8d960720d0848bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b5c3c5f5315449884342c00676a7a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9654cd217684f67b77d2849d320f7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "412d827f4dfd4ca8ad0322c5567d7828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6cd09dff9f924afaa57cfb1b1d333850",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3b44acac8de2465b84b8785e4e422c4e",
              "IPY_MODEL_0a469f0faa434535981653caeee2220d"
            ]
          }
        },
        "6cd09dff9f924afaa57cfb1b1d333850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b44acac8de2465b84b8785e4e422c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b34d0eea570e4ff7beb9162fcb821be6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e742895551814aab9e238de77ee6ac1f"
          }
        },
        "0a469f0faa434535981653caeee2220d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e10b062314724548a1b016c0e08a014b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10570/0 [00:01&lt;00:00, 8790.63 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b2c7595672c4c0ead0d9bc2ae217e25"
          }
        },
        "b34d0eea570e4ff7beb9162fcb821be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e742895551814aab9e238de77ee6ac1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e10b062314724548a1b016c0e08a014b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b2c7595672c4c0ead0d9bc2ae217e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5ed8e38e4b4407d83b5d9c6516ad618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f892028c9bc4c6b9cea9f0d2e353dc2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c3b92a65cd0a4012842d73c4086088c8",
              "IPY_MODEL_54d404bf1a8d4b4aaefed7782383ecde"
            ]
          }
        },
        "2f892028c9bc4c6b9cea9f0d2e353dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3b92a65cd0a4012842d73c4086088c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c881957e5ca34a188462b064d9bfb4eb",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6202167ee6d345b2b29089f11e4ed2f1"
          }
        },
        "54d404bf1a8d4b4aaefed7782383ecde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b90775d537f469f86a502fc639c4ddb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59/59 [00:30&lt;00:00,  1.97ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f15ef64c5184a0e939a3ad73493b9c2"
          }
        },
        "c881957e5ca34a188462b064d9bfb4eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6202167ee6d345b2b29089f11e4ed2f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b90775d537f469f86a502fc639c4ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f15ef64c5184a0e939a3ad73493b9c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d738dc2ae8ea443d995c8fb7818689e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8dba3b398bd448f5bb566cff7eff8e01",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b98e804f288642339daa0b1ab87a46df",
              "IPY_MODEL_87cc1d01fb0342cb989a5263badc7cb4"
            ]
          }
        },
        "8dba3b398bd448f5bb566cff7eff8e01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b98e804f288642339daa0b1ab87a46df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3260cd759ea049c396fc9ecf0e4057ad",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ca632cc43a74b66808c8ef7388ba68c"
          }
        },
        "87cc1d01fb0342cb989a5263badc7cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aaab5f370f714015b3e5be2e5f9165f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11/11 [00:06&lt;00:00,  1.73ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_636a9eac22bf4772947966da4279e91b"
          }
        },
        "3260cd759ea049c396fc9ecf0e4057ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ca632cc43a74b66808c8ef7388ba68c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aaab5f370f714015b3e5be2e5f9165f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "636a9eac22bf4772947966da4279e91b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da3d877e32c945aa999b7b5eebd5db03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e76b6bf40b4d440eb6ec653f0393f8fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_de9866dc89834e06bdd9ed8fe8cc2638",
              "IPY_MODEL_4905ca4ba5834a229575a8f9dcf9c361"
            ]
          }
        },
        "e76b6bf40b4d440eb6ec653f0393f8fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de9866dc89834e06bdd9ed8fe8cc2638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a64f5fc3f09941c59d0f17551f5c44f1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_feaafc37b3684796804531838d243140"
          }
        },
        "4905ca4ba5834a229575a8f9dcf9c361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f58d720e28bf4852887200a86e00fc8d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29/29 [00:16&lt;00:00,  1.72ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fedf476a7ab04330a4803d0b499606fe"
          }
        },
        "a64f5fc3f09941c59d0f17551f5c44f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "feaafc37b3684796804531838d243140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f58d720e28bf4852887200a86e00fc8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fedf476a7ab04330a4803d0b499606fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "856056c4642b4429af66ebeb631b84da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ed69ba4d23341cbb9336b0789fbf8e3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_87d0dead72df43f4b34af202e9aaddc3",
              "IPY_MODEL_39c51d45461f41a99858a7152ca4094c"
            ]
          }
        },
        "7ed69ba4d23341cbb9336b0789fbf8e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87d0dead72df43f4b34af202e9aaddc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03d48ffab67d46b7accda89888d0a85b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0e4162e8a054cefbe06d5998f966c0c"
          }
        },
        "39c51d45461f41a99858a7152ca4094c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b72447fda4c4b4cba86a3b3cd060206",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29/29 [00:49&lt;00:00,  1.71s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2827b3ba903241f8b0db34a65d5d5ba7"
          }
        },
        "03d48ffab67d46b7accda89888d0a85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0e4162e8a054cefbe06d5998f966c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b72447fda4c4b4cba86a3b3cd060206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2827b3ba903241f8b0db34a65d5d5ba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ion-bueno/bert-from-inside/blob/main/bert_from_inside.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo8tsaAo5a11"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDbShn3OWDj0"
      },
      "source": [
        "During this notebook it is used Pytorch. It is installed running next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npZ_8a2vxn7N"
      },
      "source": [
        "#!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oic_Lz0GZ6Pt"
      },
      "source": [
        "Other modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2LVsAsvOwqW"
      },
      "source": [
        "# Pytorch modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "# Colab modules\n",
        "from google.colab import files\n",
        "# Usual modules used\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmA7A_2yZ28N"
      },
      "source": [
        "Mount drive to load files from Google Drive. Useful to load trained models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KatQ5N1QI_ie"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksCpEC_5vdb_"
      },
      "source": [
        "# 1 - Background\n",
        "\n",
        "Recurrent neural networks (RNN) were declared as state of the art in sequence modeling and transduction problems, in particular long short-term memory (LSTM) and gated recurrent neural networks (GRU).\n",
        "\n",
        "These models work respect the position of the symbols, input and output. They generate a sequence of hidden states $h_t$, function of previous hidden states $h_{t-1}$ and current input $x_t$.\n",
        "\n",
        "\\begin{equation}\n",
        "  h_t = f(x_t, h_{t-1})\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByU_MM9YmQLq"
      },
      "source": [
        "![RNN](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/RNN.png)\n",
        "\n",
        "> RNN high level structure. Original image from [Dive into Deep Learning](https://d2l.ai/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL9zstqnViDC"
      },
      "source": [
        "However, RNNs are really slow to train due to the sequential computation they employ. This operations cannot be optimized with modern hardware employed today (GPUs or TPUs).\n",
        "\n",
        "Another important issue is the difficulty to capture long-term dependencies. Gradient based learning algorithms face many problems as the sequence or spans increases. Gradients can exploit or vanish, resulting in many difficulties for gradient optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHtLxnVeSryf"
      },
      "source": [
        "One novel mechanism employed was **Attention**. It is based on retaining the most significant information. It is applied between the elements of the input and the output. In translation for example, between the source sentence and the translation. Attention has been widely used for many tasks, specially in translation.\n",
        "\n",
        "In this work we are interested in one type of attention: **Self-attention**. Attention is only applied between the elements of the input sequence, relating themselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fs7sOi1O53b"
      },
      "source": [
        "# 2 - Self Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlzWfPuaNpyf"
      },
      "source": [
        "It is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. The goal is mapping sets to sets, regardless of the order in the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations. \\\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snXFyJKGRZSP"
      },
      "source": [
        "## 2.1 - Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gddSt8MOQdP6"
      },
      "source": [
        "If we have a sentence with length $ n $, each word is usually represented with a word vector $ x_i \\in \\mathbb R^{d}, i \\in \\lbrace1, \\dots, n \\rbrace $, where $ d $ is the dimension of the vector. This parameter depends on the size of embedding we are using. \n",
        "\n",
        "\\begin{array}\n",
        "  \\text{The} & \\text{orange} & \\text{is} & \\text{very} & \\text{healthy} \\\\\n",
        "  x_1 & x_2 & x_3 & x_4 & x_5\n",
        "\\end{array}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_ZPAha90o8p",
        "outputId": "f605383c-e44f-43bb-d826-4071a791f5d4"
      },
      "source": [
        "#@title { vertical-output: true }\n",
        "sentence = \"The orange is very healthy\" #@param {type:\"string\"}\n",
        "list_sentence = sentence.split()\n",
        "#@markdown Dimension of the embedding vector\n",
        "d =  3#@param {type:\"number\"}\n",
        "vocab = set(list_sentence)\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "embeds = nn.Embedding(len(word_to_ix), d)\n",
        "\n",
        "for word in list_sentence:\n",
        "  lookup_tensor = torch.tensor(word_to_ix[word], dtype=torch.long)\n",
        "  vector = embeds(lookup_tensor)\n",
        "  print(word)\n",
        "  print(vector.detach().numpy(), '\\n')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The\n",
            "[ 0.2972846  1.1454724 -0.9478285] \n",
            "\n",
            "orange\n",
            "[-1.005168    0.11030454  1.4334269 ] \n",
            "\n",
            "is\n",
            "[ 0.8999159   1.0623589  -0.44568616] \n",
            "\n",
            "very\n",
            "[-0.65508276 -0.32948834 -1.4258631 ] \n",
            "\n",
            "healthy\n",
            "[0.36417076 1.0811074  1.3970529 ] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQiDwc4JybzS"
      },
      "source": [
        "These vectors do not provide context information, i.e. the relationship with the rest of the elements in the sequence. For example, $ x_2 $ does not determine if *orange* refers to the color or to the fruit, so it is not clear if it exists a clear relationship with *healthy*.\n",
        "\n",
        "We are looking for an output vector, formed by attention weigths, $ y_i \\in \\mathbb R^{n}, i \\in \\lbrace1,\\dots,n\\rbrace $, where $ n $ is the number of elements in the sequence. For all $ i, j \\in \\lbrace{1,\\dots,n}\\rbrace $.\n",
        "\n",
        "\\begin{equation}\n",
        "  y_i = \\sum^{n}_{j} x_j w_{ij}\n",
        "\\end{equation}\n",
        "\n",
        "The question is, how could we get these weigths? In order to illustrate the process, we are going to use the previous sentence and get the weights associated to the new embedding vector for *orange* ($ y_{2} $).\n",
        "\n",
        "> Remember that $ n $ is the number of words in the sentence and $ d $ the dimension of the word vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo04Vmks3Gq0"
      },
      "source": [
        "> The explanation is based in the slides of [A series of videos on transformers](https://www.youtube.com/playlist?list=PLDw5cZwIToCvXLVY2bSqt7F2gu8y-Rqje) by Lennart Svensson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BgDkBMJ2yxK"
      },
      "source": [
        "## 2.2 - Weighted Averages of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_6qnuArbEUh"
      },
      "source": [
        "The traditional idea was based in providing larger weigths to similar words making use of the **dot product**. Two similar vectors are going to get a bigget dot product than two very distant. Applying the dot product and softmax respect $ x_2 $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqoYDolEOJdg"
      },
      "source": [
        "\\begin{equation}\n",
        "  \\begin{matrix} z_{1} = x_1^T x_2 & \\dots & z_{n} = x_n^T x_2 \\end{matrix} \\\\\n",
        "  \\begin{bmatrix} w_{1} & \\dots & w_{n} \\end{bmatrix} = \\text{softmax} \\begin{pmatrix} z_{1} & \\dots & z_{n} \\end{pmatrix} \\\\\n",
        "  y_2 = \\sum_{j=1}^{n} x_j w_{j}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRMYg52-XN6d"
      },
      "source": [
        "![Weighted Averaged of Words](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/weight_ave_words.png)\n",
        "\n",
        "> Observations and weights respect time. Original image from [A series of videos on transformers](https://www.youtube.com/playlist?list=PLDw5cZwIToCvXLVY2bSqt7F2gu8y-Rqje)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7WPCEYKYbh_"
      },
      "source": [
        "Intuitively, it is a method which could obatin good results. Nevertheless, several times correlated words are not necessary close. Therefore it is not an accurate and general method to extract the information between one element and the rest of the sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s8JJyH4MNy0"
      },
      "source": [
        "## 2.3 - Weights in Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biJITJoQXosT"
      },
      "source": [
        "We need to introduce three new vectors: **query**, **keys** and **values**. It is also included three new parameters: $ W_Q, W_K, W_V $, which are going to be trained. For all $ i \\in \\lbrace{1,\\dots,n}\\rbrace $.\n",
        "\n",
        "\\begin{matrix}\n",
        "  \\text{Query} & \\rightarrow & q_i = W^Q x_2 \\\\\n",
        "  \\text{Keys} & \\rightarrow & k_i = W^K x_i \\\\\n",
        "  \\text{Values} & \\rightarrow & v_i = W^V x_i \n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2outRvCKMV-Z"
      },
      "source": [
        "Instead of using directly the inputs $ x_i $, it is employed the **query** $ q_i $ and **keys** $ k_i $ to calculate the weights:\n",
        "\\begin{equation}\n",
        "    \\begin{matrix} z_{1} = \\frac{k_1^T q_2}{\\sqrt{d}} & \\dots & z_{n} = \\frac{k_n^T q_2}{\\sqrt{d}} \\end{matrix} \\\\\n",
        "  \\begin{bmatrix} w_1 & \\dots & w_n \\end{bmatrix} = \\text{softmax} \\begin{pmatrix} z_1 & \\dots & z_n \\end{pmatrix}\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AAWQFphXsty"
      },
      "source": [
        "To calculate the final embedding vector it is used the **values** $ v_i $ instead of the inputs $ x_i $\n",
        "\n",
        "\\begin{equation}\n",
        "  y_2 = \\sum_{j=1}^{n} v_j w_{j}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLDkf7xi-hsw"
      },
      "source": [
        "Intuitively,the query attends the word for which we are going to get the attention weights. Keys corresponds with the rest of the elements in the dot product operation. Values are used in the final combination with the weights. Thanks to learnable matrixes, these combinations are optimized to find combinations and correlations in the own sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsBg0CcUAqvi"
      },
      "source": [
        "![Self-attention process](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/self-attention_process.png)\n",
        "\n",
        "> Self-attention process. Original image from [Illustrated: Self-Attention](https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PLlEXM0YpG2"
      },
      "source": [
        "### 2.3.1 - Matrix Notation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnvZVIwwDn5W"
      },
      "source": [
        "To represent the whole process in matrix notation:\n",
        "\n",
        "\\begin{matrix}\n",
        "  \\text{Input} & \\rightarrow & X = \\begin{bmatrix} x_1 & \\dots & x_n \\end{bmatrix}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ca6iaIA1EjQ",
        "outputId": "3270cd72-2915-406a-a13a-90099ca1ff05"
      },
      "source": [
        "lookup_tensor = torch.tensor([word_to_ix[word] for word in list_sentence], dtype=torch.long)\n",
        "X = embeds(lookup_tensor).T\n",
        "print('Input: word per column\\n')\n",
        "print(X.detach().numpy())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: word per column\n",
            "\n",
            "[[ 0.2972846  -1.005168    0.8999159  -0.65508276  0.36417076]\n",
            " [ 1.1454724   0.11030454  1.0623589  -0.32948834  1.0811074 ]\n",
            " [-0.9478285   1.4334269  -0.44568616 -1.4258631   1.3970529 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yME-uGRP24l_"
      },
      "source": [
        "Calculate **query**, **keys** and **values**:\n",
        "\n",
        "\\begin{matrix}\n",
        "  Q = W^Q X = \\begin{bmatrix} q_1 & \\dots & q_n \\end{bmatrix}  \\\\\n",
        "  K = W^K X = \\begin{bmatrix} k_1 & \\dots & k_n \\end{bmatrix} \\\\\n",
        "  V = W^V X = \\begin{bmatrix} v_1 & \\dots & v_n \\end{bmatrix}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEMuOjMq4XU0",
        "outputId": "36bf2c3d-8e48-4496-be2a-6c850428e8e2"
      },
      "source": [
        "# initialize weight matrixes\n",
        "dim = (X.shape[-1], X.shape[0])\n",
        "W_Q = torch.randn(dim)\n",
        "W_K = torch.randn(dim)\n",
        "W_V = torch.randn(dim)\n",
        "\n",
        "# calculate query, keys, values\n",
        "Q = W_Q @ X\n",
        "K = W_K @ X\n",
        "V = W_V @ X\n",
        "\n",
        "print('Query\\n')\n",
        "print(Q.detach().numpy(), '\\n')\n",
        "print('Keys\\n')\n",
        "print(K.detach().numpy(), '\\n')\n",
        "print('Values\\n')\n",
        "print(V.detach().numpy(), '\\n')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query\n",
            "\n",
            "[[ 0.94732577  0.24976121  1.807257   -2.105751    2.7083457 ]\n",
            " [ 2.6012852   0.7231882   1.4945571   0.6981796   1.288662  ]\n",
            " [ 1.7002228  -1.5210627   1.5536348   0.53349406 -0.11486899]\n",
            " [ 0.91347826 -0.7959454   1.7463113  -1.4348488   1.5853568 ]\n",
            " [-0.37543783  0.11682709 -0.62658256  0.5410353  -0.69848484]] \n",
            "\n",
            "Keys\n",
            "\n",
            "[[-0.48036295  2.6824331  -1.0744416  -0.26827198  1.1428027 ]\n",
            " [ 1.7740306  -4.1905646  -0.08809493  5.2739897  -5.7614717 ]\n",
            " [ 2.5668268  -1.8516264   1.1261073   2.8332417  -1.9053587 ]\n",
            " [ 1.3917127   0.23223738  1.0341364   0.02369173  0.9536887 ]\n",
            " [ 0.54052305 -1.723981    0.91600287  0.09904789 -0.5192256 ]] \n",
            "\n",
            "Values\n",
            "\n",
            "[[-0.77198565  0.3788088  -0.6859384  -0.0975714  -0.2236819 ]\n",
            " [ 1.9430461  -3.0536022   1.1756802   2.4986253  -2.511243  ]\n",
            " [ 1.2776299  -2.8472173   2.323278   -0.77578324  0.27764013]\n",
            " [-0.60166216  0.53085405 -0.10473537 -1.0189025   0.8270517 ]\n",
            " [-2.396129    2.7505422  -2.6366727  -0.26620758 -0.03109352]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJhYMfJBhMV_"
      },
      "source": [
        "Calculate the **weights**:\n",
        "\n",
        "\\begin{matrix}\n",
        "  Z = \\frac{K^T Q}{\\sqrt{d}} \\\\\n",
        "  W = \\text{softmax}(Z)\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9Iir7Nn1NCp",
        "outputId": "addbc3cf-9434-4cd0-fa13-236d82dc508d"
      },
      "source": [
        "Z = (K.T @ Q) / (d)\n",
        "# dim=0 since we want to apply it per column\n",
        "W = nn.LogSoftmax(dim=0)(Z)\n",
        "print('Weigths\\n')\n",
        "print(W.detach().numpy(), '\\n')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weigths\n",
            "\n",
            "[[ -2.9488108   -2.386987    -1.5730894   -1.7282917   -1.753173  ]\n",
            " [ -9.695726    -1.1018249   -5.1294265   -5.976006    -1.3762794 ]\n",
            " [ -5.72343     -2.0453682   -3.8913448   -1.7621305   -3.3105993 ]\n",
            " [ -0.05735593  -1.3149333   -0.26784465  -0.44056866  -0.6886264 ]\n",
            " [-11.505575    -1.7259446   -6.699026    -5.3982463   -3.3382103 ]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYvPf694-192"
      },
      "source": [
        "Finally, we get the **output** matrix:\n",
        "\n",
        "\\begin{matrix}\n",
        "  \\text{Output} & \\rightarrow & Y = VW = \\begin{bmatrix} y_1 & \\dots & y_n \\end{bmatrix}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg6YXnOC_e4w",
        "outputId": "39bfe940-a031-417b-b593-2ae8967bcc68"
      },
      "source": [
        "Y = V @ W\n",
        "print('Output\\n')\n",
        "print(Y.detach().numpy(), '\\n')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output\n",
            "\n",
            "[[  5.108719     3.3426979    3.4651382    1.5296426    3.9168322 ]\n",
            " [ 45.898277    -2.629449    24.185305    25.273985     3.5663462 ]\n",
            " [  7.39132     -4.1235976    1.9019614    9.555967    -6.405379  ]\n",
            " [-12.230647     0.9778175   -6.6364803   -5.963714    -1.388278  ]\n",
            " [ -4.1389437    8.485591     0.20042273  -7.364752     9.431396  ]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0yR7j8HDIaw"
      },
      "source": [
        "As it is normal, we have not obtained a meaningful result, since $ W^Q, W^K, W^V $ have not been trained. At the end, we are looking for a rectangular matrix which relates every word in the sentence. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkH-EJ8jlh8O"
      },
      "source": [
        "![Intuition self-attention](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/intuition_att.png)\n",
        "\n",
        "> Intuition about attention. Image from [exBERT](https://huggingface.co/exbert/?model=bert-base-cased&modelKind=bidirectional&sentence=The%20orange%20is%20very%20healthy&layer=0&heads=..0,1,2,3,4,5,6,7,8,9,10,11&threshold=0.7&tokenInd=null&tokenSide=null&maskInds=..&hideClsSep=true) tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx2d2n9VycK7"
      },
      "source": [
        "# 3 - The Transformer\n",
        "\n",
        "In 2017 was presented the Transformer in the paper [Attention is All You Need](https://arxiv.org/abs/1706.03762). It is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequence aligned RNNs or convolution. The Transformer reached a new state of the art in translation quality, the original goal for the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_xD9N3umEyu"
      },
      "source": [
        "![Transformer architecture](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/transformer.png)\n",
        "\n",
        "> Transformer architecture. Image from [Attention is All You Need](https://arxiv.org/abs/1706.03762)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78bu--O6DXAu"
      },
      "source": [
        "In order to understand how the Transformer works, it is going to be explained the main parts.\n",
        "\n",
        "> The code is based mainly in the implementation of [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html), which implements the model step by step as it is discussed in the original paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9XTCL8IJ9Ma"
      },
      "source": [
        "## 3.1 - Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIW801LBKBh5"
      },
      "source": [
        "The model is based in an encoder-decoder structure, as other competitive neural sequence transduction models. It receives as input a complete sentence and generates the probabilities for the next word as output. Usually it is selected the higher one and feed it into the decoder until it is selected the token which indicates the end of sequence. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nofb2wJqO9TP"
      },
      "source": [
        "![High level transformer architecture](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/hl_trans_archi.png)\n",
        "\n",
        "> High-level transformer architecture. From the slides of [A series of videos on transformers](https://www.youtube.com/watch?v=0SmNEp4zTpc&list=PLDw5cZwIToCvXLVY2bSqt7F2gu8y-Rqje)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jopZSHTl6sk2"
      },
      "source": [
        "The Transformer generates a one symbol at a time, consuming the previously generated symbols as additional input, so it is an example of auto-regressive model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxiXBozxPpWI"
      },
      "source": [
        "## 3.2 - Input Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOKfYGq8R90U"
      },
      "source": [
        "Before going into the encoder and decoder stacks, mention how the sentences are preprocessed. The word vectors used as input in the encoder and the decoder are formed by the sum of other two vectors: **word embedding** and **positional encoding**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE33YK_we8uE"
      },
      "source": [
        "> Let's define some variables:\n",
        "\n",
        "\n",
        "\n",
        "*   Number of sentences in a batch: $ m $\n",
        "*   Number of words per sentence: $ n $\n",
        "*   Embedding dimension: $ d_{model} $\n",
        "*   Size of vocabulary: $ vocab $\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np5nmAyUbPgV"
      },
      "source": [
        "![Transformer input embedding](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/in_emb.png)\n",
        "\n",
        "> Transformer input embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsV9N-zJYnGg"
      },
      "source": [
        "### 3.2.1 - Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLsRZqxRTL4i"
      },
      "source": [
        "It is used learned embeddings to convert the input tokens and output tokens to vectors of dimension $ d_{model} $. It is shared the same weight matrix between the two embbeding layers, similar to [Using the Output Embedding to Improve Language Models](https://arxiv.org/abs/1608.05859). Also mention those weihts are multiplied by $ \\sqrt{d_{model}} $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kav4S0GhU3Jd"
      },
      "source": [
        "class Embeddings(nn.Module):\n",
        "  def __init__(self, d_model, vocab):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.lut = nn.Embedding(vocab, d_model)\n",
        "    self.d_model = d_model\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lut(x) * math.sqrt(self.d_model)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmnQ3x8IYrRV"
      },
      "source": [
        "### 3.2.2 - Positional Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuY7cXIoTnaj"
      },
      "source": [
        "The attention blocks only map sets to sets, due to that, there is not any information about the position of the word in the sentence. Then it is injected some information about the relative or absolute position. In the original paper, it is used sine and cosine functions of different frequencies:\n",
        "\n",
        "\\begin{equation}\n",
        "  PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}}) \\\\\n",
        "  PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}})\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s3UgPQ0Wdck"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  \"\"\"Implement the PE function\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, d_model, dropout, max_len=5000):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    position = torch.arange(0, max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2) * \n",
        "                         -(math.log(10000.0) / d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
        "    return self.dropout(x)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhcQ8jbyyzlp"
      },
      "source": [
        "The output is the addition of both embeddings. \n",
        "\n",
        "\\begin{matrix}\n",
        "  x_i = & \\underbrace{E_i}_\\text{Word Embedding} & + & \\underbrace{P_i}_\\text{Positional Encoding}\n",
        "\\end{matrix}\n",
        "\n",
        "Let's see how is the input and how is transformed after this process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpnPSaICY6OA"
      },
      "source": [
        "Function to mask Transformer inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lzuoKnVa03e"
      },
      "source": [
        "def subsequent_mask(size):\n",
        "  \"\"\"Mask out subsequent positions\n",
        "\n",
        "  \"\"\"\n",
        "  attn_shape = (1, size, size)\n",
        "  subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "  return torch.from_numpy(subsequent_mask) == 0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oSCMJUEY2pU"
      },
      "source": [
        "Class to manage one batch of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCLpgj6fZ4UW"
      },
      "source": [
        "class Batch:\n",
        "  \"\"\"Object for holding a batch of data with mask during training\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, src, trg=None, pad=0):\n",
        "    self.src = src\n",
        "    self.src_mask = (src != pad).unsqueeze(-2)\n",
        "    if trg is not None:\n",
        "      self.trg = trg[:, :-1]\n",
        "      self.trg_y = trg[:, 1:]\n",
        "      self.trg_mask = self.make_std_mask(self.trg, pad)\n",
        "      self.ntokens = (self.trg_y != pad).data.sum()\n",
        "\n",
        "  @staticmethod\n",
        "  def make_std_mask(tgt, pad):\n",
        "    \"\"\"Create a mask to hide padding and future words\n",
        "\n",
        "    \"\"\"\n",
        "    tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "    tgt_mask = tgt_mask & Variable(subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
        "    return tgt_mask"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS_sxWBgY_wJ"
      },
      "source": [
        "Function to generate a random batch of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f_dsjQNVVfT"
      },
      "source": [
        "def batch_gen(V, batch, words):\n",
        "  \"\"\"Generate random data for a src-tgt copy task.\n",
        "\n",
        "  Args:\n",
        "  V (int): until number created for random int\n",
        "  batch (int): number of rows\n",
        "  words (int): number of columns\n",
        "\n",
        "  Returns:\n",
        "  Batch\n",
        "\n",
        "  \"\"\"\n",
        "  data = torch.from_numpy(np.random.randint(1, V, size=(batch, words)))\n",
        "  data[:, 0] = 1\n",
        "  src = Variable(data, requires_grad=False)\n",
        "  tgt = Variable(data, requires_grad=False)\n",
        "  return Batch(src, tgt, 0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cyPzIoPVu_A"
      },
      "source": [
        "We can check the Transformer input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZAKlqt0iSBb",
        "outputId": "7536d92b-64e9-4954-b6e0-96fa3f127587"
      },
      "source": [
        "#@title { vertical-output: true }\n",
        "#@markdown Number of sentences in a batch\n",
        "m = 5 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Number of words in a sentence\n",
        "n = 10 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Embedding dimension\n",
        "d_model = 512 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Vocabulary size\n",
        "vocab = 11 #@param {type:\"integer\"}\n",
        "\n",
        "batch = batch_gen(vocab, m, n)\n",
        "emb = Embeddings(d_model, vocab)\n",
        "pos = PositionalEncoding(d_model, 0.01)\n",
        "\n",
        "emb_w = emb.lut.weight\n",
        "print('Embedding matrix with dimension: (vocab x d_model)')\n",
        "print(tuple(emb_w.shape), '\\n')\n",
        "#print(emb_w.detach().numpy(), '\\n')\n",
        "\n",
        "enc_in = batch.src\n",
        "print('Encoder input before embedding with dimension: (m x n) ')\n",
        "print(tuple(enc_in.shape), '\\n')\n",
        "\n",
        "enc_out = nn.Sequential(emb, pos)(enc_in)\n",
        "print('Encoder input with dimension: (m x n x d_model)')\n",
        "print(tuple(enc_out.shape), '\\n')\n",
        "\n",
        "dec_in = batch.trg\n",
        "print('Decoder input before embedding  with dimension: (m x n-1) ')\n",
        "print(tuple(dec_in.shape), '\\n')\n",
        "\n",
        "dec_out = nn.Sequential(emb, pos)(dec_in)\n",
        "print('Decoder input with dimension: (m x n-1 x d_model)')\n",
        "print(tuple(dec_out.shape), '\\n')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding matrix with dimension: (vocab x d_model)\n",
            "(11, 512) \n",
            "\n",
            "Encoder input before embedding with dimension: (m x n) \n",
            "(5, 10) \n",
            "\n",
            "Encoder input with dimension: (m x n x d_model)\n",
            "(5, 10, 512) \n",
            "\n",
            "Decoder input before embedding  with dimension: (m x n-1) \n",
            "(5, 9) \n",
            "\n",
            "Decoder input with dimension: (m x n-1 x d_model)\n",
            "(5, 9, 512) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9ofzwczProp"
      },
      "source": [
        "## 3.3 - Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PP1EybI5CV6"
      },
      "source": [
        "The encoder stacks $ N $ encoder blocks which map sets to sets, what means the output size is the same than input: $ ( m \\ x \\ n \\ x \\ d_{model} ) $. In the original implementation, they employ $ N=6 $ encoders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms1C-CsrbIuR"
      },
      "source": [
        "![Transformer's encoder](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/encoder.png)\n",
        "\n",
        "> Encoder architecture. Modified image from [Attention is All You Need](https://arxiv.org/abs/1706.03762)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAibzJp2sMNL"
      },
      "source": [
        "Each block is formed by two sub-layers: **Multi-Head Attention** and **Feed Forward**. Both are followed by an **Add \\& Norm** layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuOR0vIaZeH6"
      },
      "source": [
        "### 3.3.1 - Multi-Head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSCGGrr5Uof3"
      },
      "source": [
        "The Transformer differs for using exclusively self-attention. This model employs a type of self-attention called **Scaled Dot-Product Attention**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3njTSJhVEfur"
      },
      "source": [
        "#### 3.3.1.1 - Scaled Dot-Product Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdUPRWV1u9Ao"
      },
      "source": [
        "It is fast and space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code.\n",
        "\n",
        "We have queries $ Q $ and keys $ K $ of dimension $ d_k $ and values $ V $ of dimension $ d_v $.\n",
        "\n",
        "\\begin{equation}\n",
        "  \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\n",
        "\\end{equation}\n",
        "\n",
        "For large values of $ d_k $ the softmax function could have extremely small gradients. For this reason, the dot product is scaled by $ \\frac{1}{\\sqrt{d_k}} $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLtjORVBnZ1D"
      },
      "source": [
        "![Scaled dot product attention](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/sdp_attention.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeDeFHvgWprw"
      },
      "source": [
        "def sdp_attention(query, key, value, mask=None, dropout=None):\n",
        "  d_k = query.size(-1)\n",
        "  scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scores = scores.masked_fill(mask == 0, -1e9)\n",
        "  p_attn = F.softmax(scores, dim=-1)\n",
        "  if dropout is not None:\n",
        "    p_attn = dropout(p_attn)\n",
        "  return torch.matmul(p_attn, value), p_attn"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cxAhy-RZxHi"
      },
      "source": [
        "> To remember variables:\n",
        "\n",
        "*   Number of sentences in a batch: $ m $\n",
        "*   Number of words per sentence: $ n $\n",
        "*   Embedding dimension: $ d_{model} $\n",
        "\n",
        "> And let's introduce new ones\n",
        "\n",
        "\n",
        "*   Attention blocks: $ h $\n",
        "*   Dimension attention layers: $ d_k = \\frac{d_{model}}{h} $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64X60ZyWAQz"
      },
      "source": [
        "Multi-Head Attention is based on performing attention in parallel. There are $ h $ different blocks, with identical structure but different parameterers: $ W^Q $, $ W^K $ and $ W^V $. The output vectors from different heads are concatenated for each word using the parameter $ W^O $.\n",
        "\n",
        "\\begin{equation}\n",
        "  \\text{MultiHead}(Q,K,V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h) W_O \\\\\n",
        "  \\text{where} \\ \\text{head}_i = \\text{Attention}(QW^Q_i, KW^K_i, VW^V_i) \\\\\n",
        "  W^Q_i \\in \\mathbb R^{d_{model}\\ x \\ d_k}, \\ W^K_i \\in \\mathbb R^{d_{model}\\ x \\ d_k}, \\ W^V_i \\in \\mathbb R^{d_{model}\\ x \\ d_v} \\\\\n",
        "  W^O \\in \\mathbb R^{h d_v\\ x \\ d_{model}}\n",
        "\\end{equation}\n",
        "\n",
        "The idea is to get information from different representation subspaces at different positions. To get an intuition, we could see it as one head is understanding the sentence gramatically, another one from the point of spelling, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB3nhzM6dyOk"
      },
      "source": [
        "> In the papers [Attention is All You Need](https://arxiv.org/abs/1706.03762) and [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html), it is used $ h = 8 $ and they assume that $ d_v = d_k $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcZ1ULyDnpXm"
      },
      "source": [
        "![Multi-Head Attention](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/multi__head_attention.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKpHHa4vZ0Lc"
      },
      "source": [
        "To generate $ N $ identical layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIptwAwCj7wB"
      },
      "source": [
        "import copy\n",
        "\n",
        "def clones(module, N):\n",
        "  return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCpFzMs6Z6yr"
      },
      "source": [
        "A class to represent Multi-Head Attention:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGabuvuHebXG"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  \n",
        "  def __init__(self, h, d_model, dropout=0.1):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    assert d_model % h == 0\n",
        "    # To assume d_v always equals d_k\n",
        "    self.d_k = d_model // h\n",
        "    self.h = h\n",
        "    self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "    self.attn = None\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "\n",
        "  def forward(self, query, key, value, mask=None):\n",
        "    if mask is not None:\n",
        "      # Same mask applied to all h heads.\n",
        "      mask = mask.unsqueeze(1)\n",
        "    nbatches = query.size(0)\n",
        "\n",
        "    # 1) Do all the linear projections in batch from d_model => h x d_k\n",
        "    query, key, value = \\\n",
        "      [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "      for l, x in zip(self.linears, (query, key, value))]\n",
        "\n",
        "    # 2) Apply attention on all the projected vectors in batch.\n",
        "    att_out, self.attn = sdp_attention(query, key, value, mask=mask, \n",
        "                                       dropout=self.dropout)\n",
        "\n",
        "    # 3) \"Concat\" using a view and apply a final linear.\n",
        "    concat_out = att_out.transpose(1, 2).contiguous().view(nbatches, -1, \n",
        "                                                           self.h * self.d_k)\n",
        "\n",
        "    # 4) Last linear\n",
        "    return query, key, value, att_out, concat_out, self.linears[-1](concat_out)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbId20t_aBu4"
      },
      "source": [
        "We can see how the tensor is divided into the $ h $ heads and then contactenated to recover its original shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se0tXhR_fCks",
        "outputId": "c6eb697b-cc52-45ee-c4c0-5a10173490a7"
      },
      "source": [
        "#@title  { vertical-output: true }\n",
        "#@markdown Attention blocks\n",
        "h =  8#@param {type:\"integer\"}\n",
        "\n",
        "# get previous output as input\n",
        "input = enc_out\n",
        "\n",
        "multi = MultiHeadAttention(h , d_model)\n",
        "q, k, v, att, concat, output = multi(input, input, input)\n",
        "\n",
        "print('Input with dimension: (m x n)')\n",
        "print(tuple(input.shape), '\\n')\n",
        "\n",
        "print('Query, keys and values with dimension: (m x h x n x d_k)')\n",
        "print(tuple(q.shape), '\\n')\n",
        "\n",
        "print('Output with dimension: (m x n x d_model)')\n",
        "print(tuple(output.shape), '\\n')\n",
        "\n",
        "for w, layer in zip(['W_Q', 'W_K', 'W_V', 'W_O'], multi.linears): \n",
        "  print(f'{w} with dimension: {tuple(layer.weight.shape)}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input with dimension: (m x n)\n",
            "(5, 10, 512) \n",
            "\n",
            "Query, keys and values with dimension: (m x h x n x d_k)\n",
            "(5, 8, 10, 64) \n",
            "\n",
            "Output with dimension: (m x n x d_model)\n",
            "(5, 10, 512) \n",
            "\n",
            "W_Q with dimension: (512, 512)\n",
            "W_K with dimension: (512, 512)\n",
            "W_V with dimension: (512, 512)\n",
            "W_O with dimension: (512, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyScS4mWaIGG"
      },
      "source": [
        "### 3.3.2 - Feed-Forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leKQ5Bk1M6fW"
      },
      "source": [
        "Each layer contains a fully connected feed-forward network. It is used different parameters between blocks.\n",
        "\n",
        "\\begin{equation}\n",
        "  \\text{FFN}(x) = \\text{max}(0,\\ xW_1 \\ + \\ b_1)W_2 \\ + \\ b_2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAS0XzeuaNSt"
      },
      "source": [
        "> In the original paper the input and output have dimensionality $ d_{model} = 512 $ and the inner-layer $ d_{ff} = 2048 $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMlushNuv3BV"
      },
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "\n",
        "  def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "    super(PositionwiseFeedForward, self).__init__()\n",
        "    self.w_1 = nn.Linear(d_model, d_ff)\n",
        "    self.w_2 = nn.Linear(d_ff, d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.w_2(self.dropout(F.relu(self.w_1(x))))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98jLXRaxnDJv"
      },
      "source": [
        "### 3.3.3 Add & Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rgP8tPIVuS7"
      },
      "source": [
        "This layer corresponds to a [residual connection](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html) followed by [layer normalization](https://arxiv.org/abs/1607.06450) in both sub-layers. The goal of a residual connection is easing the training, with layers learning functions with reference to the layer inputs, instead of learning unreferenced ones. The layer normalization is a normalization which is applied per feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PEU842En4eM"
      },
      "source": [
        "![Layer Normalization](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/layer_norm.png)\n",
        "\n",
        "> Layer Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDoWEwSxtlCi"
      },
      "source": [
        "Then, the output of each sub-layer is:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{LayerNorm}(x \\ + \\ \\text{Sublayer}(x))\n",
        "\\end{equation}\n",
        "\n",
        "where $ \\text{Sublayer}(x) $ is the function implemented by the corresponding sub-layer. \n",
        "\n",
        "In order to reduce overfitting, it is applied dropout to the output of each sub-layer, before it is added to the sub-layer input and normalized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWCRO3n8w6GK"
      },
      "source": [
        "class LayerNorm(nn.Module):\n",
        "\n",
        "  def __init__(self, features, eps=1e-6):\n",
        "    super(LayerNorm, self).__init__()\n",
        "    self.a_2 = nn.Parameter(torch.ones(features))\n",
        "    self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "    self.eps = eps\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(-1, keepdim=True)\n",
        "    std = x.std(-1, keepdim=True)\n",
        "    return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0riUa70aU8b"
      },
      "source": [
        "To show normalization process in a layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsnnp7boyMI5",
        "outputId": "369a213d-ff6b-4c93-9bed-2cca8285e32d"
      },
      "source": [
        "#@title { vertical-output: true }\n",
        "#@markdown This variable would correspond with d_model in the Transformer\n",
        "features = 5 #@param {type:\"integer\"}\n",
        "rows = 2 #@param {type:\"integer\"}\n",
        "\n",
        "batch_norm = batch_gen(5, rows, features)\n",
        "input = batch_norm.src.float()\n",
        "print('Input')\n",
        "print(input.detach().numpy(), '\\n')\n",
        "\n",
        "output = LayerNorm(features)(input)\n",
        "print('Output')\n",
        "print(output.detach().numpy())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input\n",
            "[[1. 2. 1. 2. 3.]\n",
            " [1. 4. 1. 1. 3.]] \n",
            "\n",
            "Output\n",
            "[[-0.95618165  0.23904549 -0.95618165  0.23904549  1.4342726 ]\n",
            " [-0.7071063   1.4142126  -0.7071063  -0.7071063   0.7071063 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il6ellS9aas_"
      },
      "source": [
        "Class to represent Sublayer Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klJw2QYEw8js"
      },
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "  \"\"\"A residual connection followed by a layer norm.\n",
        "  Note for code simplicity the norm is first as opposed to last\n",
        "  \n",
        "  \"\"\"\n",
        "  def __init__(self, size, dropout):\n",
        "    super(SublayerConnection, self).__init__()\n",
        "    self.norm = LayerNorm(size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, sublayer):\n",
        "    \"\"\"Apply residual connection to any sublayer with the same size\n",
        "\n",
        "    \"\"\"\n",
        "    return x + self.dropout(sublayer(self.norm(x)))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aofgg0qifWRd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB-x7Ye92U_A"
      },
      "source": [
        "Now that all layers are explained, we can implement the whole encoder. First, it is defined the class for an instance in the stack."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHgrd2822bir"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "  def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    self.self_attn = self_attn\n",
        "    self.feed_forward = feed_forward\n",
        "    self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "    self.size = size\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "    return self.sublayer[1](x, self.feed_forward)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9_hBtxp3Rhm"
      },
      "source": [
        "And the whole class for the encoder\n",
        "\n",
        "> In the original paper they used a stack of $ N=6 $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF0BUBYQ3UhK"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \n",
        "  def __init__(self, layer, N):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.layers = clones(layer, N)\n",
        "    self.norm = LayerNorm(layer.size)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    for layer in self.layers: \n",
        "      x = layer(x, mask)\n",
        "    return self.norm(x)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7qGfrVEaoXA"
      },
      "source": [
        "To show encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3fL2fnkMQKl",
        "outputId": "abbe72f5-855e-4b42-910b-ae1e466a602d"
      },
      "source": [
        "#@title \n",
        "#@markdown Attention blocks\n",
        "h =  8#@param {type:\"integer\"}\n",
        "#@markdown Embedding dimension\n",
        "d_model = 512 #@param {type:\"integer\"}\n",
        "#@markdown Dimension inner layer\n",
        "d_ff = 2048 #@param {type:\"integer\"}\n",
        "#@markdown Dropout\n",
        "dropout = 0.1 #@param {type:\"number\"}\n",
        "#@markdown Encoder blocks\n",
        "N = 6 #@param {type:\"integer\"}\n",
        "\n",
        "c = copy.deepcopy\n",
        "attn = MultiHeadAttention(h, d_model)\n",
        "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "enc_block = EncoderLayer(d_model, c(attn), c(ff), dropout)\n",
        "encoder = Encoder(enc_block, N)\n",
        "\n",
        "print(f'One encoder block, there are {N} like this\\n')\n",
        "print(encoder.layers[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One encoder block, there are 6 like this\n",
            "\n",
            "EncoderLayer(\n",
            "  (self_attn): MultiHeadAttention(\n",
            "    (linears): ModuleList(\n",
            "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (feed_forward): PositionwiseFeedForward(\n",
            "    (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "    (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (sublayer): ModuleList(\n",
            "    (0): SublayerConnection(\n",
            "      (norm): LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): SublayerConnection(\n",
            "      (norm): LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6apm_esRlPP"
      },
      "source": [
        "## 3.4 - Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5WY0_QqyvBF"
      },
      "source": [
        "It is also composed of a stack of $ N $ decoder blocks. Using the output from the encoder its function is also mapping sets to sets, maintaning the shape: number of vectors $ m $ and length $ n $. However, the dimensionality in the number of words differs one position from the encoder, being the size: $ ( m \\ x \\ n-1 \\ x \\ d_{model} ) $. In the original implementation, they employ $ N=6 $ decoders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivW20glBbTXN"
      },
      "source": [
        "![Transformer's decoder](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/decoder.png)\n",
        "\n",
        "> Decoder architecture. Modified image from [Attention is All You Need](https://arxiv.org/abs/1706.03762)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XLa9Wa8U7Wj"
      },
      "source": [
        "The architecture is almost equal to the encoder. Appart from the dimension, there are other two differences:\n",
        "\n",
        "-   The mask for the first multi-attention.\n",
        "-   The encoder's output used as input in the second multi-attention.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Ocr6ZOa_fk"
      },
      "source": [
        "### 3.4.1 - Masked Multi-Head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XutrVAx7Vk_H"
      },
      "source": [
        "The use of a mask is already implemented in the self-attention function and in the generation of a batch. This prevents attending to subsequent positions and ensures that the predictions only depend on known outputs previous to the current one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzScbuiZbYh6"
      },
      "source": [
        "![Masked self-attention](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/masked_attn.png)\n",
        "\n",
        "> Self-attention intuition in encoder and decoder. Image from [Transformer video](https://www.youtube.com/watch?v=TQQlZhbC5ps&list=PLTl9hO2Oobd_bzXUpzKMKA3liq2kj6LfE) by CodeEmporium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZgY-1yCaphw",
        "outputId": "9e2030c8-13af-417c-f3ad-b024cdfce83c"
      },
      "source": [
        "enc_mask = batch.src_mask.detach().numpy()\n",
        "dec_mask = batch.trg_mask[0].detach().numpy()\n",
        "\n",
        "print('No mask used in encoder\\n')\n",
        "print(enc_mask, '\\n\\n')\n",
        "\n",
        "print('Mask used in decoder\\n')\n",
        "print(dec_mask)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No mask used in encoder\n",
            "\n",
            "[[[ True  True  True  True  True  True  True  True  True  True]]\n",
            "\n",
            " [[ True  True  True  True  True  True  True  True  True  True]]\n",
            "\n",
            " [[ True  True  True  True  True  True  True  True  True  True]]\n",
            "\n",
            " [[ True  True  True  True  True  True  True  True  True  True]]\n",
            "\n",
            " [[ True  True  True  True  True  True  True  True  True  True]]] \n",
            "\n",
            "\n",
            "Mask used in decoder\n",
            "\n",
            "[[ True False False False False False False False False]\n",
            " [ True  True False False False False False False False]\n",
            " [ True  True  True False False False False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvvlsaTyb7BS"
      },
      "source": [
        "### 3.4.2 - Encoder-Decoder Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFncrjt8eTiR"
      },
      "source": [
        "The second sublayer in the decoder is a multi-head attention, without mask in this case, but using the encoder's output as input in the block.\n",
        "\n",
        "\\begin{matrix}\n",
        "  \\text{Query} & \\rightarrow & Q^D  & \\text{from decoder's input embedding} \\\\\n",
        "  \\text{Keys} & \\rightarrow & K^E & \\text{from encoder's output} \\\\\n",
        "  \\text{Values} & \\rightarrow & V^E & \\text{from encoder's output}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8E3Qhk1h22R"
      },
      "source": [
        "Once these two differences are explained, it can be implemented the decoder's blocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVuMeBPJh-tN"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "  def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "    self.size = size\n",
        "    self.self_attn = self_attn\n",
        "    self.src_attn = src_attn\n",
        "    self.feed_forward = feed_forward\n",
        "    self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "  def forward(self, x, memory, src_mask, tgt_mask):\n",
        "    \n",
        "    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "    x = self.sublayer[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
        "    return self.sublayer[2](x, self.feed_forward)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNn7e0ZiiK1G"
      },
      "source": [
        "And the complete decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8l37wzGiMPw"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self, layer, N):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.layers = clones(layer, N)\n",
        "    self.norm = LayerNorm(layer.size)\n",
        "\n",
        "  def forward(self, x, memory, src_mask, tgt_mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, memory, src_mask, tgt_mask)\n",
        "    return self.norm(x)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCnMNMjUcBQo"
      },
      "source": [
        "To show decoder architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8cZH1NvB2Ml",
        "outputId": "7cf10da4-397e-4ac1-cca5-6f576bd0afa9"
      },
      "source": [
        "#@title \n",
        "#@markdown Attention blocks\n",
        "h =  8#@param {type:\"integer\"}\n",
        "#@markdown Embedding dimension\n",
        "d_model = 512 #@param {type:\"integer\"}\n",
        "#@markdown Dimension inner layer\n",
        "d_ff = 2048 #@param {type:\"integer\"}\n",
        "#@markdown Dropout\n",
        "dropout = 0.1 #@param {type:\"number\"}\n",
        "#@markdown Encoder blocks\n",
        "N = 6 #@param {type:\"integer\"}\n",
        "\n",
        "c = copy.deepcopy\n",
        "attn = MultiHeadAttention(h, d_model)\n",
        "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "dec_block = DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout)\n",
        "decoder = Decoder(dec_block, N)\n",
        "\n",
        "print(f'One decoder block, there are {N} like this\\n')\n",
        "print(decoder.layers[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One decoder block, there are 6 like this\n",
            "\n",
            "DecoderLayer(\n",
            "  (self_attn): MultiHeadAttention(\n",
            "    (linears): ModuleList(\n",
            "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (src_attn): MultiHeadAttention(\n",
            "    (linears): ModuleList(\n",
            "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (feed_forward): PositionwiseFeedForward(\n",
            "    (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "    (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (sublayer): ModuleList(\n",
            "    (0): SublayerConnection(\n",
            "      (norm): LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): SublayerConnection(\n",
            "      (norm): LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): SublayerConnection(\n",
            "      (norm): LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxEz0m8hW9y2"
      },
      "source": [
        "## 3.5 - Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBFIP1RX2KwQ"
      },
      "source": [
        "The final block is a combination of a feed-forward network and a softmax in order to get probabilities for next word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_qOaBC1cK13"
      },
      "source": [
        "![Transformer's generator](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/generator.png)\n",
        "\n",
        "> Final module, generator. Modified image from [Attention is All You Need](https://arxiv.org/abs/1706.03762)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1XNpbMhBHh6"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "   \n",
        "  def __init__(self, d_model, vocab):\n",
        "    super(Generator, self).__init__()\n",
        "    self.proj = nn.Linear(d_model, vocab)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyjjFoHV4Z9H"
      },
      "source": [
        "## 3.6 - Final Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-Csm3wmI6Vm"
      },
      "source": [
        "Finally, we can implement the whole transformer architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6pCQJOKDOpR"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "    super(EncoderDecoder, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embed\n",
        "    self.tgt_embed = tgt_embed\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "    return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
        "\n",
        "  def encode(self, src, src_mask):\n",
        "    return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "  def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypAq7A13cUIm"
      },
      "source": [
        "Function to get a transforme by just setting the parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbLhOCWTchCh"
      },
      "source": [
        "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadAttention(h, d_model)\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "    model = EncoderDecoder(\n",
        "            Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "            Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
        "            nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
        "            nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
        "            Generator(d_model, tgt_vocab))\n",
        "\n",
        "    # This was important from their code.\n",
        "    # Initialize parameters with Glorot / fan_avg.\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9Zt7OVFcq6e"
      },
      "source": [
        "Set the Transformer parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKdpBa-aFIR_"
      },
      "source": [
        "#@markdown Size of source vocabulary\n",
        "src_vocab = 11#@param {type:\"integer\"}\n",
        "#@markdown Size of target vocabulary\n",
        "tgt_vocab = 11#@param {type:\"integer\"}\n",
        "#@markdown Number of encoder and decoder blocks\n",
        "N = 6#@param {type:\"integer\"}\n",
        "#@markdown Inner Transformer size\n",
        "d_model = 512#@param {type:\"integer\"}\n",
        "#@markdown Hidden feed forward size\n",
        "d_ff = 2048#@param {type:\"integer\"}\n",
        "#@markdown Number of attention heads\n",
        "h = 8#@param {type:\"integer\"}\n",
        "#@markdown Dropout probability\n",
        "dropout = 0.1#@param {type:\"number\"}\n",
        "\n",
        "model = make_model(src_vocab, tgt_vocab, N, d_model, d_ff, h, dropout)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH-9hBJudSnF"
      },
      "source": [
        "To visualize the whole architecture or per block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf9xw--dFRnk",
        "outputId": "17d81698-66e4-4394-c7ed-f888459443e1"
      },
      "source": [
        "#@markdown Select a block in the Transformer to visualize it\n",
        "block = \"transformer\" #@param [\"transformer\", \"encoder\", \"decoder\", \"src_embed\", \"tgt_embed\", \"generator\"]\n",
        "\n",
        "if block == 'transformer':\n",
        "    print(model)\n",
        "else:\n",
        "    print(getattr(model, block))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EncoderDecoder(\n",
            "  (encoder): Encoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (4): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): EncoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (4): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): DecoderLayer(\n",
            "        (self_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm()\n",
            "  )\n",
            "  (src_embed): Sequential(\n",
            "    (0): Embeddings(\n",
            "      (lut): Embedding(11, 512)\n",
            "    )\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (tgt_embed): Sequential(\n",
            "    (0): Embeddings(\n",
            "      (lut): Embedding(11, 512)\n",
            "    )\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Generator(\n",
            "    (proj): Linear(in_features=512, out_features=11, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcmcatefeCb3"
      },
      "source": [
        "# 4 - BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KexD7CXsOLxz"
      },
      "source": [
        "**B**idirectional **E**ncoder **R**epresentations from **T**ransformer, released in 2019 in paper [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805), obtaining new state-of-the-art results on eleven NLP tasks. \n",
        "\n",
        "BERT was designed to pretrain deep bidirecional representations from unlabeled text by using self-attention to get the left and right context. This approach overcomes current pre-training techniques, where they use unidirectional language models to learn general language representations. Two examples which were competitive models before BERT are [ELMo](https://arxiv.org/abs/1802.05365) and [GPT](https://openai.com/blog/language-unsupervised/).\n",
        "\n",
        "This pretrained model can be fine-tuned adding one output layer and used for a wide range of NLP tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGrb8nPpeHz6"
      },
      "source": [
        "> The original model developed in TensorFlow is in [github.com/google-research/bert](https://github.com/google-research/bert), but it is going to be used the libray of [HuggingFace](https://huggingface.co/transformers/index.html) to show the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnUkCtDSRYPs",
        "outputId": "1850abe9-abdf-45c4-d8bd-6dd787697693"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 4.0MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 23.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 29.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Qe3tZVePqX"
      },
      "source": [
        "## 4.1 - Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR6BHy1eOAez"
      },
      "source": [
        "It is a multi-layer bidirectional Transformer encoder, based on [Attention is All You Need](https://arxiv.org/abs/1706.03762) and implemented as [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html). The different hyperparameters and the original notation are:\n",
        "\n",
        "\n",
        "\n",
        "*   Number of layers: $ L $, number of encoder blocks which compose the whole stack. Previously defined as $ N $ in the Encoder part.\n",
        "\n",
        "*   Hidden size: $ H $, embedding dimension of the model. Previously deined as $ d_{model} $.\n",
        "\n",
        "*   Self-attention heads: $ A $, number of heads in self-attention blocks. Previously defined as $ h $.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXQPhg66eVM5"
      },
      "source": [
        "There are defined two model sizes: \n",
        "\n",
        "\\begin{matrix}\n",
        "  \\text{BERT}_{\\text{BASE}} & \\rightarrow & L=12, \\ H=768, \\ A=12 & \\text{Total parameters}:\\ 110\\text{M} \\\\\n",
        "  \\text{BERT}_{\\text{LARGE}} & \\rightarrow & L=24, \\ H=1024, \\ A=16 & \\text{Total parameters}:\\ 340\\text{M}\n",
        "\\end{matrix}\n",
        "\n",
        "In both cases the inner layer for the last feed-forward block is defined as $ 4H $, being in the BASE 3072 and in the LARGE 4096."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EBnC4w7eYxG"
      },
      "source": [
        "BERT has been already trained, so we can easily instantiate one of the base model classes of the [HuggingFace](https://huggingface.co/transformers/index.html) library from a pretrained model. To load the required model is used the class [`BertModel`](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel).\n",
        "\n",
        "> [HuggingFace](https://huggingface.co/transformers/index.html) has the the possibility to differentiate between *cased* and *uncased* models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt7Oq3-r3PmA"
      },
      "source": [
        "from transformers import BertModel"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186,
          "referenced_widgets": [
            "eed17105d92e44239e8dc9be5ea3c706",
            "f08631001b6f465bb05c6607d47af343",
            "d53c15aaa60c4d3dac2c6798df06116f",
            "f90870fe55f746e3a4bb6bf1f45aa5af",
            "96a3b0df54bd4a2da54d12fbb1734f8d",
            "0418c437d03a4c6fbc080ff62d78369b",
            "73f14a5f40014f9b9543e9cbf1047bca",
            "353bb1503d7b4e11b81a97db53c86518",
            "d157f96fbda1481b902cc9928144f4f6",
            "0573f5c28d734881a9b9d88b45384ec9",
            "2203cd949c644eba9727edd11198d475",
            "7513e90105be4df6bfc390fdd1bee470",
            "2d5e319cf29b495d9e92725bd24e88fa",
            "c69662f5bdb84b0d8587d2d43a0d3235",
            "db735268868e43f190bdc99ed2ec8053",
            "530b61cdc72e467a99a5f4134c94e8d6"
          ]
        },
        "id": "yp0Vn4p1R4EH",
        "outputId": "2f9b42e1-f428-4f64-b6b1-3a84dc2fa000"
      },
      "source": [
        "#@markdown Select one configuration\n",
        "model_name = \"bert-base-uncased\" #@param [\"bert-base-uncased\", \"bert-base-cased\", \"bert-large-uncased\", \"bert-large-cased\"]\n",
        "# We need to create the model and tokenizer\n",
        "model = BertModel.from_pretrained(model_name)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eed17105d92e44239e8dc9be5ea3c706",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d157f96fbda1481b902cc9928144f4f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1qpQYvHS8Rj"
      },
      "source": [
        "The warning is telling us we are throwing away some weights and randomly initializing some other. That is because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do in next sections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvyTaI6sh-oB",
        "outputId": "f6030ce8-ed28-486f-af0d-d363489f8342"
      },
      "source": [
        "#@markdown Select whole model or a block to visualize it\n",
        "block = \"bert\" #@param [\"bert\", \"embeddings\", \"encoder\", \"pooler\"]\n",
        "if block == 'bert':\n",
        "    print(model)\n",
        "else:\n",
        "    print(getattr(model, block))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F7MxCNyfPeo"
      },
      "source": [
        "### 4.1.1 - Input-Output Representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xsn3fTeGbFdL"
      },
      "source": [
        "In order to handle a variety of tasks, the input can be a single sentence or a pair of sentences in one token sequence, which is certainly the name given to the input. The input representation of a word is the addition of three different embeddings:\n",
        "\n",
        "*   **Token Embedding**: normal word embedding. It is used WordPiece with a 30.000 token vocabulary.\n",
        "\n",
        "*   **Segment Embedding**: to differentiate the sentence the word belongs to. It is used the special token $ [SEP] $ to separate both sentences. \n",
        "\n",
        "*   **Position Embedding**: to indicate the position in the whole sequence.\n",
        "\n",
        "The first token is always a special classification token $ [CLS] $, whose final hidden state layer is used in classification tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hBoDdzBAIvD"
      },
      "source": [
        "![BERT's input](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/in_BERT.png)\n",
        "\n",
        "> Input Embedding. Image from [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSmOADeOfOiY",
        "outputId": "1b605824-ddce-44a4-903d-7c330abc1be8"
      },
      "source": [
        "print(model.embeddings)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertEmbeddings(\n",
            "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "  (position_embeddings): Embedding(512, 768)\n",
            "  (token_type_embeddings): Embedding(2, 768)\n",
            "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGc2QVvs6vDl"
      },
      "source": [
        "As output we get the corresponding sequence embedding, as it is explained in the encoder, and *NSP* for classification. These values are going to be explained better in *Pre-Training* section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g6fHh4mfHXX"
      },
      "source": [
        "## 4.2 - Pre-training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2M14_bCgkfM"
      },
      "source": [
        "This step is in charge of the model to understand the language and its context. It is used two unsupervised tasks instead of the traditional left-to-right or right-to-left."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3AH5O6uALAE"
      },
      "source": [
        "![Pre-training BERT](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/pretrain_BERT.png)\n",
        "\n",
        "> Pre-training process in BERT. Image from [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zmfGdJHfFC1"
      },
      "source": [
        "### 4.2.1 - Masked Language Model (MLM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swuvqUT5jALw"
      },
      "source": [
        "Some tokens are masked at random and then predicted. The final $ T_i $ vectors have the sime size and are generated simultaneously. They are fed into an output softmax over the vocabulary (30k) to get a distribution and compare with cross entropy loss in order to train the model.\n",
        "\n",
        "However, as the output have all the worlds, included the ones were not masked, it is only considered the ones were masked and ignores the others to calculate the cross entropy loss. This ensures more focus into predict the masked values and increases the context awareness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkGOlDsqpShP"
      },
      "source": [
        "![MLM](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/cross_entro_BERT.png)\n",
        "\n",
        "> Prediction of masked word in BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0QIZVHpfbJA"
      },
      "source": [
        "### 4.2.2 - Next Sentence Prediction (NSP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuQTTjvOjdp8"
      },
      "source": [
        "Many important tasks as question and answering are based on understanding relationship between two sentences, which is not captured by language modeling. For that reason, while the model is being trained in MLM, is also trained in next sentence prediction.\n",
        "\n",
        "For this purpose it is used the special token $ [CLS] $ in the input and $ C $ in the output to indicate if *Sentence B* could follow *Sentence A*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul_LRGnUpb-j"
      },
      "source": [
        "![Pre-train BERT](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/pretrain_BERT_methods.png)\n",
        "\n",
        "> MLM and NSP in pre-training BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhI1w305tZET"
      },
      "source": [
        "Training of $ \\text{BERT}_{\\text{BASE}} $ was performed on 4 Cloud TPUs (16 TPU chips total). While training of $ \\text{BERT}_{\\text{LARGE}} $ eployed 16 Cloud TPUs (64 TPU chips total). Each pre-training took 4 days to complete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qEQi_BDffW1"
      },
      "source": [
        "### 4.2.3 - Self-Attention Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm8NzovuqEqC"
      },
      "source": [
        "As it has been mentioned, the model contains $ L $ blocks and $ A $ attention heads. Many models which come from BERT acquired the encoder to perform self-attention. Self-attention operations are not straightforward, even further if we have different blocks and many heads into them.\n",
        "\n",
        "To get an intuition for BERT (and other similar models) respect the attention weights between the elements, we can use [exBERT](https://huggingface.co/exbert/?model=bert-base-cased&modelKind=bidirectional&sentence=This%20model%20has%20revolutionized%20the%20world!&layer=0&heads=..0,1,2,3,4,5,6,7,8,9,10,11&threshold=0.7&tokenInd=null&tokenSide=null&maskInds=..&hideClsSep=true). Following next steps:\n",
        "\n",
        "1. First we select a model and introduce the input sentence.\n",
        "2. We can choose if hide special tokens and the percentage of attention shown.\n",
        "3. We select an encoder block (as *Layer*).\n",
        "4. Lastly the attention heads we want to visualize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyG_JpNiG299"
      },
      "source": [
        "![exBERT](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/exbert.png)\n",
        "\n",
        "> Example of [exBERT](https://huggingface.co/exbert/?model=bert-base-cased&modelKind=bidirectional&sentence=This%20model%20has%20revolutionized%20the%20world!&layer=0&heads=..0,1,2,3,4,5,6,7,8,9,10,11&threshold=0.7&tokenInd=null&tokenSide=null&maskInds=..&hideClsSep=true) visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9ky2Sp-N5Ut"
      },
      "source": [
        "## 4.3 - Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DJIu80m4QdU"
      },
      "source": [
        "Thanks to self-attention, which is in charge of applying bidirectional cross attention between the two sentences, is straightforward to model many downstream tasks. In addition to, the two sentences as input in pretraining are equivalent to different trainings in NLP as sentence pairs in paraphrasing, hypothesis-premise pairs, question-passage pairs, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NwtnjUvpwFh"
      },
      "source": [
        "![Fine-tune BERT](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/finetune_examples.png)\n",
        "\n",
        "> Different NLP tasks implemented by fine-tuning BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dASIeoBig8mC"
      },
      "source": [
        "The output token representations are fed into an output layer and the $ C $ is fed into an output layer for classification. Only new parameters are learned from sratch, while the rest are slightly fine-tuned. \n",
        "\n",
        "That is the reason fine-tune is relatively inexpensive in computation cost compared with pretraining. In the original paper, authors claim that all of the results can be replicated in at most 1 hour on a single Cloud TPU, or a few hours on a GPU, starting from the exact same pre-trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRQ7TcbAp9Nl"
      },
      "source": [
        "![Fine-tune BERT details](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/finetune_BERT_details.png)\n",
        "\n",
        "> Output layer added in fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhsnqD1UKfE4"
      },
      "source": [
        "# 5 - Sentiment Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISgoHueqCeEg"
      },
      "source": [
        "A tradiditonal task in NLP is **Sentiment Analysis**. The target is to determine if the sentence has a *positive* or *negative* sentiment, corresponding with a binary classification problem. As it is normal, these two labels depend on the context of our text. In spite of being one of the most simple applications, it is really useful and currently demanded in many applications, for example in films or series reviews.\n",
        "\n",
        "In addition to be a standard assignment, it compounds one of the task of [GLUE](https://gluebenchmark.com/) (General Language Understanding Evaluation), a group of nine classification tasks on sentences or pairs of sentences, which is commonly used to evaluate state-of-the-art models. Sentiment analysis corresponds with [SST-2](https://nlp.stanford.edu/sentiment/index.html) (Stanford Sentiment Treebank)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEm7PX1G3luN"
      },
      "source": [
        "![Sentiment Analysis](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/sentiment_analysis.PNG)\n",
        "\n",
        "> Example of sentiment analysis in one of the [Hugging Face's models](https://huggingface.co/models)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7sSjqazGNDT"
      },
      "source": [
        "> For this task, two tutorials [Fine tuning BERT for Sentiment Analysis](https://skimai.com/fine-tuning-bert-for-sentiment-analysis/) and [BERT Fine-Tuning Tutorial with PyTorch](http://mccormickml.com/2019/07/22/BERT-fine-tuning/), have been used as guide and support to the development of the application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C72t07tkgGGf"
      },
      "source": [
        "## 5.1 - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sy2wgHzAwRJ"
      },
      "source": [
        "In spite of being much faster than pre-training, fine-tune a BERT model for any class could be slow for a CPU. Due to that, we are going to try using a GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYpkzpTFBEIY"
      },
      "source": [
        "> In case of running it from Colab, we could make use of Google's GPUs. Make sure to select GPU from *Runtime > Change runtime type > Hardware accelerator > GPU*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_x4k_DmO5M8",
        "outputId": "80b35493-b2e3-42af-fe0b-ff65fedb3004"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcAwK4YSYAtO"
      },
      "source": [
        "def info_device():\n",
        "    # If there's a GPU available\n",
        "    if torch.cuda.is_available():\n",
        "        print(f'\\nUsing GPU {torch.cuda.get_device_name(0)}.', '\\n')\n",
        "    # If not\n",
        "    else:\n",
        "        print('\\nNo GPU available, using the CPU instead.', '\\n')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWOX4s-agL1m"
      },
      "source": [
        "## 5.2 - Load SST-2 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSzeqGUCIPCh"
      },
      "source": [
        "First of all we need to download the dataset. We’ll use the `wget` package to download the dataset to the Colab instance’s file system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_EKeJwIMOjb",
        "outputId": "3e4bd131-fdf2-4aa4-bdeb-07d4f6edca6e"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9675 sha256=2adf5a38e51ee62c56e4ad9e8bd58925f30c675c8ec81e02b70fb74a2ac853b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1QkRBVoI6G0"
      },
      "source": [
        "In this [repository](https://github.com/nyu-mll/GLUE-baselines) is explained how to manage GLUE datasets, altough in this case we only need the corresponding URL. We donwload the dataset and then unzip it to access it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ0uAJ2WNE1t",
        "outputId": "f83e81b9-bb31-4fb4-8993-0bfc26096fd8"
      },
      "source": [
        "import wget\n",
        "\n",
        "sentiment_dir = Path('sentiment_analysis')\n",
        "if not os.path.exists(sentiment_dir):\n",
        "    !mkdir $sentiment_dir\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://dl.fbaipublicfiles.com/glue/data/SST-2.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./SST-2.zip'):\n",
        "    print('Downloading dataset...')\n",
        "    wget.download(url, './SST-2.zip')\n",
        "\n",
        "# Unzip the dataset (if we haven't already)\n",
        "sst2_dataset = Path('sst-2_dataset')\n",
        "if not os.path.exists(sst2_dataset):\n",
        "    !unzip SST-2.zip\n",
        "    shutil.move('SST-2', sst2_dataset)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n",
            "Archive:  SST-2.zip\n",
            "   creating: SST-2/\n",
            "  inflating: SST-2/dev.tsv           \n",
            "   creating: SST-2/original/\n",
            "  inflating: SST-2/original/README.txt  \n",
            "  inflating: SST-2/original/SOStr.txt  \n",
            "  inflating: SST-2/original/STree.txt  \n",
            "  inflating: SST-2/original/datasetSentences.txt  \n",
            "  inflating: SST-2/original/datasetSplit.txt  \n",
            "  inflating: SST-2/original/dictionary.txt  \n",
            "  inflating: SST-2/original/original_rt_snippets.txt  \n",
            "  inflating: SST-2/original/sentiment_labels.txt  \n",
            "  inflating: SST-2/test.tsv          \n",
            "  inflating: SST-2/train.tsv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyXCF0E3fW8o"
      },
      "source": [
        "There are three different datasets: *train.csv*, *test.csv*, *dev.csv*. As its own name indicates, they are used for training, testing and validate respectively, the studied model. As there is a [GLUE leaderboard](https://gluebenchmark.com/leaderboard), the test dataset is not labeled. In order to study the performance of our model, we are going to divide the train dataset, which has enough samples, into train and test. Test set is going to be one third of the original train test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMYvqVOQfIg8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df = pd.read_csv(sst2_dataset/'train.tsv', delimiter='\\t', header=1, names=['sentence', 'label'])\n",
        "val_df = pd.read_csv(sst2_dataset/'dev.tsv', delimiter='\\t', header=1, names=['sentence', 'label'])\n",
        "train_df, test_df = train_test_split(train_df, test_size=0.33, shuffle=True)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaVAVVZgJPID"
      },
      "source": [
        "They are saved into a dictionay to allow an easy access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO9lvi3_T_oA"
      },
      "source": [
        "# Load the datasets into a pandas dataframe.\n",
        "original_datasets = {\n",
        "    'train':    train_df, \n",
        "    'val':      val_df, \n",
        "    'test':     test_df\n",
        "}"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sUA4BM7LO3C"
      },
      "source": [
        "To get a fast intuition on the dataset, we can plot some used sentences for the three splits. Mention the label 1 corresponds with positive sentiment while label 0 with negative.\n",
        "\n",
        "\\begin{matrix}\n",
        "    \\text{Class 0} & \\rightarrow & \\text{Negative sentiment} \\\\\n",
        "    \\text{Class 1} & \\rightarrow & \\text{Positive sentiment}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "_1s1Y3T5RS-z",
        "outputId": "9ad08325-8565-4972-d27e-4ff5e9a9e78c"
      },
      "source": [
        "#@markdown Select a split\n",
        "split = \"train\" #@param [\"train\", \"val\", \"test\"]\n",
        "\n",
        "#@markdown Select number of examples to visualize it\n",
        "num_examples = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "print(f'Some sentences of {split} split, which has a length of {len(original_datasets[split])}\\n')\n",
        "pd.set_option(\"max_colwidth\", 150)\n",
        "original_datasets[split].sample(num_examples)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some sentences of train split, which has a length of 45123\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48657</th>\n",
              "      <td>certain</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44012</th>\n",
              "      <td>is almost certainly going to go down as the worst -- and only -- killer website movie of this or any other year</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37689</th>\n",
              "      <td>poignant and gently humorous</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32390</th>\n",
              "      <td>should drop everything and run to ichi</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51718</th>\n",
              "      <td>he makes you realize that deep inside righteousness can be found a tough beauty .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                               sentence  label\n",
              "48657                                                                                                          certain       1\n",
              "44012  is almost certainly going to go down as the worst -- and only -- killer website movie of this or any other year       0\n",
              "37689                                                                                     poignant and gently humorous       1\n",
              "32390                                                                           should drop everything and run to ichi       1\n",
              "51718                                he makes you realize that deep inside righteousness can be found a tough beauty .       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o03dUBH1KxIp"
      },
      "source": [
        "Depending on the computation velocity, training process could be more or less slow. For a fast intuition on the model, we can remove some data, since the original size of the dataset has more than 60k samples only in training. With `perc` we select the percentage of data we are going to use. Removed sample are selected randomly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3d-eYHQgegp",
        "outputId": "2d5cc08a-6c46-4e91-93d3-450b13543ae7"
      },
      "source": [
        "#@title 5.2.1 Resize dataset { vertical-output: true }\n",
        "#@markdown Percentage of dataset to use %\n",
        "perc = 100 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "datasets = {}\n",
        "\n",
        "for key, df in original_datasets.items():\n",
        "    new_df = df.sample(n=round(len(df)*(perc/100)), random_state=np.random.RandomState())\n",
        "    datasets[key] = new_df.reset_index(drop=True)\n",
        "    if perc != 100:\n",
        "        print(f'{key:<10}', f'From: {len(original_datasets[key]):<10}', f'To: {len(datasets[key]):<10}')\n",
        "    else:\n",
        "        print(f'{key:<10}', f'size: {len(original_datasets[key]):<10}')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train      size: 45123     \n",
            "val        size: 871       \n",
            "test       size: 22225     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxgbVHrorSqy"
      },
      "source": [
        "It is important to know how many samples we have per class in our training dataset, in case we are dealing with an imbalanced classification problem. The number of samples is going to depend on how the original train datatset has been splitted to get the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chVHT0EOrcW3",
        "outputId": "cdd2d708-c9d3-4540-f7ff-9d0410d68ece"
      },
      "source": [
        "train_labels = datasets['train'].label\n",
        "\n",
        "# Print resulted samples\n",
        "print(f\"{'Total samples':^15} | {'Positive':^10} | {'Negative':^10}\")\n",
        "print(42*'-')\n",
        "print(f\"{len(train_labels):^15} | {len(train_labels[train_labels==1]):^10} | {len(train_labels[train_labels==0]):^10}\")\n",
        "print(42*'-')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Total samples  |  Positive  |  Negative \n",
            "------------------------------------------\n",
            "     45123      |   25135    |   19988   \n",
            "------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPwweniNgTvl"
      },
      "source": [
        "## 5.3 -  Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krEPtT0qTpQ9"
      },
      "source": [
        "Before input sequences into BERT, it is necessary to preprocess data. Depending on the model, there are more or less steps to do, but mainly the guide to follow is:\n",
        "\n",
        "*   Tokenize sequences. Convert text into integers according to embedding space used. There are many literature about tokenization algorithms.\n",
        "\n",
        "*   Pad each sentence to the maximum length there is in your batch.\n",
        "\n",
        "*   Truncate each sentence to the maximum length the model can accept (if applicable). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRbrb0iDqkZX"
      },
      "source": [
        "![Tokenization](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/tokenization.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iePZgKqDVcFD"
      },
      "source": [
        "The whole text must also be divided into sentences. Each one can select the more suitable approach depending on the origin of the text. In this case, I already have the original text divided into sentences.\n",
        "\n",
        "BERT employs [WordPiece](https://research.google/pubs/pub37842/) subword tokenization algorithm. Subword tokenization algorithms rely on the principle that frequently used words should not be split into smaller subwords, but rare words should be decomposed into meaningful subwords.\n",
        "\t\t\n",
        "WordPiece is very similar to [Byte Pair Encoding (BPE)](https://arxiv.org/abs/1508.07909). Every character present in training data is included to learn the corresponding merge rules. In contrast to BPE that chooses the most frequent symbol pair, this algorithm maximizes the likelihood of the training data when it is added to the vocabulary. This approach evaluates if it is worthy to merge two symbols, instead of separated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjbGx7_xMfdH"
      },
      "source": [
        "Remember that BERT input follows next scheme\n",
        "\n",
        "\\begin{matrix}\n",
        "    \\text{[CLS]} & \\text{Sentence A} & \\text{[SEP]} & \\text{Sentence B} & \\text{[SEP]}\n",
        "\\end{matrix}\n",
        "\n",
        "or\n",
        "\n",
        "\\begin{matrix}\n",
        "    \\text{[CLS]} & \\text{Sentence} & \\text{[SEP]}\n",
        "\\end{matrix} \\\\\n",
        "\n",
        "depending on the final task. Our case, classification of one sentence, corresponds with second option.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSdChhNAOfLC"
      },
      "source": [
        "In order to preprocess according to the model, it is going to be used the [`BertTokenizer`](https://huggingface.co/transformers/model_doc/bert.html?highlight=berttokenizer#transformers.BertTokenizer) from Hugging Face which ensures that we get a tokenizer that corresponds to the model architecture we want to use. Besides that, it downloads the vocabulary used when pretraining this specific checkpoint.\n",
        "\n",
        "\n",
        "It is necessary to pass to the tokenizer the name of the pre-trained model we are going to use. For this task the selected one is [`bert-base-uncased`](https://huggingface.co/bert-base-uncased), a base BERT which does not distinguish between upper and lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198,
          "referenced_widgets": [
            "ace10f1bac344bd097eeb4bf740f8190",
            "46448d09808e46d18c47dc56b43a48a5",
            "6d78faaa864a487387a4a5f4cdee7c35",
            "f75126cff7bd4761ba6b2d86f5cf81ac",
            "6133a68ea3b243a794fddc44a9f14640",
            "812090fb5d634ff2990df26c72ba32fa",
            "b98c6cb3c3254a40a9e0062d7f3818e4",
            "ed10841c114f45ef8e614c6ea6515847",
            "d404716eddac4c9a9bcefbd580e77ebc",
            "3894ec6f711944b2859240678c7e8c54",
            "c655b880806c42f09f40d43cc02157ab",
            "07a5b51d786c4e90bfb8e798cbbff6e0",
            "39443ef61eb54a2f9dc970ef679deb55",
            "55f0863f26dd484f81466bf953d69f84",
            "bd0ed33b9ed04ae8899dab053f115f5d",
            "230462d1065c40d0aed8bda2bd96ebed",
            "97dda1f3205442ba9a717f2dd0dec45d",
            "08ef3b639c434f12ae73d67fd78a875f",
            "27ac5f42541d4e9996feb4221a5eed66",
            "7ee52677e4f645058711d4edf68de5a7",
            "f6c512a3be8d425996ba02c084714ecc",
            "d43fe1a66e1842c3a7ff3abe07e542f0",
            "500520ae8d8a4b07a9d4ffbdac2d6747",
            "9eff15c520f64aa6a3ac6721bff56aba"
          ]
        },
        "id": "_QEvK9RzQdln",
        "outputId": "eb456470-51b2-4b26-967b-05b6966f0f53"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "MODEL_NAME = 'bert-base-uncased'\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...\\n')\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ace10f1bac344bd097eeb4bf740f8190",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d404716eddac4c9a9bcefbd580e77ebc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97dda1f3205442ba9a717f2dd0dec45d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esjs9IJyQ-mU"
      },
      "source": [
        "From this instance we can get many information about the model: \n",
        "\n",
        "- Dimension of the vocabulary used\n",
        "- Maximum allowed length of the model\n",
        "- In which size is applied padding\n",
        "- Special used tokens for separation token, padding token, classification token, mask token and other unknown tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbJCgRpQYODR",
        "outputId": "585dae22-398d-4c53-9866-a331ba7b50e5"
      },
      "source": [
        "#@markdown Select an option to visualize it\n",
        "attribute = \"vocab_size\" #@param [\"vocab_size\", \"model_max_length\", \"padding_side\", \"sep_token\", \"pad_token\", \"cls_token\", \"mask_token\", \"unk_token\"]\n",
        "\n",
        "print(getattr(tokenizer, attribute))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1hLzeZHRJHb"
      },
      "source": [
        "BERT works with sentences of same dimension. Due to that, it is required to pad (add padding tokens until a specified size) or truncate (separate a sentence if it is longer than the maximum model length). For this reason it is very useful to know which is the maximum length in our sentences, and limit the input size to this value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLbnuF07maXq",
        "outputId": "a4ad6a6a-5367-454f-e9d2-e48ba3c81b32"
      },
      "source": [
        "# Concatenate sentences in datasets\n",
        "all_sentences = np.concatenate([datasets['train'].sentence.values, \n",
        "                                datasets['val'].sentence.values, \n",
        "                                datasets['test'].sentence.values])\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_sentences = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_sentences]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_sentences])\n",
        "print(f'Max length: {max_len}')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length: 66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re7NomrbSU4B"
      },
      "source": [
        "In addition to, we have to add the special tokens: [CLS] at the beginning of a sentence and [SEP] between them, altough in our case it will be only at the end of each one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqTTwCtTSwNw"
      },
      "source": [
        "In next function, we tokenize each sentence in addition to add special tokens and perform the required padding or truncating operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2uqvgtbrZSV"
      },
      "source": [
        "def preprocessing_for_sa(data, tokenizer, max_len=512):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            sent,                           # Tokenize sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=max_len,             # Max length to truncate/pad\n",
        "            padding='max_length',           # Pad sentence to max length\n",
        "            truncation=True,                # Truncate to max_length\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Get output and attention mask\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0oMD7QcTUH_"
      },
      "source": [
        "From this function we will get the corresponding token IDs as `input_ids`. Also, the second output `attention_masks`, indicates which tokens are useful and which ones are padding tokens. This requirement in the input is necessary for BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggrf-hV_3Qmr"
      },
      "source": [
        "encoded_datasets = dict.fromkeys(datasets)\n",
        "\n",
        "for split, df in datasets.items(): \n",
        "    encoded_datasets[split] = dict()\n",
        "    encoded_datasets[split]['input_ids'], encoded_datasets[split]['attention_mask'] = preprocessing_for_sa(df.sentence, tokenizer, max_len)\n",
        "    # Add the corresponding labels\n",
        "    encoded_datasets[split]['label'] = torch.tensor(df.label)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS872sOtUW60"
      },
      "source": [
        "To get an intutiton about the whole process, we can print a random sentence as well as the corresponding token IDs and the result after tokenize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uMO0Akt4VSR",
        "outputId": "68627b69-68f6-4abf-fe91-e196c6b9d00a"
      },
      "source": [
        "# Random index\n",
        "rnd_index = random.randint(0, len(datasets[split])-1)\n",
        "# Original sentence\n",
        "sentence = datasets[split].sentence[rnd_index]\n",
        "print('Original sentence:')\n",
        "print(sentence, '\\n')\n",
        "\n",
        "# IDs\n",
        "ids = encoded_datasets[split]['input_ids'][rnd_index]\n",
        "print('Token IDs:')\n",
        "print(ids.detach().numpy(), '\\n')\n",
        "\n",
        "# Token IDs\n",
        "#tokens = tokenizer.convert_ids_to_tokens(ids)\n",
        "print('After tokenization:')\n",
        "print(np.array(tokenizer.convert_ids_to_tokens(ids)))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence:\n",
            "substantial depth  \n",
            "\n",
            "Token IDs:\n",
            "[ 101 6937 5995  102    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0] \n",
            "\n",
            "After tokenization:\n",
            "['[CLS]' 'substantial' 'depth' '[SEP]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0qzQm6Ag2fG"
      },
      "source": [
        "We will create an iterator for our dataset using the torch [data loader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) class. This will help save on memory during training and boost the training speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmgor3yXeUsW"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "def generate_data_loaders(batch_size, test=False):\n",
        "    # Train and val dataloaders\n",
        "    if test is False:\n",
        "        dataloaders = list()\n",
        "        for dataset in (encoded_datasets['train'], \n",
        "                        encoded_datasets['val']):\n",
        "            \n",
        "            data = TensorDataset(dataset['input_ids'], \n",
        "                                dataset['attention_mask'], \n",
        "                                dataset['label'])\n",
        "            sampler = RandomSampler(data)\n",
        "            dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
        "            dataloaders.append(dataloader)\n",
        "        return tuple(dataloaders)\n",
        "\n",
        "    # Test dataloader\n",
        "    else:\n",
        "        dataset = encoded_datasets['test']\n",
        "        data = TensorDataset(dataset['input_ids'], \n",
        "                                dataset['attention_mask'], \n",
        "                                dataset['label'])\n",
        "        sampler = SequentialSampler(data)\n",
        "        return DataLoader(data, sampler=sampler, batch_size=batch_size)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPQVNkKcgfQp"
      },
      "source": [
        "## 5.4 - Create the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jqdXV0CFsG4"
      },
      "source": [
        "To fine-tune on GLUE, new parameters introduced are classification layer weigths $ W \\in \\mathbb R^{K \\ x \\ H} $, where $ K $ is the number of labels. Then we compute a standard classification loss with $ C $ and $ W $:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{log}(\\text{softmax}(CW^T))\n",
        "\\end{equation}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUkyebe_q0cZ"
      },
      "source": [
        "![Fine tune sentiment analysis](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/sentiment_analysis_fine_tune.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhpgGfl9heot"
      },
      "source": [
        "In **Sentiment Analysis** task, the final model is just a combination of BERT's encoder and a classifier to get the final probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bV6gHgCqrRP"
      },
      "source": [
        "![BERT Classifier](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/bert-classifier.png)\n",
        "\n",
        "> Diagram of BERT Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUAMrvRQYa_a"
      },
      "source": [
        "Hugging Face provides [`BertForSequenceClassification`](https://huggingface.co/transformers/model_doc/bert.html?highlight=berttokenizer#bertforsequenceclassification) to perform this task. However, in order to show the simplicity of fine-tune process, we are going to create our own model. At the end, this is the combination of the pre-trained [`BertModel`](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel) and a classifier, composed by a simple feed-forward neural netword with only one hidden layer, plus a softmax to get the probabilities of each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujfnQXfrhwcB"
      },
      "source": [
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_classifier=50, dropout=0.1, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        H = in_classifier\n",
        "        D_in = self.bert.config.hidden_size\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "                nn.Linear(D_in, H),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(H, 2)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        # outputs[0] = last_hidden_state\n",
        "        # last_hidden_state dimension: (n_batches x words x inner_dim_BERT)\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1NLY5sbc097"
      },
      "source": [
        "Finally, we have to decide the classifier's parameters. In our case the number of neurons in the hidden layer of the neural network as `in_classifier` and a dropout probability as `dropout_classifier`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r__KXCK8-9jI",
        "outputId": "75f5b443-c4cc-4242-c185-32ad4f2b3bfc"
      },
      "source": [
        "#@markdown Size classifier layer\n",
        "in_classifier = 50 #@param {type:\"integer\"}\n",
        "#@markdown Classifier droput probability\n",
        "dropout_classifier = 0.01 #@param {type:\"number\"}\n",
        "model = BertClassifier(in_classifier, dropout_classifier)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LVmrGBOeB15"
      },
      "source": [
        "With the model created, we can visualize each part: the whole model, only pretrained BERT or the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyXhITJRm0Pq",
        "outputId": "e420586c-9241-41d1-8d3f-57dd0ae14e44"
      },
      "source": [
        "#@markdown Select whole model, only pretrained BERT or the classifier\n",
        "block = \"classifier\" #@param [\"model\", \"bert\", \"classifier\"]\n",
        "if block == 'model':\n",
        "    print(model)\n",
        "else:\n",
        "    print(getattr(model, block))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=768, out_features=50, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Dropout(p=0.01, inplace=False)\n",
            "  (3): Linear(in_features=50, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6iOXiN8-8gc"
      },
      "source": [
        "To fine-tune our Bert Classifier, we need to create an optimizer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "D4RYJWzH0wYH"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def init_model(train_dataloader,\n",
        "               in_classifier=50, dropout_classifier=0.1, \n",
        "               learning_rate=5e-5, epsilon=1e-8, \n",
        "               epochs=4):\n",
        "    # Model\n",
        "    bert_classifier = BertClassifier(in_classifier, dropout_classifier)\n",
        "    # Run model in device\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(\n",
        "        bert_classifier.parameters(),\n",
        "        lr=learning_rate,    \n",
        "        eps=epsilon    \n",
        "    )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beqNViLcz0es"
      },
      "source": [
        "## 5.5 - Fine-Tune on SST-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf1km6oGwsat"
      },
      "source": [
        "Before going into detail about how to fine-tune the model, a recap about binary classification problems. There are 4 possible combinations in a binary classification problem (predict a class between two possible ones).\n",
        "\n",
        "- **True Positive (TP)**: if both predicted and actual values are *Positive*.\n",
        "- **False Positive (FP)**: if predicted value is *Positive* and actual one is *Negative*.\n",
        "- **False Negative (FN)**: if predicted value is *Negative* and actual one is *Positive*.\n",
        "- **True Negative (NP)**: if both predicted and actual values are *Negative*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSiDusMqx_Nx"
      },
      "source": [
        "![Confussion matrix](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/conf_matrix.png)\n",
        "\n",
        "> Confusion matrix. Predicted vs. real values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOQkdtq70lGH"
      },
      "source": [
        "One method to measure the performance of the model is the **accuracy**. This is defined as the coefficient between the number of correct predictions and the total number of predictions. Then, with previous classification possibilities defined we have:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}} = \\frac{TP \\ + \\ TN}{TP \\ + \\ TN \\ + \\ FP \\ + \\ FN}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za8pBoDYzw5B"
      },
      "source": [
        "In addition to the accuracy, we use the [cross-entropy loss](https://machinelearningmastery.com/cross-entropy-for-machine-learning/). Each sample has a known class label with a probability of 1.0, and 0.0 for the other label. The model can estimate the probability of an example belonging to each class label. Cross-entropy can then be used to calculate the difference between the two probability distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo_Ew7bvz74W"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb7K4dyOestG"
      },
      "source": [
        "To train the model, as in other architectures, we are going to iterate through batches. At the end of each epoch the model is evaluated respect the validation dataset. We use a [fixed seed](https://machinelearningmastery.com/reproducible-results-neural-networks-keras/) for the random number generator to ensure the same result in two consecutive executions with same parameters, and do not let it to random initialization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq2h2osmcg-D"
      },
      "source": [
        "import datetime\n",
        "import time\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round(elapsed))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBwRZLp97bTB"
      },
      "source": [
        "class BertTrainer():\n",
        "\n",
        "    def __init__(self, params):\n",
        "        self.epochs = params['epochs']\n",
        "        self.train_dataloader, self.val_dataloader = generate_data_loaders(params['batch_size'])\n",
        "        self.training_stats = []\n",
        "        self.model, self.optimizer, self.scheduler = init_model(self.train_dataloader,\n",
        "                                                                params['in_classifier'], params['dropout'],\n",
        "                                                                params['learning_rate'], params['epsilon'],\n",
        "                                                                self.epochs)\n",
        "        \n",
        "    def set_seed(self, seed_value=42):\n",
        "        \"\"\"Set seed for reproducibility.\n",
        "        \"\"\"\n",
        "        random.seed(seed_value)\n",
        "        np.random.seed(seed_value)\n",
        "        torch.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "    def train(self, evaluation=True):\n",
        "        self.set_seed(42)\n",
        "        info_device()\n",
        "        for epoch_i in range(self.epochs):\n",
        "\n",
        "            # =======================================\n",
        "            #               Training\n",
        "            # =======================================\n",
        "            print(f'======== Epoch {epoch_i+1} / {epochs} ========\\n')\n",
        "\n",
        "            # Print the header of the result table\n",
        "            print(f'Training: {len(self.train_dataloader)} batches\\n')\n",
        "            print(f\"{'Batch':^7} | {'Train Loss':^12} | {'Elapsed':^9}\")\n",
        "            print(\"-\"*35)\n",
        "\n",
        "            # Measure the elapsed time of each epoch\n",
        "            training_time = 0\n",
        "            t0_batch = time.time()\n",
        "\n",
        "            # Reset tracking variables at the beginning of each epoch\n",
        "            total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "            # Put the model into the training mode\n",
        "            self.model.train()\n",
        "\n",
        "            # For each batch of training data...\n",
        "            for step, batch in enumerate(self.train_dataloader):\n",
        "\n",
        "                batch_counts +=1\n",
        "                # Load batch to device\n",
        "                b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "                # Zero out any previously calculated gradients\n",
        "                self.model.zero_grad()\n",
        "\n",
        "                # Perform a forward pass. This will return logits.\n",
        "                logits = self.model(b_input_ids, b_attn_mask)\n",
        "\n",
        "                # Compute loss and accumulate the loss values\n",
        "                loss = loss_fn(logits, b_labels)\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                # Perform a backward pass to calculate gradients\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "\n",
        "                # Update parameters and the learning rate\n",
        "                self.optimizer.step()\n",
        "                self.scheduler.step()\n",
        "\n",
        "                # Print the loss values and time elapsed for every 20 batches\n",
        "                if (step % 20 == 0 and step != 0) or (step == len(self.train_dataloader) - 1):\n",
        "                    # Calculate time elapsed for 20 batches\n",
        "                    time_elapsed = time.time() - t0_batch\n",
        "                    training_time += time_elapsed\n",
        "                    time_elapsed = format_time(time_elapsed)\n",
        "\n",
        "                    # Print training results\n",
        "                    print(f\"{step:^7} | {batch_loss / batch_counts:^12.6f} | {time_elapsed:^9}\")\n",
        "\n",
        "                    # Reset batch tracking variables\n",
        "                    batch_loss, batch_counts = 0, 0\n",
        "                    t0_batch = time.time()\n",
        "\n",
        "            # Calculate the average loss over the entire training data\n",
        "            avg_train_loss = total_loss / len(self.train_dataloader)\n",
        "            # Format training_time\n",
        "            training_time = format_time(training_time)\n",
        "\n",
        "            print(\"-\"*35)\n",
        "            print(f\"{'-':^7} | {avg_train_loss:^12.6f} | {training_time:^9}\")\n",
        "            print(\"-\"*35)\n",
        "            print(\"\\n\")\n",
        "\n",
        "            # =======================================\n",
        "            #               Evaluation\n",
        "            # =======================================\n",
        "\n",
        "            if evaluation:\n",
        "                # After the completion of each training epoch, measure the model's performance\n",
        "                # on our validation set.\n",
        "                val_loss, val_accuracy, validation_time = self.evaluate()\n",
        "\n",
        "            print(\"\\n\")\n",
        "\n",
        "            # Record all statistics from this epoch.\n",
        "            self.training_stats.append(\n",
        "                {\n",
        "                    'epoch': epoch_i + 1,\n",
        "                    'Training Loss': avg_train_loss,\n",
        "                    'Validation Loss': val_loss,\n",
        "                    'Accuracy': val_accuracy,\n",
        "                    'Training Time': training_time,\n",
        "                    'Validation Time': validation_time\n",
        "                }\n",
        "            )\n",
        "\n",
        "        # Finished all epochs\n",
        "        print(\"Training completed!\")\n",
        "\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "        on our validation set.\n",
        "        \"\"\"\n",
        "        # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "        # the test time.\n",
        "        self.model.eval()\n",
        "\n",
        "        # Set time\n",
        "        t0_val = time.time()\n",
        "\n",
        "        # Tracking variables\n",
        "        val_accuracy = []\n",
        "        val_loss = []\n",
        "\n",
        "        # For each batch in our validation set...\n",
        "        for batch in self.val_dataloader:\n",
        "            # Load batch to device\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Compute logits\n",
        "            with torch.no_grad(): \n",
        "                logits = self.model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "            # Get the predictions\n",
        "            preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "            # Calculate the accuracy rate\n",
        "            accuracy = (preds == b_labels).cpu().numpy().mean()\n",
        "            val_accuracy.append(accuracy)\n",
        "\n",
        "        # Compute the average accuracy and loss over the validation set.\n",
        "        val_loss = np.mean(val_loss)\n",
        "        val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "        # Compute elapsed time\n",
        "        time_elapsed = format_time(time.time() - t0_val)\n",
        "\n",
        "        print('Evaluation\\n')\n",
        "        print(f\"{'Val Loss':^10} | {'Accuracy':^10} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*35)\n",
        "        print(f\"{val_loss:^10.6f} | {val_accuracy:^10.6f} | {time_elapsed:^9}\")\n",
        "        print(\"-\"*35)\n",
        "\n",
        "        return val_loss, val_accuracy, time_elapsed"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Owa1c6DDge93"
      },
      "source": [
        "Once we have declared the `BertTrainer` class, it is only necessary to specify the parameters to train the model. The authors recommend following hyper-parameters:\n",
        "\n",
        "- Batch size: 16 or 32\n",
        "- Learning rate for AdamW optimizer: 5e-5, 3e-5 or 2e-5\n",
        "- Number of epochs: 2, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX0SIOS7AtWH"
      },
      "source": [
        "#@title 5.5.1 - Hyperparameters Selection\n",
        "in_classifier = 50 #@param {type:\"integer\"}\n",
        "dropout_classifier = 0.1 #@param {type:\"number\"}\n",
        "batch_size =  32#@param {type:\"integer\"}\n",
        "learning_rate = 5e-5 #@param {type:\"number\"}\n",
        "epochs =  3#@param {type:\"integer\"}\n",
        "epsilon = 1e-8 #@param {type:\"number\"}\n",
        "\n",
        "args = {\n",
        "    'batch_size': batch_size,\n",
        "    'in_classifier': in_classifier,\n",
        "    'dropout': dropout_classifier,\n",
        "    'learning_rate': learning_rate,\n",
        "    'epsilon': epsilon,\n",
        "    'epochs': epochs,\n",
        "}"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vkGIBQ9jIrY"
      },
      "source": [
        "And now we only need to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THVUZrz-jIKy",
        "outputId": "d30e948d-3f99-4f1f-c657-545b1f52a895"
      },
      "source": [
        "trainer = BertTrainer(args)\n",
        "bert_classifier = trainer.model\n",
        "trainer.train()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using GPU Tesla P100-PCIE-16GB. \n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "\n",
            "Training: 1411 batches\n",
            "\n",
            " Batch  |  Train Loss  |  Elapsed \n",
            "-----------------------------------\n",
            "  20    |   0.594820   |  0:00:05 \n",
            "  40    |   0.437119   |  0:00:05 \n",
            "  60    |   0.350687   |  0:00:05 \n",
            "  80    |   0.373798   |  0:00:04 \n",
            "  100   |   0.301961   |  0:00:04 \n",
            "  120   |   0.281907   |  0:00:04 \n",
            "  140   |   0.369403   |  0:00:04 \n",
            "  160   |   0.279932   |  0:00:04 \n",
            "  180   |   0.258973   |  0:00:04 \n",
            "  200   |   0.288279   |  0:00:05 \n",
            "  220   |   0.268619   |  0:00:05 \n",
            "  240   |   0.283780   |  0:00:04 \n",
            "  260   |   0.230329   |  0:00:04 \n",
            "  280   |   0.251350   |  0:00:05 \n",
            "  300   |   0.251501   |  0:00:04 \n",
            "  320   |   0.236274   |  0:00:04 \n",
            "  340   |   0.261550   |  0:00:05 \n",
            "  360   |   0.215508   |  0:00:04 \n",
            "  380   |   0.251708   |  0:00:05 \n",
            "  400   |   0.250090   |  0:00:04 \n",
            "  420   |   0.237201   |  0:00:04 \n",
            "  440   |   0.238205   |  0:00:04 \n",
            "  460   |   0.236797   |  0:00:04 \n",
            "  480   |   0.252670   |  0:00:05 \n",
            "  500   |   0.222924   |  0:00:04 \n",
            "  520   |   0.197746   |  0:00:04 \n",
            "  540   |   0.228648   |  0:00:04 \n",
            "  560   |   0.231988   |  0:00:04 \n",
            "  580   |   0.198080   |  0:00:04 \n",
            "  600   |   0.261458   |  0:00:05 \n",
            "  620   |   0.235857   |  0:00:04 \n",
            "  640   |   0.217918   |  0:00:04 \n",
            "  660   |   0.231648   |  0:00:05 \n",
            "  680   |   0.188360   |  0:00:04 \n",
            "  700   |   0.235695   |  0:00:04 \n",
            "  720   |   0.174407   |  0:00:04 \n",
            "  740   |   0.226846   |  0:00:04 \n",
            "  760   |   0.206273   |  0:00:04 \n",
            "  780   |   0.206333   |  0:00:04 \n",
            "  800   |   0.198325   |  0:00:04 \n",
            "  820   |   0.222146   |  0:00:04 \n",
            "  840   |   0.206344   |  0:00:04 \n",
            "  860   |   0.222196   |  0:00:04 \n",
            "  880   |   0.174761   |  0:00:04 \n",
            "  900   |   0.176433   |  0:00:05 \n",
            "  920   |   0.256068   |  0:00:05 \n",
            "  940   |   0.202234   |  0:00:05 \n",
            "  960   |   0.179071   |  0:00:04 \n",
            "  980   |   0.188692   |  0:00:04 \n",
            " 1000   |   0.188433   |  0:00:04 \n",
            " 1020   |   0.160693   |  0:00:05 \n",
            " 1040   |   0.202717   |  0:00:04 \n",
            " 1060   |   0.220555   |  0:00:04 \n",
            " 1080   |   0.200393   |  0:00:04 \n",
            " 1100   |   0.171707   |  0:00:04 \n",
            " 1120   |   0.175271   |  0:00:04 \n",
            " 1140   |   0.205547   |  0:00:04 \n",
            " 1160   |   0.166423   |  0:00:05 \n",
            " 1180   |   0.192327   |  0:00:05 \n",
            " 1200   |   0.136133   |  0:00:04 \n",
            " 1220   |   0.214982   |  0:00:05 \n",
            " 1240   |   0.165796   |  0:00:04 \n",
            " 1260   |   0.202230   |  0:00:05 \n",
            " 1280   |   0.180694   |  0:00:04 \n",
            " 1300   |   0.175379   |  0:00:04 \n",
            " 1320   |   0.179297   |  0:00:04 \n",
            " 1340   |   0.180432   |  0:00:04 \n",
            " 1360   |   0.178001   |  0:00:04 \n",
            " 1380   |   0.206532   |  0:00:04 \n",
            " 1400   |   0.145416   |  0:00:04 \n",
            " 1410   |   0.124790   |  0:00:02 \n",
            "-----------------------------------\n",
            "   -    |   0.230106   |  0:05:17 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "Evaluation\n",
            "\n",
            " Val Loss  |  Accuracy  |  Elapsed \n",
            "-----------------------------------\n",
            " 0.265750  |  0.918527  |  0:00:02 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "\n",
            "Training: 1411 batches\n",
            "\n",
            " Batch  |  Train Loss  |  Elapsed \n",
            "-----------------------------------\n",
            "  20    |   0.073684   |  0:00:05 \n",
            "  40    |   0.099593   |  0:00:05 \n",
            "  60    |   0.129891   |  0:00:05 \n",
            "  80    |   0.069543   |  0:00:04 \n",
            "  100   |   0.097948   |  0:00:04 \n",
            "  120   |   0.097687   |  0:00:04 \n",
            "  140   |   0.119813   |  0:00:04 \n",
            "  160   |   0.114485   |  0:00:04 \n",
            "  180   |   0.110638   |  0:00:04 \n",
            "  200   |   0.094508   |  0:00:05 \n",
            "  220   |   0.095065   |  0:00:04 \n",
            "  240   |   0.103606   |  0:00:04 \n",
            "  260   |   0.095944   |  0:00:04 \n",
            "  280   |   0.097062   |  0:00:04 \n",
            "  300   |   0.083154   |  0:00:05 \n",
            "  320   |   0.079007   |  0:00:05 \n",
            "  340   |   0.123202   |  0:00:05 \n",
            "  360   |   0.117752   |  0:00:05 \n",
            "  380   |   0.131261   |  0:00:05 \n",
            "  400   |   0.069624   |  0:00:05 \n",
            "  420   |   0.072874   |  0:00:05 \n",
            "  440   |   0.136612   |  0:00:05 \n",
            "  460   |   0.081754   |  0:00:05 \n",
            "  480   |   0.100706   |  0:00:05 \n",
            "  500   |   0.141537   |  0:00:05 \n",
            "  520   |   0.099608   |  0:00:05 \n",
            "  540   |   0.112656   |  0:00:04 \n",
            "  560   |   0.127765   |  0:00:04 \n",
            "  580   |   0.127243   |  0:00:04 \n",
            "  600   |   0.115704   |  0:00:04 \n",
            "  620   |   0.125418   |  0:00:04 \n",
            "  640   |   0.112627   |  0:00:04 \n",
            "  660   |   0.124983   |  0:00:04 \n",
            "  680   |   0.090048   |  0:00:04 \n",
            "  700   |   0.106911   |  0:00:04 \n",
            "  720   |   0.117750   |  0:00:04 \n",
            "  740   |   0.118897   |  0:00:04 \n",
            "  760   |   0.071674   |  0:00:04 \n",
            "  780   |   0.112982   |  0:00:04 \n",
            "  800   |   0.096081   |  0:00:04 \n",
            "  820   |   0.090005   |  0:00:04 \n",
            "  840   |   0.116208   |  0:00:04 \n",
            "  860   |   0.119611   |  0:00:04 \n",
            "  880   |   0.088636   |  0:00:04 \n",
            "  900   |   0.105149   |  0:00:04 \n",
            "  920   |   0.096139   |  0:00:04 \n",
            "  940   |   0.083286   |  0:00:05 \n",
            "  960   |   0.140003   |  0:00:04 \n",
            "  980   |   0.118999   |  0:00:04 \n",
            " 1000   |   0.107233   |  0:00:04 \n",
            " 1020   |   0.142684   |  0:00:04 \n",
            " 1040   |   0.143187   |  0:00:04 \n",
            " 1060   |   0.086926   |  0:00:04 \n",
            " 1080   |   0.099656   |  0:00:04 \n",
            " 1100   |   0.114866   |  0:00:04 \n",
            " 1120   |   0.105302   |  0:00:04 \n",
            " 1140   |   0.096852   |  0:00:04 \n",
            " 1160   |   0.098767   |  0:00:04 \n",
            " 1180   |   0.074267   |  0:00:04 \n",
            " 1200   |   0.085456   |  0:00:04 \n",
            " 1220   |   0.105475   |  0:00:04 \n",
            " 1240   |   0.071382   |  0:00:04 \n",
            " 1260   |   0.140006   |  0:00:04 \n",
            " 1280   |   0.091383   |  0:00:04 \n",
            " 1300   |   0.164539   |  0:00:04 \n",
            " 1320   |   0.144595   |  0:00:04 \n",
            " 1340   |   0.084051   |  0:00:04 \n",
            " 1360   |   0.061330   |  0:00:04 \n",
            " 1380   |   0.088596   |  0:00:04 \n",
            " 1400   |   0.125008   |  0:00:04 \n",
            " 1410   |   0.161261   |  0:00:02 \n",
            "-----------------------------------\n",
            "   -    |   0.105900   |  0:05:16 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "Evaluation\n",
            "\n",
            " Val Loss  |  Accuracy  |  Elapsed \n",
            "-----------------------------------\n",
            " 0.272132  |  0.921875  |  0:00:02 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "\n",
            "Training: 1411 batches\n",
            "\n",
            " Batch  |  Train Loss  |  Elapsed \n",
            "-----------------------------------\n",
            "  20    |   0.060758   |  0:00:05 \n",
            "  40    |   0.078574   |  0:00:04 \n",
            "  60    |   0.040253   |  0:00:04 \n",
            "  80    |   0.074244   |  0:00:04 \n",
            "  100   |   0.030892   |  0:00:04 \n",
            "  120   |   0.056373   |  0:00:04 \n",
            "  140   |   0.075627   |  0:00:04 \n",
            "  160   |   0.030853   |  0:00:04 \n",
            "  180   |   0.059997   |  0:00:04 \n",
            "  200   |   0.065142   |  0:00:04 \n",
            "  220   |   0.047742   |  0:00:04 \n",
            "  240   |   0.054948   |  0:00:04 \n",
            "  260   |   0.029407   |  0:00:04 \n",
            "  280   |   0.067557   |  0:00:04 \n",
            "  300   |   0.044758   |  0:00:04 \n",
            "  320   |   0.067717   |  0:00:04 \n",
            "  340   |   0.043061   |  0:00:04 \n",
            "  360   |   0.042496   |  0:00:04 \n",
            "  380   |   0.095344   |  0:00:04 \n",
            "  400   |   0.040127   |  0:00:04 \n",
            "  420   |   0.080905   |  0:00:04 \n",
            "  440   |   0.018381   |  0:00:04 \n",
            "  460   |   0.067945   |  0:00:04 \n",
            "  480   |   0.080781   |  0:00:04 \n",
            "  500   |   0.039621   |  0:00:04 \n",
            "  520   |   0.076255   |  0:00:04 \n",
            "  540   |   0.053821   |  0:00:04 \n",
            "  560   |   0.108361   |  0:00:04 \n",
            "  580   |   0.046406   |  0:00:04 \n",
            "  600   |   0.056247   |  0:00:04 \n",
            "  620   |   0.078013   |  0:00:04 \n",
            "  640   |   0.060597   |  0:00:04 \n",
            "  660   |   0.041377   |  0:00:04 \n",
            "  680   |   0.072292   |  0:00:04 \n",
            "  700   |   0.035585   |  0:00:04 \n",
            "  720   |   0.051748   |  0:00:04 \n",
            "  740   |   0.054523   |  0:00:04 \n",
            "  760   |   0.067309   |  0:00:04 \n",
            "  780   |   0.065173   |  0:00:04 \n",
            "  800   |   0.054451   |  0:00:04 \n",
            "  820   |   0.080523   |  0:00:04 \n",
            "  840   |   0.074345   |  0:00:04 \n",
            "  860   |   0.060683   |  0:00:04 \n",
            "  880   |   0.048259   |  0:00:04 \n",
            "  900   |   0.046421   |  0:00:04 \n",
            "  920   |   0.055089   |  0:00:04 \n",
            "  940   |   0.051863   |  0:00:04 \n",
            "  960   |   0.087878   |  0:00:04 \n",
            "  980   |   0.038504   |  0:00:04 \n",
            " 1000   |   0.050723   |  0:00:04 \n",
            " 1020   |   0.050777   |  0:00:04 \n",
            " 1040   |   0.035005   |  0:00:04 \n",
            " 1060   |   0.062082   |  0:00:04 \n",
            " 1080   |   0.055904   |  0:00:04 \n",
            " 1100   |   0.049720   |  0:00:04 \n",
            " 1120   |   0.058608   |  0:00:04 \n",
            " 1140   |   0.059931   |  0:00:04 \n",
            " 1160   |   0.053162   |  0:00:04 \n",
            " 1180   |   0.063436   |  0:00:04 \n",
            " 1200   |   0.058945   |  0:00:04 \n",
            " 1220   |   0.050578   |  0:00:04 \n",
            " 1240   |   0.039514   |  0:00:04 \n",
            " 1260   |   0.033200   |  0:00:04 \n",
            " 1280   |   0.055645   |  0:00:04 \n",
            " 1300   |   0.034922   |  0:00:04 \n",
            " 1320   |   0.051704   |  0:00:04 \n",
            " 1340   |   0.034471   |  0:00:04 \n",
            " 1360   |   0.053350   |  0:00:04 \n",
            " 1380   |   0.058071   |  0:00:04 \n",
            " 1400   |   0.050435   |  0:00:04 \n",
            " 1410   |   0.053603   |  0:00:02 \n",
            "-----------------------------------\n",
            "   -    |   0.055978   |  0:05:14 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "Evaluation\n",
            "\n",
            " Val Loss  |  Accuracy  |  Elapsed \n",
            "-----------------------------------\n",
            " 0.302988  |  0.927455  |  0:00:02 \n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "Training completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZBJw6_Kufca"
      },
      "source": [
        "After training the model, we can easily print its statistics in a data frame and save it as an excel table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "d9cqHoFsscUh",
        "outputId": "61009558-cd35-400f-e66c-7b193dc84b4e"
      },
      "source": [
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=trainer.training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Save data frame\n",
        "df_stats.to_excel(sentiment_dir/'training_stats.xlsx')\n",
        "\n",
        "df_stats"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.230106</td>\n",
              "      <td>0.265750</td>\n",
              "      <td>0.918527</td>\n",
              "      <td>0:05:17</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.105900</td>\n",
              "      <td>0.272132</td>\n",
              "      <td>0.921875</td>\n",
              "      <td>0:05:16</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.055978</td>\n",
              "      <td>0.302988</td>\n",
              "      <td>0.927455</td>\n",
              "      <td>0:05:14</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Validation Loss  Accuracy Training Time Validation Time\n",
              "epoch                                                                        \n",
              "1           0.230106         0.265750  0.918527       0:05:17         0:00:02\n",
              "2           0.105900         0.272132  0.921875       0:05:16         0:00:02\n",
              "3           0.055978         0.302988  0.927455       0:05:14         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FlBfCt1vzj9"
      },
      "source": [
        "We can print how both (training and validation) losses evolve during epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P38nQ_tbvpm2"
      },
      "source": [
        "def plot_loss_curves(df):\n",
        "    # Use plot styling from seaborn.\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "    # Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(df['Training Loss'], 'b-o', label=\"Training\")\n",
        "    plt.plot(df['Validation Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.xticks(df.index.values)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "54tP7ZpO-5Ui",
        "outputId": "f026c34e-f81a-48c7-91f6-27275926f472"
      },
      "source": [
        "plot_loss_curves(df_stats)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C--5u9xt5du0"
      },
      "source": [
        "While the the training loss is going down with each epoch, the validation loss is increasing. This suggests that we are training our model too long, and it is over-fitting on the training data.\n",
        "\t\t\t\n",
        "Validation loss is a more precise measure than accuracy, because with accuracy we do not care about the exact output value, but just which side of a threshold it falls on. If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkNh9tB_-efC"
      },
      "source": [
        "### 5.5.2 - Save and load model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7mkkuXoGVZ_"
      },
      "source": [
        "Last step is to save the fine-tuned model as well as the training arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "safVP_6TBr7n"
      },
      "source": [
        "def save_json(path, file):\n",
        "    with open(path, \"w\") as outfile:\n",
        "        json.dump(file, outfile)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gNPJgkmbYwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "885418ec-598e-4fa9-d6d8-3d2f4e595d85"
      },
      "source": [
        "print('Saving model...')\n",
        "torch.save(bert_classifier.state_dict(), sentiment_dir/'pytorch_model.pt')\n",
        "\n",
        "print('Saving tokenizer data...')\n",
        "tokenizer.save_pretrained(sentiment_dir)\n",
        "\n",
        "print('Saving training arguments...')\n",
        "save_json(sentiment_dir/'training_args.json', args)\n",
        "\n",
        "print('Saving training statistics..')\n",
        "save_json(sentiment_dir/'training_stats.json', trainer.training_stats)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model...\n",
            "Saving tokenizer data...\n",
            "Saving training arguments...\n",
            "Saving training statistics..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvizxatWVn-R"
      },
      "source": [
        "And if we want to load it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af4Zxg15Vqyr"
      },
      "source": [
        "'''path = '/content/drive/MyDrive/Degree/TFG/Models/BertForSentimentAnalysis/pytorch_model.pt'\n",
        "\n",
        "bert_classifier = BertClassifier()\n",
        "bert_classifier.load_state_dict(torch.load(path))\n",
        "bert_classifier.to(device)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDi8plm1iAp6"
      },
      "source": [
        "## 5.6 - Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2WZqXed64Bu"
      },
      "source": [
        "Once our model is fine-tuned, we can evaluate it with the test dataset. We need to define the prediction function which is going to be almost equal to the previous evaluation function, but applying a **softmax** to return the probabilities per class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4beq2q02L13"
      },
      "source": [
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Predictions\n",
        "    all_logits = []\n",
        "\n",
        "    # Set time\n",
        "    t0_test = time.time()\n",
        "\n",
        "    # Tracking variables\n",
        "    test_accuracy = []\n",
        "    test_loss = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    info_device()\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to device\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        test_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean()\n",
        "        test_accuracy.append(accuracy)\n",
        "    \n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    test_loss = np.mean(test_loss)\n",
        "    test_accuracy = np.mean(test_accuracy)\n",
        "\n",
        "    # Compute elapsed time\n",
        "    time_elapsed = format_time(time.time() - t0_test)\n",
        "\n",
        "    # Calculate probabilities\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    test_stats = {\n",
        "        'Test Loss': test_loss,\n",
        "        'Accuracy': test_accuracy,\n",
        "        'Test time': time_elapsed\n",
        "    }\n",
        "\n",
        "    print(f\"{'Test Loss':^12} | {'Accuracy':^10} | {'Test time':^11}\")\n",
        "    print(\"-\"*40)\n",
        "    print(f\"{test_loss:^12.6f} | {test_accuracy:^10.6f} | {time_elapsed:^11}\")\n",
        "    print(\"-\"*40)\n",
        "  \n",
        "    return probs, test_stats"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgDYuFTztwfN"
      },
      "source": [
        "From `BertTrainer` we get the `model` and the `test_dataloader`. Using last function, we get the corresponding probabilities for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy4fJdpU2ep1",
        "outputId": "57b6088e-ccb6-4d86-b9f9-346f97bc7a7b"
      },
      "source": [
        "# Compute probabilities in test set\n",
        "probs, test_stats= bert_predict(bert_classifier, generate_data_loaders(32, test=True))\n",
        "\n",
        "# Compute predictions\n",
        "preds = np.argmax(probs, axis=1)\n",
        "\n",
        "# Test labels\n",
        "test_df = datasets['test']\n",
        "y_true = test_df.label"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using GPU Tesla P100-PCIE-16GB. \n",
            "\n",
            " Test Loss   |  Accuracy  |  Test time \n",
            "----------------------------------------\n",
            "  0.214045   |  0.949241  |   0:00:46  \n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14_4pt8LdERy",
        "outputId": "89b32852-939d-4287-e096-9a0f8a5736b8"
      },
      "source": [
        "print('Saving test statistics..')\n",
        "save_json(sentiment_dir/'test_stats.json', test_stats)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving test statistics..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsP8WSWyaoW9"
      },
      "source": [
        "To get a fast intuition on the result, we can plot some predicted sentences. Remember that the label 1 corresponds with positive sentiment while label 0 with negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Jfc4r_BWMoGm",
        "outputId": "16547f83-9c8e-4139-db19-4811a77239b3"
      },
      "source": [
        "num_examples = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "df = test_df.sample(num_examples)\n",
        "df['real'] = np.where(df.label==0, 'negative', 'positive')\n",
        "df['predicted'] = np.where(preds[df.index]==0, 'negative', 'positive')\n",
        "df['probability'] = np.amax(probs, axis=1)[df.index]\n",
        "pd.set_option(\"max_colwidth\", 150)\n",
        "df"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>real</th>\n",
              "      <th>predicted</th>\n",
              "      <th>probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1891</th>\n",
              "      <td>fascinating -- and timely --</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.999180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20706</th>\n",
              "      <td>, sarah 's dedication to finding her husband seems more psychotic than romantic , and nothing in the movie makes a convincing case that one woman ...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.998587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14030</th>\n",
              "      <td>interesting social</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.999140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15419</th>\n",
              "      <td>found this a remarkable and novel concept</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.999182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17873</th>\n",
              "      <td>goals</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.998932</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                    sentence  ...  probability\n",
              "1891                                                                                                                           fascinating -- and timely --   ...     0.999180\n",
              "20706  , sarah 's dedication to finding her husband seems more psychotic than romantic , and nothing in the movie makes a convincing case that one woman ...  ...     0.998587\n",
              "14030                                                                                                                                    interesting social   ...     0.999140\n",
              "15419                                                                                                             found this a remarkable and novel concept   ...     0.999182\n",
              "17873                                                                                                                                                 goals   ...     0.998932\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3HkKh0_YJoK"
      },
      "source": [
        "### 5.6.1 - Variable Threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsSlCGCAajmD"
      },
      "source": [
        "Sentiment classification task is even difficult for human. Therefore, define a threshold is going to provide a safer margin to classify one class. \n",
        "\n",
        "For example, if we define that positive sentiment sample are the only ones where probability of being *positive* is bigger than 0.9, samples classified as positive are going to have surely positive sentiment. The main drawback here is all samples wich are positive and are classified as negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yvLZpyAYp1A"
      },
      "source": [
        "To get a better intuiton about the performance, we can plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8-eUICKC5ks"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        title = \"Normalized confusion matrix\"\n",
        "    else:\n",
        "        title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.min() + ((cm.max() - cm.min()) / 2)\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.grid(False)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "saeayM_oD1ng",
        "outputId": "90cd6947-583f-4ffc-c842-4a8ee45c8896"
      },
      "source": [
        "plot_confusion_matrix(confusion_matrix(preds, y_true), ('positive', 'negative'))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFXyQR063Z4M"
      },
      "source": [
        "A useful tool to determine an optimal threshold  is the **Receiver Operating Characteristic curve (ROC)**. It is a plot of the false positive rate (x-axis) versus the true positive rate (y-axis) for a number of different candidate threshold values between 0.0 and 1.0.\n",
        "\n",
        "The **true positive rate** is calculated as the number of true positives divided by the sum of the number of true positives and the number of false negatives. It is also called as **hit rate** and describes how good the model is at predicting the positive class when the actual outcome is positive. It is also known as **sensitivity** or **recall**.\n",
        "\n",
        "\\begin{equation}\n",
        "    TPR = \\frac{TP}{TP \\ + \\ FN}\n",
        "\\end{equation}\n",
        "\n",
        "The **false positive rate** is calculated as the number of false positives divided by the sum of the number of false positives and the number of true negatives. It is also called the **false alarm rate** as it summarizes how often a positive class is predicted when the actual outcome is negative.\n",
        "\n",
        "\\begin{equation}\n",
        "    FPR = \\frac{FP}{FP \\ + \\ TN}\n",
        "\\end{equation}\n",
        "\n",
        "The complement of the FPR is the **specificity** and it is calculated as:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\text{Specificity} = 1 - FPR\n",
        "\\end{equation}\n",
        "\n",
        "The Geometric Mean or G-Mean is a metric for imbalanced classification that, if optimized, will seek a balance between the sensitivity and the specificity.\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{G-Mean} = \\sqrt{\\text{Sensitivity} \\cdot \\text{Specificity}}\n",
        "\\end{equation}\n",
        "\n",
        "One approach to determine the optimized threshold would be to test the model with each threshold and select the one with the largest G-Mean value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdRopsSbtvBh"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, probs[:, 1])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "    \n",
        "    # title\n",
        "    plt.title(f'Receiver Operating Characteristic\\nAUC = {roc_auc:.2f}, Best G-Mean = {gmeans[ix]:.2f}')\n",
        "    # plot ROC curve\n",
        "    plt.plot([0, 1], [0, 1],'--', label='No skill')\n",
        "    plt.plot(fpr, tpr, marker='.', label='Bert Classifier')\n",
        "    plt.plot(fpr[ix], tpr[ix], marker='o', color='black', label=f'Best threshold = {thresholds[ix]:.2f}')\n",
        "    # show legend\n",
        "    plt.legend(loc = 'lower right')\n",
        "    # axis labels\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    # show plot\n",
        "    plt.show()\n",
        "    return tpr, fpr, thresholds"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ojBpEORfuTfI",
        "outputId": "192b1514-9e1a-4983-c290-af0d19467949"
      },
      "source": [
        "tpr, fpr, thresholds = evaluate_roc(probs, y_true)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXWo7a4bZpKs"
      },
      "source": [
        "An excellent model has AUC near to the 1 which means it has a good measure of separability. A poor model has AUC near to the 0 which means it has the worst measure of separability. In fact, it means it is reciprocating the result. It is predicting 0s as 1s and 1s as 0s. And when AUC is 0.5, it means the model has no class separation capacity whatsoever."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDdnlu47DubS"
      },
      "source": [
        "To confirm the result we can check it with the [Youden's J statistic](https://en.wikipedia.org/wiki/Youden%27s_J_statistic) which is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\begin{split}\n",
        "        &J = \\text{Sensitivity} + \\text{Specificity} - 1 = \\\\\n",
        "        &TPR + (1 - FPR) - 1 = TPR - FPR\n",
        "    \\end{split}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILv2twvdv7OE",
        "outputId": "675a3a88-3f76-4a79-eceb-3fc5b579c9b2"
      },
      "source": [
        "# get the best threshold\n",
        "J = tpr - fpr\n",
        "ix = np.argmax(J)\n",
        "best_thres = thresholds[ix]\n",
        "print('Best threshold = %.2f' % (best_thres))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best threshold = 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPu5KLWpl7B5"
      },
      "source": [
        "Another way to evaluate the skill of a prediction model is with the **Precision-Recall** curve.\n",
        "\n",
        "Precision is a ratio of the number of true positives divided by the sum of the true positives and false positives. It describes how good a model is at predicting the positive class. Precision is referred to as the positive predictive value.\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{Precision} = \\frac{TP}{TP \\ + \\ FP}\n",
        "\\end{equation}\n",
        "\n",
        "As it has been mentioned, **recall** is the same as TPR.\n",
        "\n",
        "F-Measure or **F1 score** is defined as the harmonic mean of precision (P) and recall (R).\n",
        "\n",
        "\\begin{equation}\n",
        "    F1 = \\frac{2PR}{P \\ + \\ R}\n",
        "\\end{equation}\n",
        "\n",
        "As in the ROC curve, the approach to finding the optimal threshold would be to calculate the F-measure for each threshold and select the largest one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5pEb0H4pmE4"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "def evaluate_prec_recall(probs, preds, y_true):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, probs[:, 1])\n",
        "\n",
        "    # convert to f score\n",
        "    fscore = (2 * precision * recall) / (precision + recall)\n",
        "    # locate the index of the largest f score\n",
        "    ix = np.argmax(fscore)\n",
        "\n",
        "    # title\n",
        "    plt.title(f'Precision-Recall\\nBest F1 score = {fscore[ix]:.2f}')\n",
        "    # plot the precision-recall curves\n",
        "    no_skill = len(y_true[y_true==1]) / len(y_true)\n",
        "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No skill')\n",
        "    plt.plot(recall, precision, marker='.', label='Bert Classifier')\n",
        "    plt.plot(recall[ix], precision[ix], marker='o', color='black', label=f'Best threshold = {thresholds[ix]:.2f}')\n",
        "    # show legend\n",
        "    plt.legend()\n",
        "    # axis labels\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    # show the plot\n",
        "    plt.show()"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "AixYhUNZmycW",
        "outputId": "c034c25d-440b-435a-967e-abe338ff2d38"
      },
      "source": [
        "evaluate_prec_recall(probs, preds, y_true)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bXiLFZnBvmk"
      },
      "source": [
        "A model with perfect skill is depicted as a point at (1,1). A skilful model is represented by a curve that bows towards (1,1) above the flat line of no skill."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwA726ILA6kv"
      },
      "source": [
        "ROC curves should be used when there are roughly equal numbers of observations for each class. Precision-Recall curves should be used when there is a moderate to large class imbalance. The reason for this recommendation is that ROC curves present an optimistic picture of the model on datasets with a class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkcwMyOGJX-M"
      },
      "source": [
        "Finally, we can predict test samples with the optimized threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "OUPJwQ5K2cS1",
        "outputId": "f806ecda-602f-4c9b-9b79-113569943771"
      },
      "source": [
        "# Get new predictions respect best threshold\n",
        "preds_thres = np.where(probs[:, 1] > best_thres, 1, 0)\n",
        "\n",
        "num_examples = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "df = test_df.sample(num_examples)\n",
        "df['real'] = np.where(df.label==0, 'negative', 'positive')\n",
        "df['predicted'] = np.where(preds_thres[df.index]==0, 'negative', 'positive')\n",
        "df['positive probability'] = probs[df.index, 1]\n",
        "df['negative probability'] = probs[df.index, 0]\n",
        "pd.set_option(\"max_colwidth\", 150)\n",
        "print(f'Threshold: {best_thres:.2f}')\n",
        "df"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Threshold: 0.94\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>real</th>\n",
              "      <th>predicted</th>\n",
              "      <th>positive probability</th>\n",
              "      <th>negative probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17964</th>\n",
              "      <td>the costuming of the stars</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.998746</td>\n",
              "      <td>0.001254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5055</th>\n",
              "      <td>lofty</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.998983</td>\n",
              "      <td>0.001017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13665</th>\n",
              "      <td>truly funny</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.999195</td>\n",
              "      <td>0.000805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7671</th>\n",
              "      <td>go to a picture-perfect beach during sunset</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.999077</td>\n",
              "      <td>0.000923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16903</th>\n",
              "      <td>remarkably faithful one</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.999169</td>\n",
              "      <td>0.000832</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentence  ...  negative probability\n",
              "17964                   the costuming of the stars   ...              0.001254\n",
              "5055                                         lofty   ...              0.001017\n",
              "13665                                  truly funny   ...              0.000805\n",
              "7671   go to a picture-perfect beach during sunset   ...              0.000923\n",
              "16903                      remarkably faithful one   ...              0.000832\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA2b-qLbJb3v"
      },
      "source": [
        "And check the new results in the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "imFdzQGPtlKv",
        "outputId": "647de283-5e09-44bb-9a18-c9499e02a5ce"
      },
      "source": [
        "plot_confusion_matrix(confusion_matrix(preds_thres, y_true), ('positive', 'negative'))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGtCAYAAADtf4sDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVxU5f4H8M8Mq2wCCmoqoiWbbG4IiJqKC6SpmeIGkRZqaF5LDdN+t9SrRmjmUi63XHHJgqhUVNTMBTVXXABXVFAEREAWWef3B825DjPgDBzQsc+717zuned5znOec5jBL892JDKZTAYiIiIiEkifdwOIiIiIXjQMkIiIiIiqYIBEREREVAUDJCIiIqIqGCARERERVcEAiYiIiKgKBkikkcTERLzzzjvo2rUr7O3tsWLFino5T1RUFOzt7XHy5Ml6qf9lZG9vj7CwsOfdjGfStJ3acl3/VCdPnoS9vT2ioqKEtNTU1Hr9/aCOFStWwN7eHqmpqc+tDaTddJ93A0g9RUVF2LFjB/bt24fr16+joKAAjRs3RocOHeDn54c333wTurr1++MsKyvD1KlTUVZWhmnTpsHU1BT29vb1es5/mri4OCQmJmLq1KnPuykNasWKFXB0dISvr+/zbopKqampiI6Ohq+vLxwdHZ93c+hv/9TvCzUMBkha4Pbt2wgJCUFKSgq8vb0REhICCwsLPHz4EPHx8Zg9ezauX7+OWbNm1Ws77t69i7t37yIsLAzjxo2r13MNGTIEb7zxBvT09Or1PC+auLg4REdH1+oXfkJCAqTSF79TWFU7V65ciWHDhr2wAVJaWhpWrlyJli1bMkBSQ8uWLZGQkAAdHZ16PU9N35fJkycjJCQE+vr69doGenkxQHrBPXnyBBMnTkRqaipWrFiB/v37K+SHhIQgISEBFy9erPe2ZGVlAQAaN25c7+fS0dGp91+uL4MnT55AV1cXurq6MDAweN7NUYu2tFPb5Ofnw8TE5Hk3AwAgkUie+89Z/r0gqq0X/8/Nf7idO3fi1q1bePfdd5WCIzlXV1eMHTtWIS0uLg6jRo2Cu7s7OnbsiFGjRiEuLk7p2D59+iAwMBA3btxASEgIOnbsiM6dO+PDDz9EZmamUC4wMFDoNZo9ezbs7e2F8f2a5gsFBgaiT58+Cmlnz57Fe++9h+7du8PFxQU9evTA+++/j/PnzwtlqqszOzsbX3zxBXr16gVnZ2f06tULX3zxBR49eqRQTn58fHw8vv/+e/j6+sLZ2RkDBgxAdHS0yvtY1dNzKyIjIzFgwAC4uLhg8ODBOHToEAAgOTkZEyZMQKdOndCtWzcsWLAApaWlCvUkJCQgLCwMAwYMgJubm/Dz2L9/v9K9krdNfn+fntsRFhYGe3t7ZGdnY/bs2fD29oa7uzvS09OFY56eqxMZGQl7e3usWrVK4TwPHjyAp6cn/Pz8UFhYqNa9eNrs2bPh4uKC4uJiIe3cuXOwt7eHh4cHKioqhPTDhw/D3t4eu3fvFtKebqd8rgoAREdHK1x3VefOncO4cePg7u6Obt26Yc6cOSgoKFAql5SUhNDQUHTr1g0uLi7w9/fHunXrUF5erlBO1Wfz6TbJ589ERUUhKChIuHZ5+wIDA2u8T/I5MDdv3sTSpUvRs2dPODs7480338Thw4eVypeVlWHt2rXw9/eHi4sLunXrhtDQUCQnJ1fbvt27d+Ott96Cq6srFixYoHB/4+PjERAQADc3N/Ts2RNr164FAOTm5uLTTz+Fl5cX3NzcMHHiRDx48EDhHA8ePMDixYsxZMgQdO3aVbiPa9euVbqPqqiagxQYGKjw83369fTPQazvS3VzkFJTUzFz5kx4e3vD2dkZvr6+WLp0KYqKiur086OXD8PrF9zevXsBAAEBAWofExkZiXnz5qFdu3b44IMPAFT+4xMaGop58+Yp1fXgwQMEBQXB19cXs2bNQlJSEnbs2IH8/Hz88MMPAIBJkyahU6dOWL16NQICAtC5c2cAgKWlpUbXc/PmTYwfPx5NmzZFUFAQmjRpgocPH+LMmTNISkqCu7t7tcc+fvwYo0ePxu3btzF8+HA4OTkhMTER27Ztw4kTJ7Bz506lv6C//vprPHnyBAEBAdDX18e2bdsQFhYGGxsb4RqeJTIyEnl5eRgxYgT09fWxefNmTJkyBd988w3mzp2LQYMGwdfXF8eOHcPmzZthaWkp3HcA2L9/P27evImBAweiZcuWyMnJQXR0NKZMmYKIiAgMHjxYuMcVFRU4ffo0wsPDheM7deqk0J53330XTZs2xQcffIDCwkIYGRmpbPfYsWNx4sQJrFq1Ct26dUOXLl1QUVGBGTNmoKCgABs2bKj22Jp069YNUVFROHv2LLy8vAAA8fHxkEqlyM3NxZUrV+Ds7AwAOHHiBCQSCbp166ayLktLS4SHh2PWrFno0qULRo4cqbJcYmIiJk2ahLfeeguDBg3CqVOn8NNPP0EqlWL+/PlCuYsXLyIwMBC6uroYO3YsmjZtikOHDiEiIgJJSUlYsmSJxtfbtWtXTJo0Semz37RpU7WODwsLg66uLsaPH4/S0lJs3LgRoaGhiI2NRatWrYRyM2bMwJ49e9C9e3eMHj0aWVlZiIyMxKhRoxAZGQknJyeFeuPi4rB582aMHj0ao0aNUvjsX7lyBYcOHcLIkSMxZMgQ7NmzB0uWLIGBgQF++eUXtGzZElOmTMGdO3ewefNmfPLJJ9iwYYNwfHJyMvbt24d+/frBxsYGpaWlOHLkCJYsWYLU1FTMmzdP4/s4adIkvP322wppd+/exYoVK9CkSRMhTezvy9PS0tIwYsQIPH78GGPGjEGbNm1w6tQprFmzBmfPnsWGDRuUep3U/fnRS0hGLzQPDw9Zp06d1C6fk5Mjc3d3l/n6+soeP34spD9+/FjWt29fmbu7uyw3N1dI7927t8zOzk62a9cuhXo+//xzmZ2dnezGjRtC2okTJ2R2dnayn3/+WaHszz//LLOzs5OdOHFCqT3jxo2T9e7dW3i/ceNGmZ2dnezChQs1XoeqOpcuXSqzs7OTbdmyRaHsli1bZHZ2drKvv/5a6fghQ4bIiouLhfT09HRZhw4dZNOnT6/x/E9fr4+PjywvL09IT0xMlNnZ2cns7e1le/fuVThm2LBhsu7duyukFRQUKNVdWFgo69+/v8zPz08h/ZNPPpHZ2dmpbI887+OPP1aZb2dnJ/vkk08U0nJycmS9e/eW9erVS5aTkyNbuXKlzM7OTrZ58+bqL/wZ0tPTZXZ2drKlS5cKaYGBgbJJkybJOnbsKFu7dq2QPmzYMNmgQYOe2U5VaU/n2dvby86fP6+Q/v7778ucnJxk+fn5QlpAQIDM0dFRlpiYKKRVVFTIPvzwQ5mdnZ3s+PHjQnrVz6bc3bt3ZXZ2drLly5cLadV99muyfPlymZ2dnSwkJERWUVEhpF+4cEFmZ2cni4iIENKOHj0qs7Ozk02bNk2hbGJioszR0VE2evRopfY5OTnJrl+/rnReVferuLhY1r17d5m9vb1s/vz5CuUXLlyo9F0vKipSaIfcjBkzZA4ODrIHDx4Iaarujap7WFVOTo5swIABMg8PD9nt27eFdLG+L/L7f/fuXSHto48+ktnZ2cn++OMPhbKLFy+W2dnZyX788Uel49X5+dHLiUNsL7j8/HwYGxurXf7YsWMoLCxEYGCgwl+UJiYmCAwMRGFhIY4fP65wjLW1Nfz9/RXSPD09AVROEBeTqakpAODAgQMKQzTq2L9/PywtLZV6wAICAmBpaalyCHHMmDEKkzSbNWuGtm3bIiUlRe3zvvXWW0K7AcDBwQEmJiawtrZWGvbs1KkTMjMzFYZ+nu6lKSoqwqNHj1BUVARPT0/cuHED+fn5arcFACZMmKB22caNGyMiIgKZmZl4//33sWrVKvTp06dOk+ybNWsGW1tbnDhxAgBQXFyM8+fPw8fHBx4eHkJ6Xl4eEhMTq+090oS7uzvc3NwU0jw9PVFWVoa0tDQAwMOHD3Hu3Dn06dMHDg4OQjmJRILJkycDgNIwTUMICgqCRCIR3ru6usLIyEjhuyVv16RJkxTKOjg4oHfv3jhz5gyys7MV6u3VqxdeffVVleeser/09fXh4uICmUymNDTYpUsXAIrfdUNDQ6EdJSUlyMnJQXZ2Nnx8fFBRUYFLly5pdA+qKi0txdSpU5GamopVq1bBxsZGyBP7+yJXUVGBgwcPwsnJCb169VLImzhxIqRSqcrfIer8/OjlxCG2F5yJiYnKeRbVkY+3t2/fXilPnnb37l2F9NatWyuVNTc3BwDk5OSofW51vPHGG/j111+xevVqbNiwAW5ubvDx8cEbb7yBli1b1nhsamoqnJ2dlbrAdXV1YWtriytXrigdU921yf9RVYeqbvTGjRujefPmKtOByvsmD2wfPnyIZcuW4cCBA3j48KHSMXl5eRpNrrW1tVW7LFAZtL333ntYvXo1rKyssHDhQo2OV8XT0xM//fQT8vPzcfHiRRQXF8PT0xOlpaVYtmwZSkpKcOrUKVRUVAjBdl2o8xmVf/Zfe+01pbLt2rWDVCpV+uw3BFVtt7CwUJg3l5qaCqlUqjLgee211xAXF4fU1FSFIe2aPgeqzin/bFb9PJuZmQFQ/K7L50PFxMTg9u3bkMlkCsfk5eVVe251/N///R9OnjyJL7/8UgjQ5MT+vshlZ2ejsLBQ5efD3NwcVlZWKj8f6vz86OXEAOkF1759e/z111+4e/euyi+qGGpaLVb1F6MqT/91VVVZWZnCe319faxfvx4JCQk4cuQITp8+jeXLl2PlypVYsmQJ+vXrp37D1SDGsvfq7o86900mk2H8+PG4ceMGgoKC4OzsDFNTU+jo6ODnn3/G77//rjCpWR2NGjXSqHxJSQmOHj0KoPIfwfv378PCwkKjOqry9PTE9u3bcfr0aZw7dw7W1tZ49dVXUVpaiqKiIly4cAEnTpyAjo4OPDw86nQuoO6fUU2oMwlZE/W19UJNn4Oa7ld1eU/fx8WLF2Pz5s3w9/fHpEmTYGlpCT09PVy+fBkREREaf2aftnr1akRFRWHy5MkYOnSoUhvE/r7UlTZsnUH1gz/5F5x8CGfnzp1qlZcHUdeuXVPKu379ukIZscj/Ms3NzVXKq24XW1dXV4SGhmL9+vXYv38/GjVqhGXLltV4ntatW+PWrVtKQVdZWRlSUlLqLYCsi+TkZCQlJSEkJASzZs2Cv78/evToAW9vb5W/6GsKNmtr6dKluHTpEmbOnAkTExNMnz69VqvXntatWzdIJBLEx8fjxIkTQi+Rvb09LCwsEB8fj5MnT8LR0VHooahv8p4R+ef8aTdv3kRFRYXCZ8Tc3FxlD6mqXoT6+Lk8rXXr1qioqMCNGzeU8uRpDTkhOCYmBl27dsXXX3+NYcOGoVevXvD29q7zNgK7d+/GsmXL4O/vj2nTpinl1+f3xdLSEsbGxio/H7m5ucjMzHwhf4fQ88MA6QU3YsQItG3bFj/88IPK8XEAuHTpEiIjIwEA3bt3h5GREbZs2aIwVp+fn48tW7bAyMgI3bt3F7WN8q7+qnObfv/9d2RkZCikVZ1HAQDNmzeHpaWlygDrab6+vsjOzlYKFn/88UdkZ2e/kJsMyv/6rNrLcfXqVZXzYeTzL8Qa2jx8+DA2bNiAYcOG4b333sOiRYuQkpKisPKrNiwtLWFnZ4c//vgDly5dEgIk+Yq12NhYXLt2Te3hNSMjozpfc5MmTdCxY0ccOnQIV69eFdJlMpmwxP3pHkpbW1sUFBQgISFBSKuoqFBYzfV0+wDVfwSIQf7ZXbt2rcJn5erVqzh48CA6d+6s8YrRupBKpUqf2cLCQpX3Rl3nz59HWFgY3NzcsHjxYpXBTX1+X6RSKXr37o0rV67gzz//VMhbu3YtKioqXsjfIfT8cIjtBdeoUSOsWbMGISEhCA0NhY+PD7y9vWFubo7s7GycPHkSR48exXvvvQegcj7BjBkzMG/ePIwcORLDhg0DULnM//bt25g3b57ChGMxtGvXDt7e3tixYwdkMhkcHR2RmJiIuLg4tGnTRqHH57vvvsOxY8fw+uuvo1WrVpDJZDh06BBu3rwpXEN13nvvPcTGxmLevHm4cuWKcJ6ffvoJbdu2febxz8Orr76K9u3b47///S+ePHmCtm3b4tatW9ixYwfs7Oxw+fJlhfJubm7YsmWLsNeTnp4eXF1da/WXbUZGBsLCwtCmTRt89tlnAIDevXsjKCgImzZtEuZ+yfXp0wdpaWlK++5Ux9PTExs3bhT+/9PpsbGxSuk1cXd3R3x8PNauXYtXXnkFEolEoW3qmjNnDgIDAzF27FiMGTMGVlZWOHToEI4ePYpBgwYJ2xIAwMiRI7F+/XqEhoYiKCgIenp62Lt3r8ohttdeew3GxsbYunUrDA0NYWZmBktLS4X66qJ79+7w8/PDrl27kJubi969eyMzMxNbt26FgYEB5s6dK8p51DVgwADs2LED//rXv+Dt7Y2srCz8/PPPwryv2vjggw9QVlaGgQMHCp8POWNjY/j6+tb79+Wjjz7C8ePHERoaijFjxsDGxganT5/G7t270bVrV+H3JRHAAEkrtGnTBr/88gt27NiBvXv3YvXq1SgsLETjxo3h7OyMxYsXC3uDAJX731hbW+P7778XNgl0cHDAqlWr6u0vpPDwcMyfPx+//fYbfv31V3Tu3BmbNm3C559/rjAh2tfXF5mZmYiNjUVWVhYMDQ3Rpk0bLFiwQGmPlKpMTU2xbds2LF++HAcPHkRUVBSaNGmCUaNGYerUqS/MLsJP09HRwZo1a/Dll18iOjoaRUVFaN++Pb788kskJSUp/cIfNGgQEhMTsWvXLsTGxqKiogKLFi3SOECqqKjArFmzhL2snl4JOXPmTJw+fRr/93//p/CPSUFBAaytrdU+hzxAat26tcIEe3nQoKenpzQBtzr//ve/MW/ePKxevVpYlFCbAMnFxQXbt2/H8uXLsW3bNhQWFqJ169aYMWMGxo8fr1C2devWWLVqFZYuXYpvvvkG5ubmGDJkCIYPHw4/Pz+FsoaGhvj666+xbNkyLFy4ECUlJfDw8BAtQAKAiIgIODk5ITo6GosXL4aRkRG6du2KadOmNfgzD2fPng1jY2PExsbiwIEDaNGiBQICAuDi4oLg4OBa1SmfcL148WKlvJYtW8LX17fevy8tW7bEjz/+iOXLl+PXX3/F48eP0axZM0ycOBGTJ0/mztukQCITe4YjEWmdpKQkDBkyBAsXLsTw4cOfd3OIiJ47zkEiIhw9ehQODg4cYiAi+ht7kIiIiIiqYA8SERERURUMkIiIiIiqYIBEREREVAUDJCIiIi2Wnav+8zpJfZykreXe/PIQ7ucUPe9mEKnl0OcDn3cTiNQiAWBsoD19CH3fXYrUB7Xbjb5VM3McWP+RyC3SftwVS8vdzynC3Yd1e64WUUPhn2OkNer38XuiS83Iw530Wj6uR6I9gWBDYoBERESk7SSSyldtjyUlDJCIiIi0nURS+54gBkgqsV+NiIiIqAr2IBEREWk7DrGJjgESERGRtpNI6zDExsEkVRggERERaTv2IImOYSMRERFRFexBIiIi0nYcYhMdAyQiIiKtV4chNm3bFbOBMEAiIiLSdtwHSXTsVyMiIiKqgj1IRERE2o6r2ETHAImIiEjbcZK26BggERERaTv2IImOYSMRERFRFexBIiIi0nYcYhMdAyQiIiJtx2X+omOAREREpO0kEkDKOUhiYr8aERERURXsQSIiItJ2nIMkOgZIRERE2o7L/EXHAImIiEjbsQdJdLwrRERERFWwB4mIiEjbSVCHITZRW/LSYIBERESk7TjEJjreFSIiIqIq2INERESk7biKTXQMkIiIiLQdh9hExwCJiIhI69WhB4mztFVi2EhERERUBXuQiIiItJ1EUochNvYgqcIAiYiISNtxkrboGCARERFpO07SFh3vChEREVEV7EEiIiLSduxBEh0DJCIiIm3HOUiiY4BERESk7biKTXTsVyMiIiKqgj1IRERE2o5DbKJjgERERKT16jBJm4NJKjFAIiIi0nbsQRIdw0YiIiKiKtiDREREpOUkEgkktewJqu1xLzv2IBEREWk5eYBU25cmMjIyEBERgcDAQHTs2BH29vY4efKkyrIHDhzAsGHD4OLigtdffx0rV65EWVmZUrm8vDx89tln8PT0hLu7O4KCgpCYmNhgdarCAImIiEjbSer40sCtW7ewbt06PHjwAPb29tWWO3z4MEJDQ9G4cWN89tln8PX1xapVq7Bo0SKFchUVFQgJCcGuXbswbtw4zJw5Ew8fPkRgYCDu3LlT73VWh0NsREREpLYOHTrgxIkTsLCwQFxcHEJDQ1WWCw8Ph5OTE77//nvo6OgAAIyNjbF27VoEBgbC1tYWABAbG4tz585h1apV8PX1BQD4+flhwIABWLlyJcLDw+u1zuqwB4mIiEjLNeQQm4mJCSwsLGosc/36dVy/fh0BAQFCIAMAY8aMQUVFBfbt2yek7d27F9bW1ujbt6+QZmlpCT8/P8TFxaG0tLTe6qwJAyQiIiItV7nKv7YBkvjtuXLlCgDA2dlZIb1Zs2Zo3ry5kA8AiYmJ6NChg1Kg5uLigoKCAmFIrD7qrAkDJCIiIi0nRg/S/fv3kZqaqvDKy8urVXsyMzMBAFZWVkp5VlZWyMjIUChrbW2tVE6eJi9bH3XWhHOQiIiICGPHjkVaWppC2pQpUzB16lSN63ry5AkAQF9fXynPwMAARUVFCmVVlZOnyeuqjzprwgCJiIhIy0lQh32Q/l7GFhkZifLycoU8MzOzWtVpaGgIACgpKVHKKy4uFvLlZVWVk6fJy9ZHnTVhgERERKTtarFcX+FYAC1atBCrNcIwmKqhrszMTHTs2FGhrKohL3ma/Pj6qLMmnINEREREonJ0dAQAXLp0SSH9wYMHSE9PF/IBwMHBAZcvX4ZMJlMom5CQACMjI9jY2NRbnTVhgERERKTlGnKZvzrat2+Pdu3aYceOHQrDdtu2bYNUKkX//v2FtIEDByIjIwMHDhwQ0rKzsxEbG4u+fftCT0+v3uqsCYfYiIiItF1dAp1aHPftt98CAG7cuAEAiImJwZkzZ2BmZoZx48YBAGbNmoXJkydjwoQJ8Pf3x9WrVxEZGYmAgAC0bdtWqGvAgAFwd3fHrFmzMH78eFhYWGDbtm2oqKhQmiBeH3VWe1tkVfufSKt0nb0bdx8WPu9mEKnl2vK3nncTiNQikQAmBtozyOI2PQZ3swpqdWzrpsa48PUQjY6p7hEjLVu2xMGDB4X3cXFxWLlyJW7cuAFLS0sMHz4cH3zwAXR1FftncnNzER4ejri4OBQXF8PFxQVhYWHo0KGD0jnqo05VGCBpOQZIpE0YIJG2YIBEHGIjIiLScnWZS1Qfc5BeBgyQiIiItJ0Iy/xJEQMkIiIiLcceJPFpzwArERERUQNhDxIREZGWk6D2PUHsP1KNARIREZGW4xCb+BggERERaTtO0hYd5yARERERVcEeJCIiIi3HITbxMUAiIiLScgyQxMcAiYiISNs18MNq/wk4B4mIiIioCvYgERERaTkOsYmPARIREZG24zJ/0TFAIq3W1NQAM990gq9LC1iZGSIj7wn2nEvDV79eQV5RqVBuUr/26O/6Cl5tbgJzI33kFJbgevpj/PfAdew5f0+hzhmDnTBjsFO15ywtr0DryVEKaa82M8Hc4S7wam8FfV0pEu7k4KtfL+NYcqa4F0wvpYULvsDi/8yrNl9XVxfZj4shk8mwY3skYnfvwrmzZ5B+/x6aNGkKFzc3zJj1Kbp6dFM6NuPBAyxc8Dn27tmNjIwHaNasOQa9ORSffvY5zM3N6/GqqCFJUIceJEZIKjFAIq3V1NQAe2b3QTPzRtj8500k3cuFwyuN8U6vV+HZvineDP8DRSXlAICOtpa4+7AABy7dR3Z+CcyN9DG4Syus/8AbX8Zcxte7EoV6d51Nw62MfKXzObVqjNAB9th34b5CehsrY/z2SW+UV8iwam8yHheVYmyPttj+rx4Ys/wojiRm1O+NIK335pBhaPfqq0rply9exDdfR8DPfxAAoLi4GCHj34GrmzuGjwiAra0t0tPT8cO6NfB9vTvWfL8Bo0aPE47PzMhAn55euH//Ht6dEAKnDh1w5fJlfL9uNY4fO4J9B4/AyMiowa6TSJswQCKt9aGfA1o3NcakdSfxy193hfS/bjzE6ve7YaJveyzbnQQAmLjupNLxaw9cw745fRE6wA7f7E5EhawyPTEtF4lpuUrlu7XvBADYduyWQvqcYc5obKSP/gvicDm18rgfT9zGn5/3x6LRHeHzf3tFuV56eTm7uMLZxVUpfdqxSQCAwODxACp7knbvOwifHr0UygW/+x48OrtgTthMjAwYA6m0cv1NRPgi3LlzG99v2IIRAaOF8t08vTAheBxWLv8as8Lm1NdlUQPiHCTxcRUbaa3u9lYoLClTCI4AIOb0XRSVlGNUd9sajy+vkCE9pwhG+rrQ06n5q2Ckr4OhXVsjLbsQBy+lK6T3d3sFx5MzheAIAAqLyxF5NAWvNTdFR1sLzS+O/vEKCgrw884daNmyFfr1HwigMkCqGhwBgHWzZvDx6YnMjAxkZvyvx/LIn3+gUaNGeHvkKIXyw0cEwNDQEFs2bajXa6CGI5H8L0jS/PW8W/9iYoBEWktfT4ri0gqldJkMeFJaDlsrE1ia6CvkmRvpoYmJPto3N8VHbziid4fmOJacieIy5XqeNrhzK5g10sOO47eFniYAcGzVGIZ6Ojh986HSMWf+TnO3tazF1dE/3S9RO5GXl4cxge9AR0fnmeXT0tKgr6+Pxk/NKyouLoaBoaFSD4FUKoVho0ZIuXUTD7OyRG87PQeSOr5ICYfYSGsl38tD+05m6NCqsULvTYdWjWFhXBkYtbQ0QnZ+iZB3bMFANDExAFA52XrXuTSERZ595rlG+7RFRYUM26sMrzU3bwQASM8pUjpGniYvQ6SJTRvWQyKRIPCdd59Zdm/sbpw5fQqjxoyDoaGhkO7o6IRrV5ORcOE8XD7iZ8QAACAASURBVN3chfSEC+eR8+gRAODu3Tto0rSp+BdApOXYg/S3qKgo2NvbIzU1VdSyVH/WxV1HeYUMayd6oq9zc7S0bIQ+zs2xJsQTJX/3CDXSV/zLe8J38QhYdgT/2vAX/rzyAIZ6OjA21KvxPK82M4Fn+6Y4mpyBOw8LFfLk9Zeo6IF6Uqq6DUTPcu1qMuKPH0Wv1/vA1rZtjWWvX7+GkAnv4JVXWmLh4giFvA+mTINUKsU740Zhb+xu3L1zB/v27kFw4Gjo6VV+7osKC1VVS1qm9sNrddiB+yXHAKkG27ZtQ1RU1LML0nNx8noWJq07ARNDXUR+6IMzi9/AplBvHEvOwP6EypVmj4vKFI45cS0Lh688wPbjtzF2xTHkPynFb5+8jsZG1QdJY3wq/4GKPHpLKU++Sk5fV/mrZKgnVShDpK5NG34AAAT9PTm7Oikpt/CmXz9IJBL8HLMLTa2sFPK9fXpg/aatyM9/jBHDBqODfVsEDB+Cnr1ex0C/NwAApmZm9XMR1KAYIImPQ2x/GzJkCN544w3o6/9vzsr27dthZmaGt95665ll6fn47Uwadp1Ng2PLxjAx1MONB4+R9bgYe2b3QWl5BVIylZfrP+3H+NsY5mED/44tse1YilK+jlSCEZ5t8DC/GHvO3VPKr2kYrabhN6LqlJWVYdvWzbBs0gSDhwyrttzt2ykYNKAv8gvy8dvu/ejg7KKy3LDhI/Dm0Ldw+dJF5D9+jPZ29rCytsbrPp7Q1dVFu1dfq69LIdJqDJD+pqOjo9ZESE3LUv2rkEFhDpKVmQGcbcwRfzXzmb03hnqVP0f5nKWq+ru2gHVjQ6yNu6ZyGC0xLRdPSsvRpV0TpbzOf6edv/1I7Wsh2rPrN2Q8eIDJoR/CwMBAZZnbt1PwRv8+yMvLRcyufXBz71hjnTo6OgpzkB6kpyPhwjn49OjFfZBeElzmL74XdohtxYoVsLe3x61bt/Dhhx+iY8eO8PLyQnh4OEpL/7dDcllZGVauXIm+ffvC2dkZvr6+WLVqFcrLFf9hPHbsGEaPHo0uXbqgY8eOGDBgAJYuXSrkV51X1KdPHyQlJeHUqVOwt7eHvb09AgMDVZYNCQnBgAEDVF6Hv78/goODhfcVFRX4/vvv4efnB2dnZ/j4+GD+/PkoKCgQ5b7900kkwH9GuUNHIsE3f++BZKSvAyMD5YBWKgHe7V25Od+Zm9kq65MPr209pjy8BlQu59+fcB/e9lZwatVYSDcy0MFYH1vcePAY526prptIlU0bax5eu3P7NgYN6Ivc3BxE/xaLjp06a1R/RUUFZn08DeXl5Zjxyew6t5deEHUZXmOApNIL34P04YcfwsbGBjNmzMCZM2fw/fffo7CwEJ9//jkAYO7cuYiOjsYbb7yBzp074/Tp01i+fDnu37+PBQsWAACuXbuGiRMnolOnTpg+fTqkUilu376NM2fOVHveTz/9FP/5z39gaGiISZMqN2trWs1KDz8/P4SFheHKlStwcvrfIyqSk5Nx48YNhQBpzpw5+O233zB8+HC88847uH37NrZs2YLr169jw4YNjOQ1YGSgg9jZfbH7fBruZBXArJEehnVtDTdbSyyMviQ85qOttQmiZ76O38+k4saDx3hUUIIW5o0w1KM12jc3w47jKTh5XXmpc7PGhujdoRnO3spGUlpete34T9RF+DhYY8e/emBN3DXk/72TdnPzRhi34li9XT+9fO7fu4e4fXvRuYuHyiGzx48fY9DAvrh9OwUTJ0/BtWvJuHYtWaFMnz79YN2sGQAgPz8fvXt4YvCbQ9HG1hZ5uXn4aed2nDt7Bv/3xQL07NW7Qa6LGgj/+RDVCx8g2draYsWKFQCAsWPHwsDAANu3b8eECRNQUFCA6OhojBo1Cl988YVQxtTUFDt27MC4cePg4OCAY8eOwcDAAOvXr1d7aMzX1xcrVqyAmZkZhgwZ8syyenp62LNnj0KAtGfPHujq6qJfv34AgNOnTyMqKgrLly9X6HFycXHB9OnTceTIEfTs2VOj+/NPVlpWgcupOXjLwwbWjQ1RVFKO8ynZGLXsCP648kAodz+nCD+duI1urzWFX8eWMDHURV5RKS7dycHXvyci6tRdlfUHeNtCV0eKyCOqe4/kUjIL8OaXhzDnLRdMHWgPPV0pLt7JwWg+ZoQ0FLllI8rLy/HOu6p7j7KzHyIlpfLzuOa7lcB3ymV27T0gBEj6+vpwdnHFzh3bkJ5+H42MjNCpcxdE/bobvv1U93oTUaUXPkAaM2aMwvuxY8ciKioKR48eRV5e5V/1776ruE9IcHAwduzYgT///BMODg4wMzNDUVERjhw5gtdff130NpqamsLHxwexsbH4+OOPhfTY2Fh4eXnBwsJCeG9ubo6uXbsiO/t/wy5dunSBjo4OTp06xQBJA6XlMkz+76lnlsvOL8Gn285rXP/yPUlYvidJrbLX0h8j+NvjGp+D6GkzZs3GjFnVD3u1aWOLvCL1V0Xq6+tj/aatYjSNXnCcgyS+Fz5AsrW1Vfk+LS0NeXl50NXVhY2NjUKZNm3aQFdXF2lpaQAq5wHt3LkTEydOhJWVFby9vdGvXz/4+vqK9sHw9/fHzJkzcfHiRbi4uCApKQm3bt3C+++/L5S5ffs2cnJy4OXlpbKOp4MmIiIidTFAEt8LHyCJwdDQEJGRkTh58iQOHz6MI0eOICYmBt27d8e6detEWZHWp08fGBgYYM+ePXBxccGePXugp6cnDK8BlZMjraysEB4errIOa2vrOreDiIj+eeoy15rxkWovfICUkpKCFi1aKLwHgFdeeQWmpqYoKyvDnTt3FHqa7ty5g7KyMrRs2VJIk0ql8PLygpeXF8LCwrBu3TpERETg1KlT1fboaBJVm5iYoEePHoiNjcWsWbMQGxsLHx8fmD21CZuNjQ1OnjyJLl26cA8lIiKiF9gLu8xfbutWxfHzyMhISCQS9OjRA716VT7VeuPGjQplNm3aBABC/qNHyvvQODo6Aqh8mGN1GjVqJMxzUoe/vz/S0tKwfft2pKSkwM/PTyF/wIABKC0txdq1a5WOLSkpQX5+zZsaEhERqcKdtMWnFT1IoaGh8Pb2xpkzZ7Br1y4EBASgdevWAIBhw4Zh69atyMvLQ6dOnXD27Fn8/vvvePvtt2Fvbw8A+Pbbb3H69Gn07NkTrVq1QnZ2NrZu3YrmzZujc+fq9xDp0KEDtmzZgm+//RZt2rSBpaVltb1NANC7d28YGhoiPDwcBgYG6Nu3r0K+p6cnRowYgRUrVuDSpUvw8vKCVCpFSkoK9uzZg4iICHh7e4tw14iI6J+EQ2zie+EDpOXLl2Pp0qWIiIiAgYEBxo8fj48++kjIX7BgAVq1aoWoqCjs3bsX1tbW+PDDD4W9i4DK+UFpaWmIiorCo0ePYGFhAQ8PD0ydOhWmpqbVnnvy5MlITU3Ff//7XxQUFMDDw6PGAMnIyAi9evXC3r174evrCxMTE6Uy8+fPR4cOHfDjjz9iyZIl0NfXR6tWrTBixAg4ODjU8i4REdE/WWWAVNtJ2iI35iUhkclksufdCFVWrFiBlStX4q+//lKYx0OKus7ejbsP+TRu0g7Xlr/17EJELwCJBDAxeOFnoQj6LD6MtEdPanVsSwtDHAzrJXKLtN8L34NERERENeMQm/gYIBEREWk5iUQCqZT7IImJARIREZGWYw+S+F7YAdapU6ciOTmZ84+IiIiowbEHiYiISMvxUSPiY4BERESk5TjEJj4GSERERFqOPUjie2HnIBERERE9L+xBIiIi0nLsQRIfAyQiIiItxzlI4mOAREREpPVq34MEMEJShXOQiIiIiKpgDxIREZGW4xCb+NiDREREpOXkk7Rr+9JUSkoK/vWvf6Fnz55wd3eHv78/1q5di5KSEoVyZ8+exejRo+Hm5obu3btjwYIFKCoqUqqvpKQEX331FXx8fODq6oqRI0ciPj5e5bnVrbOu2INEREREanvw4AFGjBgBU1NTjBs3Do0bN8bp06exZMkSXLt2DV999RUAIDExEcHBwXjttdcQFhaG9PR0/PDDD0hNTcXq1asV6gwLC8O+ffsQFBSENm3aIDo6Gu+//z42b96Mjh07CuU0qbOuGCARERFpuYYcYouJiUFeXh62bt2K9u3bAwACAgJQXFyM3bt3Y+HChdDT08PSpUthbm6OzZs3w9jYGADQqlUrzJ07F/Hx8fDy8gIAJCQkYNeuXZg9ezaCg4MBAEOHDsWgQYMQERGByMhI4dzq1ikGDrERERFpuYYcYisoKAAANGnSRCG9adOm0NXVhY6ODvLz83H8+HEMHTpUCGQAYMiQITAyMsKePXuEtNjYWOjp6WHEiBFCmoGBAd5++22cOXMGGRkZAKBRnWJggERERKTl5D1ItX0BwP3795GamqrwysvLUzpX165dAQBz5sxBUlIS7t+/j19//VUYFpNKpUhOTkZZWRmcnZ0VjtXX14ejoyMSExOFtMTERLRt21Yh6AEAV1dXyGQyoawmdYqBQ2xERESEsWPHIi0tTSFtypQpmDp1qkKaj48Ppk2bhjVr1uDgwYNC+ocffojQ0FAAQGZmJgDAyspK6TxWVlY4f/688D4zMxPNmjVTWQ6A0IOkSZ1iYIBERESk5Sp7gmr7qJHK/42MjER5eblCnpmZmcpjWrVqBQ8PD/Tr1w/m5ub4448/sGLFClhaWmL06NF48uQJgMrenaoMDAyEfAB48uQJ9PT0VJYDgOLiYqGcunWKgQESERGRlhNjknaLFi3UKr9r1y78+9//RmxsrNDz079/f8hkMoSHh8Pf3x+GhoYAoLTsH6gMeOT5AGBoaIjS0lKV5YD/BUqa1CkGzkEiIiLSenWZoK1ZZLV161Z06NBBaVisT58+KCwsRFJSkjAMJh8We1pmZiasra2F91ZWVsIwWtVyAISymtQpBgZIREREpLasrCyloTgAQi9QeXk57OzsoKuri0uXLimUKSkpQWJiIhwdHYU0BwcH3Lp1S1gdJ3fhwgUhH4BGdYqBARIREZGWE2MVm7ratm2LS5cu4c6dOwrpu3btgo6ODuzt7WFqagovLy/ExMQoBD4xMTEoLCzEwIEDhbSBAweitLQUO3fuFNJKSkoQFRWFTp06CT1VmtQpBs5BIiIi0nK1fWSI/FhNTJgwAX/++SdGjx6NsWPHonHjxvjjjz/w559/YtSoUcL+SNOnT8eoUaMQGBiIESNGID09HevXr0fPnj3h7e0t1Ofm5oaBAwciIiICmZmZsLGxQXR0NO7du4dFixYpnFvdOsUgkclkMlFrpAbVdfZu3H1Y+LybQaSWa8vfet5NIFKLRAKYGGjPIMvba08hPa+4Vsc2NzPATyEeGh2TkJCAFStWIDExETk5OWjZsiWGDx+OCRMmQEdHRyh3+vRpRERE4MqVKzAxMYG/vz8++ugjGBkZKdRXXFyMZcuW4bfffkNubi7s7e3x0UcfqQx61K2zrhggaTkGSKRNGCCRtmCARBxiIyIi0nINOcT2T8EAiYiISMsxQBIfAyQiIiItJ8ZGkaRIewZYiYiIiBoIe5CIiIi0HIfYxMcAiYiI6CXAOEdcDJCIiIi0HHuQxMc5SERERERVsAeJiIhIy3EVm/iqDZBWrlypcWUSiQShoaF1ahARERFpRiqRQFrLSKe2x73sGCARERFpOfYgia/aAOnAgQMN2Q4iIiKiF0a1AVLLli0bsh1ERERUS5U9SLVdxSZyY14StZqkXVJSgkePHsHCwgL6+vpit4mIiIg0IJEAUg6xiUqjZf6XL19GUFAQOnXqhNdffx1nzpwBADx8+BDvvPMOjh8/Xi+NJCIiImpIagdIiYmJGDt2LO7evYshQ4Yo5DVp0gTFxcWIjo4WvYFERERUM/lGkbV9kTK1h9i++eYbWFtbIzo6GsXFxfj5558V8j09PbFnzx7RG0hEREQ1k6AOq9hEbcnLQ+0epDNnzmDEiBEwNjZWGW2+8soryMjIELVxRERE9GySOv5HytQOkIqLi2Fqalptfn5+vigNIiIiInre1B5is7GxweXLl6vNP3HiBF577TVRGkVERETqk9ZhFVttj3vZqd2DNGjQIMTExCisVJMPtf3www84cuSI0uRtIiIiqn+cpC0+tXuQxo8fj2PHjmHChAlo164dJBIJFi1ahOzsbGRlZcHb2xtjxoypz7YSERGRCnzUiPjU7kHS19fH+vXr8cknn8DAwAAGBgZISUmBhYUFZs6ciTVr1kAq1WhbJSIiIqIXkkY7aevq6iI4OBjBwcH11BwiIiLSlEQigbTWjxphF5IqtXrUCBEREb04OMQmPo0CpOLiYmzatAlxcXG4e/cuAKB169bw9fVFYGAgDA0N66WRREREVL26TLZmD5JqagdI2dnZeOedd3Dt2jWYmJigdevWAIAbN27gwoULiImJwaZNm2BpaVlvjSUiIiJqCGoHSOHh4bh+/TrCwsIwZswY6OvrAwBKSkqwdetWfPnllwgPD8fixYvrrbFERESkjENs4lM7QDp06BDefvttpQna+vr6CA4OxrVr1xAXFyd2+4iIiOgZpKj9JG0pHzWiktrr8ktKSuDk5FRtvrOzM0pKSkRpFBEREalPUscXKVM7QHJxccGVK1eqzb98+TJcXV1FaRQRERHR86R2gBQWFoa9e/di8+bNKCsrE9LLysqwceNG7N+/H2FhYfXSSCIiIqpBXR4zwklIKlU7BykoKEgpzdzcHAsXLsTy5cuFVWx3795Ffn4+bGxssHjxYmzcuLH+WktERERK+LBa8VUbIKWmpqpMb9GiBQAgJycHAGBqagpTU1OUlpYKeyMRERFRw6nsCKrtPkgiN+YlUW2AdPDgwYZsBxEREdELg48aISIi0nLcB0l8DJCIiIi0HB81Ij6NAqQ7d+5gw4YNuHDhAvLy8lBRUaGQL5FIuFkkERFRA+MkbfGpvcw/OTkZw4YNw86dO4UJ2UZGRiguLkZaWhp0dHSECdxERERE2kztAGn58uXQ09NDTEwMNmzYAAD49NNPcfToUcybNw95eXn497//XV/tJCIioupwHyTRqR0gnTlzBgEBAWjXrp3SeOXIkSPRs2dPREREiN5AIiIiqhkfNSI+tQOkgoICYXNIPT09AEBhYaGQ36lTJ5w9e1bk5hERERE1PLUnaTdt2hRZWVkAABMTEzRq1AgpKSlCfl5eHsrLy0VvIBEREdVMCgmktRwqk7IPSSW1AyQHBwdcunRJeO/h4YFNmzbB1dUVFRUV2LJlCxwcHOqlkURERFQ97oMkPrWH2AYPHoxHjx7hyZMnAIBp06bh8ePHCAoKQnBwMB4/fozp06fXW0OJiIhItdpO0K7L/kkvO7V7kPz9/eHv7y+8d3Jywq5du7B//37o6OigZ8+ewhwlIiIiIm1Wp520W7RogaCgILHaQkRERLXAITbxqT3ERkRERC8miaRyknZtXrUdYktISEBISAi6du2Kjh074s0330RUVJRCmQMHDmDYsGFwcXHB66+/jpUrV6KsrEyprry8PHz22Wfw9PSEu7s7goKCkJiYqPK86tZZV9X2IM2ePVvjyiQSCRYuXFinBhEREZFmGroH6fDhwwgNDYWHhwemTZsGXV1dpKSk4P79+0plPD098dlnn+Hq1atYtWoVHj16hM8++0woV1FRgZCQEFy9ehXjx4+HhYUFtm7disDAQERFRcHGxkbjOsVQbYAUHR2tcWUMkIiIiF5ujx8/xuzZszFq1CjMnTu32nLh4eFwcnLC999/Dx0dHQCAsbEx1q5di8DAQNja2gIAYmNjce7cOaxatQq+vr4AAD8/PwwYMAArV65EeHi4xnWKodoAKSkpSbSTUP05Ot8fsufdCCI1WXSd8rybQKQWmxaWSN4973k3Q211WY2m6XG//fYb8vLyMG3aNABAfn4+jI2NFeq5fv06rl+/jnnz5gmBDACMGTMGq1evxr59+xASEgIA2Lt3L6ytrdG3b1+hnKWlJfz8/PD777+jtLQUenp6GtUpBs5BIiIi0nLSOr4A4P79+0hNTVV45eXlKZ0rPj4e7dq1w+HDh9GrVy907twZHh4eiIiIEDaMvnLlCgDA2dlZ4dhmzZqhefPmQj4AJCYmokOHDkqBmouLCwoKCnDnzh2N6xRDnVaxERER0fMnRg/S2LFjkZaWppA3ZcoUTJ06VSHt9u3bSE9PR1hYGN577z04OTnh0KFDWLduHYqLizFnzhxkZmYCAKysrJTOZ2VlhYyMDOF9ZmYmPD09lcpZW1sDADIyMvDqq69qVKcYGCARERERIiMjlR4ZZmZmplSusLAQubm5+Pjjj4Uhrf79+6OwsBDbtm3D5MmThU2l9fX1lY43MDBAUVGR8P7Jkycqy8nT5HVpUqcYGCARERFpOSkAaS1XscmH2Fq0aKFWeUNDQwDAoEGDFNIHDx6M2NhYXLx4UShTUlKidHxxcbGQL69PVTl5mrysJnWKgXOQiIiItJxEUhkg1eal6cicfIiradOmCuny97m5uUIZ+bDY0zIzM4XhM3l9qobH5GnysprUKQYGSERERFquch+k2j6LTbNzdejQAQDw4MEDhfT09HQAlSvQHB0dAUDhIffyY9LT04V8AHBwcMDly5chkymuyU5ISICRkZGwD5ImdYqBARIRERGpbeDAgQCAn376SUiTyWTYuXMnjIyM4O7ujvbt26Ndu3bYsWOHwrymbdu2QSqVon///gr1ZWRk4MCBA0JadnY2YmNj0bdvX+jp6QGARnWKQeM5SKmpqYiPj0dWVhYGDx6MVq1aoaSkBFlZWWjatKnKyVNERERUf+TDZbU9VhPOzs4YOnQo1qxZg4cPH8LJyQmHDx/G0aNHMXPmTJiYmAAAZs2ahcmTJ2PChAnw9/fH1atXERkZiYCAALRt21aob8CAAXB3d8esWbOEnbS3bduGiooKpRV06tYpBomsap9WDb766its2LAB5eXlkEgk+OGHH+Dl5YX8/Hz06NED06ZNQ3BwsKgNpJoVl4EbRZLW4EaRpC20baPIRQdv4FFR7Z5HZtFIF7P7vKrRMSUlJfj222/xyy+/ICsrC61atUJwcDBGjRqlUC4uLg4rV67EjRs3YGlpieHDh+ODDz6Arq5i/0xubi7Cw8MRFxeH4uJiuLi4ICwsTBjOq02ddaV2gLR9+3Z8/vnnCAwMRO/evTF+/HisX78eXl5eAICPP/4YWVlZ2Lhxo6gNpJoxQCJtwgCJtIW2BUhfHrpZpwDpk97tRG6R9lM73Nq6dSv69euHOXPm4NGjR0r59vb2+Ouvv0RtHBEREdHzoPYk7ZSUFHh7e1ebb2FhoTJwIiIiovolQe0fM1LLqUsvPbV7kJ61S+W9e/dU7rhJRERE9UtSi/2Mnj6WlKndg+Tq6or9+/erzCsuLkZMTAw6deokWsOIiIhIPVKJpE4vUqZ2gDRhwgScP38eM2fORHJyMgAgKysLR44cQWBgIB48eIDx48fXW0OJiIiIGoraQ2ze3t74/PPP8Z///Ae///47gMr9CABAT08P8+fPR8eOHeunlURERFQtCeowxCZqS14eGm0aEBAQgD59+iA2NhY3b96ETCaDra0t/Pz80KxZs/pqIxEREdWgITeK/KfQeFclKysrBAYG1kdbiIiIiF4I4m47SURERA1OUofJ1hJO0lZJ7QApKCjomWUkEgl30iYiImpgXOYvPrUDpNTUVKW08vJyZGZmoqKiAhYWFmjUqJGojSMiIqJn4xwk8akdIB08eFBleklJCdavX4+oqChs3rxZtIYRERERPS9q74NUHX19fUycOBGurq5YvHixGG0iIiIiDUjq+B8pq3OAJNe5c2ccPXpUrOqIiIhITfIhttq+SJloq9hSU1NRWloqVnVERESkJkkdAh1O0lZN7QDp3r17KtNzc3Nx/PhxbN68GR4eHqI1jIiIiOh5UTtA6tOnT7V7JchkMrRt2xZz584VrWFERESkHolEUuv9jLgPkmpqB0ihoaEqb6K5uTlsbW3h7e0NqVS0KU1ERESkJinqsMxf1Ja8PNQOkKZOnVqf7SAiIqJa4kaR4lMrcCwoKICvry82bNhQz80hIiIiev7U6kEyNjZGTk4OjI2N67s9REREpCFpHZ7FVtvjXnZqDz26ubnh4sWL9dkWIiIiqgVJHfZAYnykmtoB0owZMxAbG4uff/4ZMpmsPttEREREGpDPQarti5TVOMR27949WFpawtDQEIsWLYKZmRnmzp2Lr776CjY2NjA0NFQoL5FIsHHjxnptMBEREVF9qzFA6tu3L7766isMGjQIqampAIAWLVoAALKysuq/dURERPRMUkggreUz1Wp73MuuxgBJJpMJw2kHDx5skAYRERGRZrjMX3yiPYuNiIiIno+6PHSWD6tVjRtoEhEREVXxzB6k06dPo7y8XO0Khw4dWqcGERERkWYql/nX9llsIjfmJfHMAOnHH3/Ejz/++MyKZDIZJBIJAyQiIqIGJkEd5iCJ2pKXxzMDpJEjR8Ld3b0h2kJERES1wJ20xffMAKlLly4YPHhwQ7SFiIiI6IXAVWxERERajsv8xccAiYiISMtJUftl6VzOrhrvCxEREVEVNfYgJSUlNVQ7iIiIqLYkEkg4xiYqDrERERFpOQlqv1yf4ZFqDJCIiIi0HJf5i49zkIiIiIiqYA8SERGRluMQm/gYIBEREWk57oMkPgZIREREWk5Sh1VstV799pLjHCQiIiKiKtiDREREpOUkqH2PB/uPVGOAREREpOU4xCY+BkhERERajqvYxMc5SERERERVMEAiIiLSchJIhGE2jV917ENat24d7O3tMWTIEKW8s2fPYvTo0XBzc0P37t2xYMECFBUVKZUrKSnBV199BR8fH7i6umLkyJGIj49XeT5166wrBkhERERaTlrHV21l6jiP8wAAIABJREFUZmbiu+++g5GRkVJeYmIigoODUVxcjLCwMLz99tvYsWMHpk+frlQ2LCwMGzduxJtvvok5c+ZAKpXi/fffx7lz52pdZ11xDhIREZGWe16TtJcsWQJnZ2fIZDLk5eUp5C1duhTm5ubYvHkzjI2NAQCtWrXC3LlzER8fDy8vLwBAQkICdu3ahdmzZyM4OBgAMHToUAwaNAgRERGIjIzUuE4xsAeJiIiINJaQkIBff/0Vs2fPVsrLz8/H8ePHMXToUCGQAYAhQ4bAyMgIe/bsEdJiY2Ohp6eHESNGCGkGBgZ4++23cebMGWRkZGhcpxgYIBEREWk5SR1fmpLJZJg/fz6GDh0KR0dHpfzk5GSUlZXB2dlZIV1fXx+Ojo5ITEwU0hITE9G2bVuFoAcAXF1dIZPJhLKa1CkGDrERERFpuzo8i00eId2/fx/l5eUKWWZmZjAzM1M65JdffsH169exatUqlVVmZmYCAKysrJTyrKyscP78eYWyzZo1U1kOgNCDpEmdYmCAREREpOUqJ1vXLkKSDyWNHTsWaWlpCnlTpkzB1KlTFdLy8/OxZMkShISEwNraWmWdT548AVDZu1OVgYGBkC8vq6enp7IcABQXF2tcpxgYIBEREREiIyNV9iBV9d1330FPTw/vvvtutXUZGhoCqFy+X1VxcbGQLy9bWlqqshzwv0BJkzrFwACJiIhIy0nqMMQmP65FixbPLJuRkYGNGzdi2rRpyMrKEtKLi4tRWlqK1NRUmJqaCsNg8mGxp2VmZir0PFlZWQnDaFXLARDKalKnGDhJm4iISMtJ6vifuh4+fIjS0lJERESgb9++wuvChQu4ceMG+vbti3Xr1sHOzg66urq4dOmSwvElJSVITExUmNjt4OCAW7duoaCgQKHshQsXhHwAGtUpBvYgERERaTkxepDU0apVK5UTs5ctW4bCwkJ8+umnsLW1hampKby8vBATE4OJEycKK9RiYmJQWFiIgQMHCscOHDgQP/zwA3bu3Cnsg1RSUoKoqCh06tRJmMCtSZ1iYIBEREREajE1NYWvr69S+saNG6Gjo6OQN336dIwaNQqBgYEYMWIE0tPTsX79evTs2RPe3t5COTc3NwwcOBARERHIzMyEjY0NoqOjce/ePSxatEjhPOrWKQYOsREREWk5KSR1etWHDh06YP369dDX18eiRYuwc+dOjBw5Et98841S2fDwcAQGBiImJgYLFixAWVkZ1q5di86dO9e6zrqSyGQymei1UoMpLgP4AyRtYdF1yvNuApFabFpYInn3vOfdDLUdvvYQT0oranWsoZ4Uvdo3EblF2o89SERERERVcA4SERGRlmuoSdr/JAyQ6B+hsLAQnd2dkXLrFiZODsWy5SsBVD5PaPvWSOze/TvO/n979x6X4/3/AfzVQTqQ6ltOpeRw3yKlAxaFUuswkRxyKMzhO+Z8rpl9bfNjLMeyzWLOzdbUl3Br4vsdNmMMs5UsKhWm6DBJuev6/dG3e67uG5Ub3e319OjxcH+u9/W5PtfdTe8+n/d1XefP4dbNm/iHuTkcHXtgUfgS9OrdW6mvj1etxIULP+PCz+eRmZEBaxsbpKVnvuQzIk2wYOLrcOpiBSc7a9hamSPr5l10eeNfKmO9endBkHcPONu1Q7dObaHftAlen7wBJ8//rhSbFDMb/Vw7P/G4x368gkHTokVtvu5dET7ZD90lligrl+O/Z9Pwzvr9yLp5VxS35K0AvDs1QGW/EWsTsH7XsWedNr0Cdb1cv+a+pIwJEv0tfLDsPeSruLlYWVkZJk4Ig6NjD4wYOQrt29vi9u1biPn8MwzwcMPWbTsxemyoaJ/33n0HZmZm6OHkjKLCwpd1CqSBPpw5GHcLS3DxSjZaNDd4auyoAFeE+Lvit/RbuJJxGz26tHti7KotSdiW8INS+/DXnfFG/+44fOKyqH2IlyNiP56EX67m4p11/4ZxcwPMGDMA/9k+D33HrsatvCKlvhZ+/A3yC8X3pbmQeuOp50CvjrZW1Vd99yVlTJCo0bvw88+I3rge/7dyNcIXzRdt09XVxbfH/guPfv1F7W9OmgIXx24IXzQfIaPHQFv7r3K9lLRrsO3QAQDg0sMe9+/ff/EnQRrJbtC/kJlbNUNzLu4dNDNs+sTYZdGJmLF8L8ofyTEnbOBTE6TjZ66obA+f7IuHZY/w5aGfFG26utpYu3gEcv4ohPfEdSgprXpMw7enfsMPsYux5K0AzFj+pVJfB/7zC27culer8yRqjFikTY1aRUUFpk+dgtd9/RA0NFhpu66urlJyBACtWrWCe7/+uHPnjtIt8KuTI6JnqU6OauNmXhHKH8nrfay+Th0htW2NA/+5hILiB4p2D5fOaNvSBNsSflAkRwDwy9VcnDj3O4a/7gxdXdU/Cpob6UNHhz8mNMHLupP23wlnkKhR27hhHdLSruDLr/fVed/cnBzo6enBxMTkBYyMSL3GB7kBgNLSm0s3GwDAmV8ylPY5ezkTnr2l6GzdEqnXb4u2/fR1BIybGUAur8C537KwMuYIvv0+5QWNnp6XFp6jSFutI2k8+KsBNVqZGRlY/v6/EPHue7Bp375O+x6RHca5n85i+IgQtT8hmkjdmhvpI9jHCRk5+fjv2auibW0tWgAAbt5Rrperbmvb8q9fAor+fIAt35zCvNXfYPiczXgv6gCs25ghYeNUhAYqX7RADQNnkNSPM0j1FBYWBgDYtWvXKx4JPcnM6VNha9sBs+fMq9N+6b//jkkTwtDW0hIffbzmBY2OSH1G+rnAyKApduz/VmmbgX4TAEBZufLy3cPyRwAAQ309RVt07H9FMYcA7Nj/I87FvYPVC4YhIfmCaKmOqLHiDNJT5OXlISoqCqmpqa96KFRHX+7ZjWPJR7Eh+lM0adKk1vtlZmTA33cgtLS0sD9RBgsLixc4SiL1mBDkBrm8Arv2/6i0rfRhVRLUVE/592F9vap/Gw8ePj3huVdUgi3fnIKpsSFec2QNXkOkpfXXlWx1/eJ9kFTjDNJT5OfnIzo6GpaWlrCzsxNt27p16ysaFT1LWVkZFi+cBz//ALRu3RrX0tMBADdv5gIAiouKcC09Hf8wNxfVF2VlZsLXxxMl9+/jcNIx2Hfv/krGT1QX3Tq1hat9exw+8Stuqrhcv7qtbUsTpGX8IdpWvbSmavmtpqz/XdFmbtLseYdMLwDvg6R+nEGqJz09Pejp6T07kF660tJS5OXlQXb4EOztOiu+Xh84AADwZexu2Nt1xrYvtij2ycrMxOveA1BcVISDsqPo4eT0ikZPVDdvDq0qzt6u4r5IAHD+tywAQG8HW6Vtvbq3R9Gfpfj9xh2lbTV1alc1m/rHveL6DpVeoOo7adf3i5S90gQpKioKUqkU2dnZWLRoEVxcXODi4oKIiAiUlpaKYvft24ehQ4fCwcEBvXv3xuLFi5Gfny+KqaysRFRUFNzd3eHo6IiwsDCkp6fDy8sL4eHhirjCwkKsWrUKgYGBcHJygrOzMyZPnowrV/66t8iZM2cQFBQEAIiIiIBUKoVUKkV8fDyAqhqk6jqk/Px82NnZ4dNPP1U6x0uXLkEqlWL//v2Ktlu3bmHRokVwc3ODvb09AgMDcfDgwed8N6makZER9uyNU/raEPUJAOB1Xz/s2RuHQYMGAwCysrLg6+OJosJCJB7+Fs41nh5N1FDpNdHFqIBeuJ1fjMMnf1UZc/L877iVV4Q3h/aBkcFfv9R1l1iin2tnxCdfgFxe9ZBTHR1tGDdTvijBqpUJpozwQH7Bffx4SflqOKLGqEEssc2aNQvt2rXD/PnzkZKSgri4OJiZmWHhwoUAgOjoaGzatAlvvPEGRo4ciby8POzcuROXL19GfHy84iqjNWvWYMuWLfDy8oK7uzuuXLmCSZMmoaysTHS87OxsJCcnw8/PD1ZWVsjPz8dXX32F0NBQHDp0CK1atULHjh0xd+5crFu3DiEhIXD53w9NZ2dnpfGbm5vD1dUVMpkM06ZNE22TyWRo2rQpBg4cCAC4c+cORo4ciSZNmmDcuHFo0aIFjh07hvnz56O8vBzBwcr36qG6adKkCYKHDVdqz8rMBADYduio2P7nn3/Cz8cTWZmZmDZ9Jn6/mobfr6aJ9vPy9kGrVq0Ur2N378KNG1W/lefn5aG8vBwfrVgOALC2tsGY0LAXcVqkgUa/0RPWbcwAAOamzaDXRBeLJ/sCAG7cuie6oaN957Z4o3/Vsq5bj6o6nzGDeqKPU9XfP937HYrvPxT1P9jTAf8wMcKabUdRUaH6Se5yeSUWrP4Gu1a9ieQv5mJb/A8wbqaPGWM9kVdwH8s/PaSIbWbQFKmH3kfif35BWsZtFBQ/gKR9K0wY6oZmBk0xPmI7HpY9UtO7Q+qkhfpfrs8JJNUaRILUvXt3fPDBB4rXhYWF+Oabb7Bw4ULk5OTgk08+wcKFCzFx4kRFTL9+/TBq1CgkJCRg9OjRyM/Px/bt2+Hr64uNGzcq4qKjoxEVFSU6nlQqRVJSkujuyEOGDIG/vz+++eYbTJ8+Hebm5ujfvz/WrVuHHj16YMiQIU89h4CAACxbtgzXr19Hh//dSFAQBCQlJaFfv35o1qxq3X79+vXQ1tbGv//9bxgbGwMAxowZg8mTJ2Pt2rUICgoSjYterHt37yIzo+o34k83RUF5DhBISv6PKEHavm0rTp74ThTz/r+WAgA8+vVngkQKE4L6KD0zbdn0QADAiXO/ixKkHl3aKbY9vn+1Lw/9pJQgVd/7aPu/Tz91HPHJF1A65xHCJ/ti5dyhKHtU9Sy2JRv2i+qWSsse4d/HLqKnfXsEejqgmUFT5Bfex3/OpGHt9mSc+99yHTU82lpa0K7nWll992vsGkSCNGrUKNFrV1dXHD16FPfv30dycjIEQYCPjw/u3fvrtvfW1tawsLDA2bNnMXr0aJw+fRpyuRxjxowR9RUaGqqUID1eO1RRUYHi4mIYGhrC1tYWKSn1uxGar68vPvzwQ8hkMkyfPh0AcPHiRdy8eVMxEyYIAo4ePYpBgwZBLpeLzsfDwwMnT55ERkYGOnbsWK8x0NPZtG+P0kfCM9ue5dtj/1XjqKgx852yodaxuxPPYHfimTr1H/j2plrHyk7+CtkTluGqlT+S4+0PYus0BmoYOIOkfg0iQWrTpo3odfXMSlFRETIzM1FZWQlvb2+V+1YnGTdv3gQA2NjYiLabmJigRYsWorbKykrs3LkTsbGxyMnJQUVFhSi+PszMzNC7d29RgiSTyWBgYIABAwYoxlpcXIzY2FjExqr+T6igoKBexyciIiL1aRAJko6Ojsp2QRBQWVkJHR0dxMTEQEvFNGB1MlUXn332GTZs2IBhw4Zh9uzZaNGiBbS1tbFixQoIQt1mEx7n7++PpUuXIj09HR07dkRSUhL69+8PQ0NDAFWJGQAEBwcjMDBQZR+dO3dW2U5ERPREnEJSuwaRID2NtbU1KioqYGNjAysrqyfGtW3bFkDVFUmPz0gVFBSgqEh8b5CkpCT07t0bK1asELUXFxfD1NRU8VpVQvY0Pj4+eP/99yGTydC3b1/cvn0bAQEBiu1mZmYwMjKCIAjo06fPU3oiIiKqG97PSL0afDWwj48PtLW1sWmT8lp7ZWUlCgurbnDm5uYGXV1dpaWrPXv2KO2no6OjNFMkk8nwxx/im6gZGBgAqEqcasPU1BSvvfYaZDIZZDIZDA0N0b//X0+K19HRgY+PDw4fPozr168r7f94TRIREVFt8T5I6tfgZ5BsbGwwa9YsrF+/HtnZ2fD09ISBgQGys7ORlJSEadOmYcSIETA3N8e4cePwxRdf4O2330bfvn2RlpaGEydOwNTUVDQbNGDAAGzatAkRERFwcnLC1atXkZiYiHbt2omObWlpCRMTE+zduxdGRkYwNDSEg4ODUtzj/P39sWTJEty+fRteXl5KDzqdP38+zpw5g2HDhiEkJAQdOnRAQUEBLl++jJSUFBw/fly9byARERHVWYNPkABg2rRpsLGxwc6dOxEVFQUtLS20bdsW3t7eoqWqBQsWQF9fH3Fxcfj+++/Ro0cPbN26FWPGjBFduTZ16lSUlpYiMTERhw8fRteuXbF582asWSN+MKmuri5WrVqFyMhILFu2DHK5HCtXrnxqguTj44Nly5ahpKQE/v7+SttbtmyJuLg4REdHQyaT4e7duzAxMYFUKsXs2bPV8G4REdHfDUuQ1E9LeJ6qZA1QXFyMnj17Ys6cOUo3cWwMyuRAo/4GUqNi2nPGqx4CUa1YtzFD2uEPnh3YQFzKLka5vH4/DfR0teDYru4XPDV2GjGDVFsPHz5UWtLasWMHAKBXr16vYkhEREQvXP0fVcvi7idpVAlSYmIiDhw4gP79+8PAwADnz5/HoUOH4O7urnhUCBEREdGzNKoEqUuXLjh48CBiYmJQUlICc3NzjB8/HnPmzHnVQyMiInphnudqNF7FplqjSpC6d++uWFIjIiL6u2CRtvo1+PsgEREREb1sjWoGiYiI6G+LU0FqxQSJiIhIw/EqNvVjgkRERKThWKStfqxBIiIiIqqBM0hERESNACeC1IsJEhERkabjdf5qxwSJiIhIw7FIW/1Yg0RERERUA2eQiIiINByvYlM/JkhEREQajiVI6scEiYiISNMxQ1I71iARERER1cAZJCIiIg3Hq9jUjwkSERGRhmORtvoxQSIiItJwLEFSP9YgEREREdXAGSQiIiJNxykktWOCREREpOFYpK1+TJCIiIg03XMUaTM/Uo01SERERFRrv/zyC95//30EBASgR48eGDBgAObOnYusrCyl2J9//hmjR4+Go6Mj+vbti+XLl6O0tFQprry8HB9//DHc3d3h4OCAkSNH4vTp0yqPX9s+nxcTJCIiIg2n9ZxfdbFlyxYcPXoUffr0wZIlSzBy5EicPXsWQUFBuHbtmiIuNTUVEyZMQFlZGcLDwzF8+HB89dVXmDt3rlKf4eHh2LFjBwYPHowlS5ZAW1sbU6ZMwYULF0RxdenzeXGJjYiIqDF4SUtlEyZMQGRkJPT09BRtAQEBCAwMRExMDD766CMAwNq1a2FiYoJdu3bByMgIAGBlZYV3330Xp0+fhpubG4CqGalDhw4hIiICEyZMAAAEBQVh0KBBiIyMxJ49exTHqW2f6sAZJCIiIg2n9Zx/6sLZ2VmUHAFA+/bt0blzZ8UM0v379/HDDz8gKChIkcgAwJAhQ2BoaAiZTKZoO3LkCJo0aYIRI0Yo2po2bYrhw4fj/PnzuHPnTp37VAcmSERERPRcBEFAfn4+TE1NAQBpaWmQy+Wwt7cXxenp6cHOzg6pqamKttTUVNja2oqSHgBwcHCAIAiK2Lr0qQ5cYiMiItJw6njUyK1bt1BRUSHaZmxsDGNj42f2ceDAAfzxxx+KWqC8vDwAgIWFhVKshYUFLl68qHidl5eHVq1aqYwDoJhBqkuf6sAEiYiISMOp4z6RY8eORW5urmjbjBkzMHPmzKfuf+3aNXzwwQdwcXHBkCFDAAAPHz4EAKWlOKBq+ax6e3VskyZNVMYBQFlZWZ37VAcmSERERIQ9e/aonEF6mry8PLz11lto0aIFNmzYAG3tqsodfX19AFWX79dUVlam2F4d++jRI5VxwF+JUl36VAcmSERERJpODVNIbdq0qdNuf/75J6ZMmYI///wTX375pWjpq/rv1ctij8vLy0PLli1FsdXLaDXjAChi69KnOrBIm4iISMO9zKvYgKoZm6lTpyIzMxObN29Ghw4dRNslEgl0dXXx66+/itrLy8uRmpoKOzs7RVuXLl2QkZGBkpISUeylS5cU2+vapzowQSIiItJw1UXa9f2qi4qKCsyZMwcXL17Ehg0b0KNHD6WY5s2bw83NDfv37xclPvv378eDBw/g5+enaPPz88OjR48QFxenaCsvL0d8fDycnZ0VBdx16VMduMRGREREtfbRRx/h+PHj8PT0RGFhIfbv36/YZmRkBG9vbwDA3LlzMWrUKISFhWHEiBG4ffs2tm3bhn79+qFPnz6KfRwdHeHn54fIyEjk5eXB2toaCQkJuHnzJlauXCk6dm37VActQRAEtfZIL1WZHOA3kDSFac8Zr3oIRLVi3cYMaYc/eNXDqLWce2WQV9bvp4GuthaszJrWOj4sLAxnz55Vuc3S0hLHjx9XvD537hwiIyORkpKCZs2aISAgAPPmzYOhoaFov7KyMqxfvx6JiYkoKiqCVCrFvHnzVCY9te3zeTFB0nBMkEiTMEEiTaFxCVLBcyZIprVPkP4uuMRGRETUCNSn2JqejEXaRERERDVwBomIiEjDqeNRIyTGBImIiEjDqeNRIyTGBImIiEjDcQZJ/ViDRERERFQDZ5CIiIg0HqeB1I0JEhERkYbjEpv6MUEiIiLScCzSVj/WIBERERHVwBkkIiIiDaeF51hiU+tIGg8mSERERBpO6zkeNMIESTUmSERERJruebIcZkgqsQaJiIiIqAbOIBERETUCnAhSLyZIREREGk5L6zku82dmpRITJCIiIg3HIm31Yw0SERERUQ2cQSIiItJ0vIpN7ZggERERaTg+akT9uMRGREREVANnkIiIiDQcr2JTPyZIREREGo5XsakfEyQiIiINxxkk9WMNEhEREVENTJCIiIiIauASGxERkYbjEpv6MUEiIiLSePUv0ibVuMRGREREVANnkIiIiDTc8yyTcYlNNSZIREREGo6PYlM/JkhERESNATMdtWINEhEREVENnEEiIiLScM9zDRsnnlRjgkRERKThnqtIW33DaFSYIBEREWk4FmmrH2uQiIiIiGrgDBIREZGm4zSQ2jFBIiIi0nAs0lY/JkiNAD/cpCms25i96iEQ1YplS5NXPYQ6eZ6H1ZJqWoIgCK96EEREREQNCYu0iYiIiGpggkRERERUAxMkIiIiohqYIBERERHVwASJiIiIqAYmSEREREQ1MEEiIiIiqoEJEhEREVENTJCIiIiIamCCRAQgPj4eUqkUOTk5ao0laojCwsIQFhb2qodB1KAxQSJ6gi+//BLx8fGvehhE9ZKXl4eoqCikpqa+6qEQaSQ+i40IQEVFBeRyOfT09KClVfXIxyFDhsDY2Bi7du16ZixRQ5OamoqgoCCsXLkSwcHBom3l5eUAAD09vVcxNCKNoPuqB0DUEOjo6EBHR0ftsUQNERMjomfjEhs1SFFRUZBKpcjIyMCsWbPg5OQENzc3rF69Go8ePVLEyeVyREdHY+DAgbC3t4e3tzc2bdqEiooKUX/ff/89Ro8eDVdXVzg5OcHX1xdr165VbK9ZV+Tl5YUrV67g7NmzkEqlkEqlipqNmrH//Oc/4evrq/I8AgICMGHCBMXryspKbN26Ff7+/rC3t4e7uzs+/PBDlJSUqOV9o5en+jOanZ2NRYsWwcXFBS4uLoiIiEBpaakodt++fRg6dCgcHBzQu3dvLF68GPn5+aKYyspKREVFwd3dHY6OjggLC0N6ejq8vLwQHh6uiCssLMSqVasQGBgIJycnODs7Y/Lkybhy5Yoi5syZMwgKCgIAREREKD7D1UvGj9cg5efnw87ODp9++qnSOV66dAlSqRT79+9XtN26dQuLFi2Cm5sb7O3tERgYiIMHDz7nu0nU8HAGiRq0WbNmwdraGgsWLMD58+exdetWPHjwAMuWLQMAvPvuu0hISMAbb7wBFxcXnDt3Dhs3bsStW7ewfPlyAMDvv/+Ot956C87Ozpg7dy60tbWRlZWF8+fPP/G477zzDv7v//4P+vr6mDp1KgDA3NxcZay/vz/Cw8ORkpKCrl27KtrT0tJw7do1UYK0ZMkSJCYmYtiwYRg/fjyysrKwe/dupKenY/v27Vyy00CzZs1Cu3btMH/+fKSkpCAuLg5mZmZYuHAhACA6OhqbNm3CG2+8gZEjRyIvLw87d+7E5cuXER8fD319fQDAmjVrsGXLFnh5ecHd3R1XrlzBpEmTUFZWJjpednY2kpOT4efnBysrK+Tn5+Orr75CaGgoDh06hFatWqFjx46YO3cu1q1bh5CQELi4uAAAnJ2dlcZvbm4OV1dXyGQyTJs2TbRNJpOhadOmGDhwIADgzp07GDlyJJo0aYJx48ahRYsWOHbsGObPn4/y8nKlpTwijSYQNUAbN24UJBKJMGPGDFF7eHi4IJVKhRs3bgipqamCRCIR3nvvPVHM0qVLBYlEIqSmpgqCIAjbtm0TnJ2dBblc/sTj7du3T5BIJEJ2draibfDgwUJoaOgzY4uLi4Vu3boJkZGRorh169YJXbt2Fe7duycIgiD89NNPgkQiEY4cOSKKO3TokCCRSITvvvvuWW8LNSDVn9GlS5eK2qdPny706tVLEARByM7OFuzs7IStW7eKYi5cuCBIpVIhNjZWEARByMvLE7p27SrMnDlTFBcVFSVIJBJh8eLFiraysjKhoqJCFJednS3Y29sL0dHRiraUlBRBIpEI+/btUxp7aGio6LMdGxsrSCQS4dq1a4q2yspKYcCAAcL06dMVbREREUK/fv2EoqIiUX+TJk0S+vbtqzQuIk3GJTZq0MaMGSN6PXbsWAiCgFOnTuG7774DALz55puimOoZmxMnTgAAjI2NUVpaipMnT76QMTZv3hzu7u44cuSIqP3IkSNwc3ODqamp4rWJiQl69uyJe/fuKb5cXV2ho6ODs2fPvpDx0Ys1atQo0WtXV1cUFhbi/v37SE5OhiAI8PHxEX3Pra2tYWFhofienz59GnK5XOnzHhoaqnQ8PT09aGtX/dddUVGBgoICGBoawtbWFikpKfU6B19fX+jo6EAmkynaLl68iJs3byIgIAAAIAgCjh49Ci8vL8jlctH5eHh4IC8vDxkZGfU6PlFDxCU2atDat2+v8nVubi6Ki4uhq6sLa2trUYyNjQ10dXWRm5sLoKoOKC4uDm+99RbmQvEcAAAPOklEQVQsLCzQp08f+Pj4wNvbW21LWgEBAVi4cCEuX76M7t2748qVK8jIyMCUKVMUMVlZWSgsLISbm5vKPu7du6eWsdDL1aZNG9FrY2NjAEBRUREyMzNRWVkJb29vlftWf89v3rwJoOqz+zgTExO0aNFC1FZZWYmdO3ciNjYWOTk5ono7ExOTep2DmZkZevfuDZlMhunTpwOoWl4zMDDAgAEDFGMtLi5GbGwsYmNjVfZTUFBQr+MTNURMkKjR09fXx549e3DmzBl89913OHnyJPbv34++ffsiJiZGLVekeXl5oWnTppDJZOjevTtkMhmaNGkCHx8fRUxlZSUsLCywevVqlX20bNnyucdBL9+TPj+CIKCyshI6OjqIiYlRmYxXJ1N18dlnn2HDhg0YNmwYZs+ejRYtWkBbWxsrVqyA8Bx3bfH398fSpUuRnp6Ojh07IikpCf3794ehoSGAqs8vAAQHByMwMFBlH507d6738YkaGiZI1KBlZmaKfkPPzMwEALRt2xbNmzeHXC7HjRs3RDNNN27cgFwuh6WlpaJNW1sbbm5ucHNzQ3h4OGJiYhAZGYmzZ88+cUanLrNLzZo1g4eHB44cOYJFixbhyJEjcHd3F/0AtLa2xpkzZ+Dq6srLrP8mrK2tUVFRARsbG1hZWT0xrm3btgCqZhkf/7wXFBSgqKhIFJuUlITevXtjxYoVovbi4mLFci5Qt88vAPj4+OD999+HTCZD3759cfv2bcXyGlA1y2RkZARBENCnT5869U2kiViDRA1azan8PXv2QEtLCx4eHujfvz8AYMeOHaKYnTt3AoBiu6ppfzs7OwBQukLocQYGBiguLq71WAMCApCbm4u9e/ciMzMT/v7+ou2+vr549OgRPv/8c6V9y8vLcf/+/VofizSDj48PtLW1sWnTJqVtlZWVKCwsBAC4ublBV1dX5ee9Jh0dHaWZIplMhj/++EPUZmBgAAC1/gybmpritddeg0wmg0wmg6GhoeLfUPVxfXx8cPjwYVy/fl1pfy4RU2PDGSRq0DIzMzF9+nT06dMH58+fx6FDhxASEoJ27doBAIYOHYrY2FgUFxfD2dkZP//8Mw4ePIjhw4dDKpUCAD755BOcO3cO/fr1g5WVFe7du4fY2Fi0bt1acfmzKt26dcPu3bvxySefwMbGBmZmZk+cbQIAT09P6OvrY/Xq1aJLo6u99tprGDFiBKKiovDrr7/Czc0N2trayMzMhEwmQ2RkJH8zb2RsbGwwa9YsrF+/HtnZ2fD09ISBgQGys7ORlJSEadOmYcSIETA3N8e4cePwxRdf4O2330bfvn2RlpaGEydOwNTUVDQbNGDAAGzatAkRERFwcnLC1atXkZiYqPg3Uc3S0hImJibYu3cvjIyMYGhoCAcHB6W4x/n7+2PJkiW4ffs2vLy8FLcgqDZ//nycOXMGw4YNQ0hICDp06ICCggJcvnwZKSkpOH78uHrfQKJXiAkSNWgbN27E2rVrERkZiaZNm2LixImYN2+eYvvy5cthZWWF+Ph4JCUloWXLlpg1a5bi3kVAVX1Qbm4u4uPjUVBQAFNTU/Tq1QszZ85E8+bNn3jsadOmIScnB1u2bEFJSQl69er11ASp+jfupKQkeHt7o1mzZkoxH374Ibp164avv/4aa9asgZ6eHqysrDBixAh06dKlnu8SNWTTpk2DjY0Ndu7ciaioKGhpaaFt27bw9vYWJcQLFiyAvr4+4uLi8P3336NHjx7YunUrxowZI1qSnTp1KkpLS5GYmIjDhw+ja9eu2Lx5M9asWSM6rq6uLlatWoXIyEgsW7YMcrkcK1eufGqC5OPjg2XLlqGkpERpBhSoqpOLi4tDdHQ0ZDIZ7t69CxMTE0ilUsyePVsN7xZRw8FnsVGDFBUVhejoaPz000/1KmQlagyKi4vRs2dPzJkzR+kmjkT0YrEGiYioAXj48KFSW3V9Xa9evV72cIj+9rjERkTUACQmJuLAgQPo378/DAwMFDV37u7uT62VI6IXgwkSEVED0KVLFxw8eBAxMTEoKSmBubk5xo8fjzlz5rzqoRH9LbEGiYiIiKgG1iARERER1cAEiYiIiKgGJkhERERENTBBIvobycnJgVQqRVRU1FPbGpLw8HDFXdGfxcvLC2FhYfU+VlhYGLy8vOq9/9NIpVKEh4e/kL6JSP14FRvRC3bmzBmMGzdO1GZoaAhbW1sMGTIEoaGhT3wifEOXk5ODhIQEeHt7K55vR0TUGDBBInpJBg0ahH79+kEQBNy5cwcJCQlYsWIF0tPT8eGHH76ycVlaWuKXX36pV5KWm5uL6OhoWFpaMkEiokaFCRLRS9K1a1cMGTJE8XrMmDHw9/dHXFwcZs+eDXNzc5X73b9/X+Vz3dRFS0sLTZs2fWH9ExFpItYgEb0izZo1g5OTEwRBQHZ2NoC/amhSUlIwadIkuLi4YPDgwYp9MjMzsXDhQri7u8Pe3h5eXl5YtWoVHjx4oNT/uXPnMGrUKDg4OKBPnz744IMPVMY9rQYpKSkJYWFhcHV1haOjI3x9fbF8+XKUl5cjPj5esXQYEREBqVQKqVQqqgESBAGxsbEIDg6Go6MjnJycEBYWhh9//FHpWGVlZVi1ahXc3d3h4OCA4cOH49SpU3V/Y2s4deoU5syZg4EDB8LBwQGurq6YOHEizp49+8R9srOzMW3aNLi4uMDZ2RnTp09XfI8eV5fzIyLNwhkkoldEEARkZWUBAExNTRXtN2/exPjx4+Hn54fXX39dkdT8+uuvGD9+PIyNjRESEoJWrVrhypUr2LVrFy5cuIBdu3ahSZMmAIBLly7hzTffhJGREaZMmYLmzZvj8OHDWLx4ca3Ht27dOnz22Wfo1KkTJkyYAAsLC9y4cQPffvstZs2ahZ49e2Lq1Kn47LPPEBISongcxuMzYQsXLsShQ4fg6+uL4OBglJeXIzExERMnTkRUVBQGDhyoiJ03bx6Sk5Ph6ekJDw8P3LhxAzNnzoSVlVX932QACQkJKCoqQlBQEFq3bo0//vgDcXFxmDBhAnbu3AlXV1dR/IMHDxAWFgYHBwfMmzcPWVlZiI2NxaVLl5CQkAALC4t6nR8RaRiBiF6oH3/8UZBIJEJUVJRw9+5d4e7du0JqaqqwZMkSQSKRCCNHjlTEenp6ChKJRPj666+V+gkMDBR8fX2FP//8U9T+7bffChKJRNi3b5+iLSQkROjWrZtw/fp1RVtZWZkwbNgwQSKRCBs3blS0Z2dnK7VdunRJkEgkQlhYmPDw4UPR8SorK4XKykrRuT1+7Jrj2rt3r6j90aNHwtChQwVPT09FPydPnhQkEomwePFiUezRo0cFiUQiSCQSpf5V8fT0FEJDQ0VtJSUlSnF5eXlCr169hMmTJ4vaQ0NDBYlEIixfvlzluSxdurRe5ycIgsrzI6KGi0tsRC9JVFQU3Nzc4ObmhiFDhmDfvn3w8vLCpk2bRHEmJiYIDg4WtaWlpSEtLQ2DBg1CeXk57t27p/hycXGBoaEhvv/+ewDA3bt3ceHCBXh5ecHW1lbRh56eHiZMmFCrsR44cAAAMH/+fKX6JC0tLWhpadWqDyMjI3h7e4vGW1xcDC8vL+Tm5iIzMxMAkJycDACYNGmSqA9vb2/ROdSHoaGh4u8lJSUoKCiAtrY2HB0d8csvv6jc55///KfotY+PD2xtbXHs2LF6nR8RaR4usRG9JCEhIfDz84OWlhYMDAzQvn17mJiYKMW1a9dO6Yqya9euAahKsp50v6L8/HwAUNTKdOjQQSmmU6dOtRprVlYWtLS00KVLl1rFq3Lt2jWUlJSgT58+T4y5e/cubG1tkZ2dDW1tbbRv314ppmPHjsjIyKj3OG7cuIF169bh1KlTKC4uFm1TlegZGxuLltEeH0dycjIePHgAQ0PDOp0fEWkeJkhEL4mNjc1Tf5hWMzAweOK2iRMnwsPDQ+U2Y2Pjeo9NldrOFD2JIAgwMzPDmjVrnhjTuXPnevdfGyUlJRg7dixKS0sxfvx4SCQSGBkZQVtbG5s3b36uYuqGcH5E9OIwQSLSADY2NgAAbW3tZyZZ1UXN169fV9qWnp5eq+O1b98eJ06cwJUrV+Dg4PDEuKclUDY2NsjMzISjoyOMjIyeerx27dqhsrISmZmZSklF9exZfZw+fRp37tzBihUrMGzYMNG29evXq9ynuLgYeXl5SrNI165dwz/+8Q/Fkl1dzo+INA9rkIg0QNeuXSGRSLB3716Vl5vL5XIUFhYCqLqKrEePHjh+/Lhoaaq8vBzbt2+v1fECAwMBAGvXrkV5ebnSdkEQAPxV31NUVKQUExQUhMrKSqxdu1blMaqXBAEorvbaunWrKCY5Ofm5lteqlyqrx1vt1KlTuHTp0hP3+/zzz0Wvjx49ioyMDHh7eyva6nJ+RKR5OINEpAG0tLSwevVqjB8/HoMHD8awYcPQqVMnPHz4EFlZWTh69CjmzZunKO4ODw9HWFgYRo8ejbFjxyou86+oqKjV8RwcHDBlyhTExMQgODgY/v7+sLCwQE5ODpKSkhAXFwdjY2N06tQJRkZGiI2Nhb6+PoyNjWFmZgY3Nzf4+fkhODgYu3fvxm+//QZPT0+Ympri9u3buHjxIrKyshRFzx4eHvD09ERCQgIKCwvh4eGB7OxsfPXVV5BIJLh69Wq93jcXFxdYWFhg1apVyM3NRevWrZGamor9+/c/sV9TU1McPXoUd+7cQa9evRSX+Zubm2PGjBmKuLqcHxFpHiZIRBrCzs4OCQkJ2Lx5M44fP469e/fCyMgIlpaWGDp0KNzc3BSxTk5O2LZtG9asWYPPP/8czZs3h6+vL0aPHq2YHXqWBQsWoEuXLti9eze2bNkCQRDQunVr9OvXD/r6+gAAfX19rFu3DuvXr8eKFStQXl6OXr16KcaycuVK9O7dG19//TU2b96MR48ewcLCAl27dsX8+fNFx1u/fj3Wr1+PxMRE/PDDD5BIJIiKisLBgwfrnSAZGxtjy5Yt+Pjjj7F7927I5XLY29sjJiYG33zzjcp+DQ0NsWPHDqxYsQJr1qyBIAjw8PBAeHg4WrZsKYqty/kRkWbREmrOPRMRERH9zbEGiYiIiKgGJkhERERENTBBIiIiIqqBCRIRERFRDUyQiIiIiGpggkRERERUAxMkIiIiohqYIBERERHVwASJiIiIqAYmSEREREQ1/D9kqfXVCHX7JgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNmIMT68s2az"
      },
      "source": [
        "### 5.6.2 - Pipeline for Custom Sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HysJTFYCToL"
      },
      "source": [
        "In order to get a fast intuiton about the application, let's define a pipeline to process and classify a custom sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nAtUId96-N1"
      },
      "source": [
        "def bert_classification(model, sequence):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Load batch to device\n",
        "    b_input_ids, b_attn_mask = (sequence['input_ids'].to(device), \n",
        "                                sequence['attention_mask'].to(device))\n",
        "\n",
        "    # Compute logits\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8byVLP5CCkJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275f6a2e-cc0b-4247-8fd8-6c23cc212782"
      },
      "source": [
        "#@title { vertical-output: true }\n",
        "\n",
        "#@markdown Insert here a sentence in English\n",
        "sentence = \"After all this process, we can claim this model is super\" #@param {type:\"string\"}\n",
        "\n",
        "# Preprocess sentence\n",
        "encoded_sentence = dict()\n",
        "encoded_sentence['input_ids'], encoded_sentence['attention_mask'] = preprocessing_for_sa(pd.Series(sentence), tokenizer, len(tokenizer.encode(sentence)))\n",
        "\n",
        "# Compute probabilities\n",
        "final_probs = bert_classification(bert_classifier, encoded_sentence)\n",
        "\n",
        "# Print results\n",
        "print(f\"{'Sentiment':^11} | {'Probability':^13}\")\n",
        "print(27*'-')\n",
        "print(f\"{'Positive':^11} | {final_probs[0][1]:^13.5f}\")\n",
        "print(27*'-')\n",
        "print(f\"{'Negative':^11} | {final_probs[0][0]:^13.5f}\")\n",
        "print(27*'-')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sentiment  |  Probability \n",
            "---------------------------\n",
            " Positive   |    0.99280   \n",
            "---------------------------\n",
            " Negative   |    0.00720   \n",
            "---------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz6PyX0Enxw-"
      },
      "source": [
        "Finally, to download the whole folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFIwC28TnxWa"
      },
      "source": [
        "def download_folder(dir): \n",
        "    !zip -r $dir\\.zip $dir\n",
        "    files.download(f'{dir}.zip')"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJkPGEDmn86P"
      },
      "source": [
        "#download_folder(sentiment_dir)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zJIwTuBQKmU"
      },
      "source": [
        "# 6 - Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_vCUke1zRjx"
      },
      "source": [
        "A more challenged task is **Question Answering**, which corresponds to extract the answer to a question from a given context. In this case the model answers the question by taking a substring of a context, not by generating new text.\n",
        "\n",
        "We are going to use [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) (Stanford Question Answering Dataset), a collection of 100k crowdsourced question/answer pairs. Given a question and a passage from Wikipedia containing the answer, the task is to predict the answer text span in the passage. This corresponds with SQuAD 1.1. In SQuAD 2.0 the problem definition is extended allowing for the possibility\n",
        "that no short answer exists in the provided paragraph, making the problem more realistic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReMEq5Ja3w9t"
      },
      "source": [
        "![Q&A](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/question_answering.png)\n",
        "\n",
        "> Image from [Hugging Face models](https://huggingface.co/models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egdBStwB4KQl"
      },
      "source": [
        "> For this task it is followed Hugging Face notebook's [question_answering](https://github.com/huggingface/notebooks/blob/master/examples/question_answering.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHhkbyihMiix"
      },
      "source": [
        "## 6.1 - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7m050pfMpz6"
      },
      "source": [
        "As before, the option to change the runtime type to a GPU is a good option."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pGcZbjzMyvX",
        "outputId": "c35000b9-e370-46a4-8715-dfb46b71e7c2"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Oz5y8fM0ka"
      },
      "source": [
        "## 6.2 - Load SQuAD Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hEJMkm3NNj_"
      },
      "source": [
        "We are going to use [Hugging Face Datasets](https://huggingface.co/docs/datasets/v1.4.1/index.html), so running next cell we install the libraries in Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I7zzOdSNcn6",
        "outputId": "4d14d343-756e-411f-8051-cf30d76ddd1f"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/a2/d4e1024c891506e1cee8f9d719d20831bac31cb5b7416983c4d2f65a6287/datasets-1.8.0-py3-none-any.whl (237kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 20.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 7.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 51kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 102kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 153kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 174kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 184kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 204kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 215kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 225kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 235kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.0.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/d2/d05466997f7751a2c06a7a416b7d1f131d765f7916698d3fdcb3a4d037e5/fsspec-2021.6.0-py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: fsspec, xxhash, datasets\n",
            "Successfully installed datasets-1.8.0 fsspec-2021.6.0 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YenkcQigPzwK"
      },
      "source": [
        "With method [`load_dataset`](https://huggingface.co/docs/datasets/v1.4.1/package_reference/loading_methods.html#datasets.load_dataset) and specifying the name of the datasets we can load the required data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267,
          "referenced_widgets": [
            "9682d236b1f14f6d9a5d466458beaf2c",
            "47778129b21e4b1ab88750557e39e94f",
            "c3a7fb759c124063ae0285bb32f2c1dc",
            "bf771ae5914e49fc9ef88fc9c581cc4a",
            "7165d4ad4e8e42aa89c2f21b38cb80da",
            "ea8bab9736b04550830b373d4c2be1a9",
            "de2728dda4f44ade9a3c7cd7d19ab3b7",
            "81d3896278af46be83a0e30c1f62c605",
            "5fda5d278f3b4f2b88ab1aa9d4e7a94a",
            "9bac08a97d654a06b730793e8ac2b644",
            "74820ca738db4e8c96d66c828e9fded9",
            "e2cc18176eef4f90ac0db167cce4f861",
            "b536b3f2aaca49b1b70c74915d8ed455",
            "bec704dba23e423bb09444a0ed868238",
            "304d22a9fd2c4c1b955f919289af3de2",
            "99fef41754a646b4a531968196b7acab",
            "af2f5508bfbc4f6a96fda3101304b387",
            "4e4104d3257144f6a85fc3fdb817760c",
            "3abf36e368e94f9c8e6820a8a3a60590",
            "3638be53fa8145bdaf4208489d0b079b",
            "903d87fa836e473e9a31a8cf1c6a7601",
            "c08438a1ecd141ed95c8809f7ddcf26a",
            "d661376dd5c44332856da9a4cf9f1335",
            "f3e9571a2e084e4b8ac16cfc38ddf1b4",
            "56272bb483334c329af56692f981f050",
            "696bb5681ac14789a0fe45dc4d3a23a9",
            "9861ef684f24462e8c1b03f13bfeb070",
            "a9c62bbb8c2046d99685920827122b2a",
            "fb761a3d3d2b4c728355fff2da6eb0e1",
            "df3a2f22afba4d2f94299f8e24d20d3b",
            "59d29630173a443ca1f84f58bfbbe90d",
            "1395c770ef2c4eccacd3efd627f7ced1",
            "baf5d5a70d36492e80a67eb99ba37ec0",
            "95439036f19a46e193e8c04380860f95",
            "3179ea28629f4313a06aca487eef4642",
            "d181b174002f430bb165690b4ea29906",
            "00b68ebfab9241968a60d44cb5793d51",
            "580eac65ec364d73a8d960720d0848bc",
            "6b5c3c5f5315449884342c00676a7a5a",
            "f9654cd217684f67b77d2849d320f7e8",
            "412d827f4dfd4ca8ad0322c5567d7828",
            "6cd09dff9f924afaa57cfb1b1d333850",
            "3b44acac8de2465b84b8785e4e422c4e",
            "0a469f0faa434535981653caeee2220d",
            "b34d0eea570e4ff7beb9162fcb821be6",
            "e742895551814aab9e238de77ee6ac1f",
            "e10b062314724548a1b016c0e08a014b",
            "0b2c7595672c4c0ead0d9bc2ae217e25"
          ]
        },
        "id": "ZCsWZXIlOTTK",
        "outputId": "f1b82e0f-fa59-4aec-d9d0-90b6f9cc5f9e"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# This flag is the difference between SQUAD v1 or 2 \n",
        "# if you're using another dataset, it indicates if impossible answers are allowed or not).\n",
        "squad_v2 = False\n",
        "original_datasets = load_dataset('squad_v2' if squad_v2 else 'squad')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9682d236b1f14f6d9a5d466458beaf2c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1947.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fda5d278f3b4f2b88ab1aa9d4e7a94a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1021.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.63 MiB, post-processed: Unknown size, total: 119.14 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/6b6c4172d0119c74515f44ea0b8262efe4897f2ddb6613e5e915840fdc309c16...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af2f5508bfbc4f6a96fda3101304b387",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=8116577.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56272bb483334c329af56692f981f050",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1054280.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "baf5d5a70d36492e80a67eb99ba37ec0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "412d827f4dfd4ca8ad0322c5567d7828",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/6b6c4172d0119c74515f44ea0b8262efe4897f2ddb6613e5e915840fdc309c16. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn_QnL6WQpOf"
      },
      "source": [
        "The loaded dataset is an object of [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict). It is a dictionary which contains train and validation samples, with the correspondig `context`, `question` and `answers`. As in the previous task, SQuAD is also used in competitions. In this case, there are not original test data. For this reason, as before, one third of training set is going to be used as test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDlay57Q0xL8"
      },
      "source": [
        "new_split = original_datasets['train'].train_test_split(test_size=0.33)\n",
        "original_datasets['train'] = new_split['train']\n",
        "original_datasets['test'] = new_split['test']"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfGCw5Gk1o0I"
      },
      "source": [
        "With next function we can show random elements in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3j8APAoIrI3"
      },
      "source": [
        "from datasets import ClassLabel, Sequence\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
        "    display(HTML(df.to_html()))"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGqxi4rE3j6e"
      },
      "source": [
        "For a fast intuition on the model, we can remove some data, since the original size of the dataset has more than 80k samples only in training. With `perc` we select the percentage of data we are going to use. Removed sample are selected randomly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "s4Ww8dtnQsSu",
        "outputId": "3aae8dc2-5b69-42f8-e856-1168ca88551a"
      },
      "source": [
        "#@markdown Select a split\n",
        "split = \"train\" #@param [\"train\", \"validation\", \"test\"]\n",
        "#@markdown Select number of examples to visualize it\n",
        "num_examples = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "print(f'Some sentences of {split} split, which has a length of {original_datasets[split].num_rows}\\n')\n",
        "show_random_elements(original_datasets[split], num_examples)\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some sentences of train split, which has a length of 58691\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'text': ['Hauts-de-Seine, Seine-Saint-Denis and Val-de-Marne'], 'answer_start': [318]}</td>\n",
              "      <td>The Métropole du Grand Paris, or Metropolis of Greater Paris, formally came into existence on January 1, 2016. It is an administrative structure for cooperation between the City of Paris and its nearest suburbs. It includes the City of Paris, plus the communes, or towns of the three departments of the inner suburbs; Hauts-de-Seine, Seine-Saint-Denis and Val-de-Marne; plus seven communes in the outer suburbs, including Argenteuil in Val d'Oise and Paray-Vieille-Poste in Essonne, which were added to include the major airports of Paris. The Metropole covers 814 square kilometers and has a population of 6.945 million persons.</td>\n",
              "      <td>5728ccfb4b864d1900164e61</td>\n",
              "      <td>What three departments of the inner suburbs are included in the metropole?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'text': ['Government'], 'answer_start': [206]}</td>\n",
              "      <td>Connaught Place, one of North India's largest commercial and financial centres, is located in the northern part of New Delhi. Adjoining areas such as Barakhamba Road, ITO are also major commercial centres. Government and quasi government sector was the primary employer in New Delhi. The city's service sector has expanded due in part to the large skilled English-speaking workforce that has attracted many multinational companies. Key service industries include information technology, telecommunications, hotels, banking, media and tourism.</td>\n",
              "      <td>5706af7575f01819005e7d37</td>\n",
              "      <td>Prior to the expansion of the service sector, what sector was the largest employer in New Delhi?</td>\n",
              "      <td>New_Delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'text': ['age and accumulated experiences'], 'answer_start': [739]}</td>\n",
              "      <td>The inclusiveness of Weinreich's definition (above) directs attention to the totality of one's identity at a given phase in time, and assists in elucidating component aspects of one's total identity, such as one's gender identity, ethnic identity, occupational identity and so on. The definition readily applies to the young child, to the adolescent, to the young adult, and to the older adult in various phases of the life cycle. Depending on whether one is a young child or an adult at the height of one's powers, how one construes oneself as one was in the past will refer to very different salient experiential markers. Likewise, how one construes oneself as one aspires to be in the future will differ considerably according to one's age and accumulated experiences. (Weinreich &amp; Saunderson, (eds) 2003, pp 26–34).</td>\n",
              "      <td>570961b2ed30961900e84037</td>\n",
              "      <td>How one construes oneself now and in the future differs considerably because of what 2 things?</td>\n",
              "      <td>Identity_(social_science)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBP-0Z5w5R3t"
      },
      "source": [
        "As before, for a fast intuition on the model, we can remove some data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNZtBVZxA-SQ"
      },
      "source": [
        "from datasets import DatasetDict"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj7Kp7aAaBTO",
        "outputId": "6e258f5c-082f-45ae-8f73-4a5d865beded"
      },
      "source": [
        "#@title 6.2.1 Resize dataset { vertical-output: true }\n",
        "#@markdown Percentage of dataset to use %\n",
        "perc = 100 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "datasets = DatasetDict()\n",
        "\n",
        "for key, dataset in original_datasets.shuffle().items():\n",
        "    if perc != 100:\n",
        "        datasets[key] = dataset.select(np.arange(0, round(dataset.num_rows*(perc/100)+1)))\n",
        "        print(f'{key:<10}\\t', f'From: {original_datasets[key].num_rows:<10}', f'To: {datasets[key].num_rows:<10}')\n",
        "    else:\n",
        "        datasets[key] = original_datasets[key]\n",
        "        print(f'{key:<10}\\t', f'size: {len(original_datasets[key]):<10}')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train     \t size: 58691     \n",
            "validation\t size: 10570     \n",
            "test      \t size: 28908     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-LZ1teNUeFY"
      },
      "source": [
        "## 6.3 - Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8q68IuPU1_l"
      },
      "source": [
        "In this task the structure of the input differs from sentiment analysis. Now we have two sentences:\n",
        "\n",
        "\\begin{matrix}\n",
        "    [CLS] & \\text{Sentence A} & [SEP] & \\text{Sentence B}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZInR1JVXVn4V"
      },
      "source": [
        "In this case we are going to use [`BertTokenizerFast`](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertTokenizerFast). This one is a [Fast Tokenizer](https://huggingface.co/transformers/main_classes/tokenizer.html#tokenizer), which according to Hugging Face implies \n",
        "\n",
        "- A significant speed-up in particular when doing batched tokenization.\n",
        "- Additional methods to map between the original string (character and words) and the token space.\n",
        "\n",
        "As before, we choose [`bert-base-uncased`](https://huggingface.co/bert-base-uncased) as pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvPgC4STfI7f",
        "outputId": "425f18db-4b03-4df8-9ef4-718894e28348"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "MODEL_NAME = 'bert-base-uncased'\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...\\n')\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul-6neG4ki-Q"
      },
      "source": [
        "As before, we can check its attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phbxf9K_kvXW",
        "outputId": "cbc9a3e6-eb5a-4dd5-f8e9-868b28b16683"
      },
      "source": [
        "#@markdown Select an option to visualize it\n",
        "attribute = \"vocab_size\" #@param [\"vocab_size\", \"model_max_length\", \"padding_side\", \"sep_token\", \"pad_token\", \"cls_token\", \"mask_token\", \"unk_token\"]\n",
        "\n",
        "print(getattr(tokenizer, attribute))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD1KrbgIAknD"
      },
      "source": [
        "One problem is how manage long documents. The \n",
        "usual truncation process could carry in losing the answer we are looking for. To deal with it, we truncate the context into features, text shorter than maximum length allowed, and allow some overlap between them in case the answer lies at the point we split a long context\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4lwrtz5C3QR"
      },
      "source": [
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two parts of the context when splitting it is needed."
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UohhB81oTEIh"
      },
      "source": [
        "Let's find an example whose length is longer than `max_length`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgCCZ_EGC354",
        "outputId": "9707e8f6-d77c-4523-97ac-b9da7a6db783"
      },
      "source": [
        "for i, example in enumerate(datasets[\"train\"]):\n",
        "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > max_length:\n",
        "        break\n",
        "example = datasets[\"train\"][i]\n",
        "example"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': {'answer_start': [56], 'text': ['1998 Winter Olympics']},\n",
              " 'context': \"Japan: The event was held in Nagano, which hosted the 1998 Winter Olympics, on April 26. Japanese Buddhist temple Zenkō-ji, which was originally scheduled to be the starting point for the Olympic torch relay in Nagano, refused to host the torch and pulled out of the relay plans, amid speculation that monks there sympathized with anti-Chinese government protesters. as well as the risk of disruption by violent protests. Parts of Zenkō-ji temple's main building (Zenkō-ji Hondō), reconstructed in 1707 and one of the National Treasures of Japan, was then vandalized with spraypaint. A new starting point, previously the site of a municipal building and now a parking lot, was chosen by the city. An event the city had planned to hold at the Minami Nagano Sports Park following the torch relay was also canceled out of concern about disruptions caused by demonstrators protesting against China's recent crackdown in Tibet. Thousands of riot police were mobilized to protect the torch along its route. The show of force kept most protesters in check, but slogans shouted by pro-China or pro-Tibet demonstrators, Japanese nationalists, and human rights organizations flooded the air. Five men were arrested and four injured amidst scenes of mob violence. The torch route was packed with mostly peaceful demonstrators. The public was not allowed at the parking lot where the relay started. After the Zenkoji monks held a prayer ceremony for victims of the recent events in Tibet. More than 100 police officers ran with the torch and riot police lined the streets while three helicopters flew above. Only two Chinese guards were allowed to accompany the torch because of Japan's concern over their treatment of demonstrators at previous relays. A man with a Tibetan flag tried to stop the torch at the beginning of the relay but was dragged off by police. Some raw eggs were also thrown from the crowd.\",\n",
              " 'id': '56db6d76e7c41114004b50e2',\n",
              " 'question': 'Which Olympics did Nagano host?',\n",
              " 'title': '2008_Summer_Olympics_torch_relay'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKprbGPFgPF6",
        "outputId": "79c8075c-93b0-467b-bfc2-f79f81da5fd5"
      },
      "source": [
        "print(f'Original length \\t{len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"])}')\n",
        "print(f'Truncated length \\t{len(tokenizer(example[\"question\"], example[\"context\"], max_length=max_length, truncation=\"only_second\")[\"input_ids\"])}')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original length \t392\n",
            "Truncated length \t384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yGs3fWPVsUO"
      },
      "source": [
        "Only the context should be truncated, specifying `truncation=only_second`. The tokenizer will return a lisf of features capped by a certain maximum length, with the overlap we talked above. We just have to declare `return_overflowing_tokens=True` and `stride=doc_stride` to pass the stride.\n",
        "\n",
        "Mention we need to find in which of those features the answer actually is, and where exactly in that feature, the start and end positions. The tokenizer we're using can help us with that by returning an `offset_mapping`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_Y6IdUoC8_W"
      },
      "source": [
        "tokenized_example = tokenizer(\n",
        "    example[\"question\"],\n",
        "    example[\"context\"],\n",
        "    max_length=max_length,\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        "    stride=doc_stride\n",
        ")"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmrd83ymaf_s"
      },
      "source": [
        "We can plot each of the features in order to see the overlapping part:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7Jy6J3XadOn",
        "outputId": "db995c7c-3f99-46db-c5ea-3a39be78338c"
      },
      "source": [
        "for i, x in enumerate(tokenized_example[\"input_ids\"]):\n",
        "    print(f'Feature {i+1} with {len(x)} tokens')\n",
        "    print(tokenizer.convert_ids_to_tokens(x), '\\n') # or tokenizer.decode(x)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature 1 with 384 tokens\n",
            "['[CLS]', 'which', 'olympics', 'did', 'naga', '##no', 'host', '?', '[SEP]', 'japan', ':', 'the', 'event', 'was', 'held', 'in', 'naga', '##no', ',', 'which', 'hosted', 'the', '1998', 'winter', 'olympics', ',', 'on', 'april', '26', '.', 'japanese', 'buddhist', 'temple', 'zen', '##ko', '-', 'ji', ',', 'which', 'was', 'originally', 'scheduled', 'to', 'be', 'the', 'starting', 'point', 'for', 'the', 'olympic', 'torch', 'relay', 'in', 'naga', '##no', ',', 'refused', 'to', 'host', 'the', 'torch', 'and', 'pulled', 'out', 'of', 'the', 'relay', 'plans', ',', 'amid', 'speculation', 'that', 'monks', 'there', 'sy', '##mp', '##athi', '##zed', 'with', 'anti', '-', 'chinese', 'government', 'protesters', '.', 'as', 'well', 'as', 'the', 'risk', 'of', 'disruption', 'by', 'violent', 'protests', '.', 'parts', 'of', 'zen', '##ko', '-', 'ji', 'temple', \"'\", 's', 'main', 'building', '(', 'zen', '##ko', '-', 'ji', 'hon', '##do', ')', ',', 'reconstructed', 'in', '1707', 'and', 'one', 'of', 'the', 'national', 'treasures', 'of', 'japan', ',', 'was', 'then', 'van', '##dal', '##ized', 'with', 'spray', '##pa', '##int', '.', 'a', 'new', 'starting', 'point', ',', 'previously', 'the', 'site', 'of', 'a', 'municipal', 'building', 'and', 'now', 'a', 'parking', 'lot', ',', 'was', 'chosen', 'by', 'the', 'city', '.', 'an', 'event', 'the', 'city', 'had', 'planned', 'to', 'hold', 'at', 'the', 'mina', '##mi', 'naga', '##no', 'sports', 'park', 'following', 'the', 'torch', 'relay', 'was', 'also', 'canceled', 'out', 'of', 'concern', 'about', 'disruption', '##s', 'caused', 'by', 'demonstrators', 'protesting', 'against', 'china', \"'\", 's', 'recent', 'crack', '##down', 'in', 'tibet', '.', 'thousands', 'of', 'riot', 'police', 'were', 'mobilized', 'to', 'protect', 'the', 'torch', 'along', 'its', 'route', '.', 'the', 'show', 'of', 'force', 'kept', 'most', 'protesters', 'in', 'check', ',', 'but', 'slogan', '##s', 'shouted', 'by', 'pro', '-', 'china', 'or', 'pro', '-', 'tibet', 'demonstrators', ',', 'japanese', 'nationalists', ',', 'and', 'human', 'rights', 'organizations', 'flooded', 'the', 'air', '.', 'five', 'men', 'were', 'arrested', 'and', 'four', 'injured', 'amidst', 'scenes', 'of', 'mob', 'violence', '.', 'the', 'torch', 'route', 'was', 'packed', 'with', 'mostly', 'peaceful', 'demonstrators', '.', 'the', 'public', 'was', 'not', 'allowed', 'at', 'the', 'parking', 'lot', 'where', 'the', 'relay', 'started', '.', 'after', 'the', 'zen', '##ko', '##ji', 'monks', 'held', 'a', 'prayer', 'ceremony', 'for', 'victims', 'of', 'the', 'recent', 'events', 'in', 'tibet', '.', 'more', 'than', '100', 'police', 'officers', 'ran', 'with', 'the', 'torch', 'and', 'riot', 'police', 'lined', 'the', 'streets', 'while', 'three', 'helicopters', 'flew', 'above', '.', 'only', 'two', 'chinese', 'guards', 'were', 'allowed', 'to', 'accompany', 'the', 'torch', 'because', 'of', 'japan', \"'\", 's', 'concern', 'over', 'their', 'treatment', 'of', 'demonstrators', 'at', 'previous', 'relay', '##s', '.', 'a', 'man', 'with', 'a', 'tibetan', 'flag', 'tried', 'to', 'stop', 'the', 'torch', 'at', 'the', 'beginning', 'of', 'the', 'relay', 'but', 'was', 'dragged', 'off', 'by', 'police', '.', 'some', 'raw', '[SEP]'] \n",
            "\n",
            "Feature 2 with 146 tokens\n",
            "['[CLS]', 'which', 'olympics', 'did', 'naga', '##no', 'host', '?', '[SEP]', 'men', 'were', 'arrested', 'and', 'four', 'injured', 'amidst', 'scenes', 'of', 'mob', 'violence', '.', 'the', 'torch', 'route', 'was', 'packed', 'with', 'mostly', 'peaceful', 'demonstrators', '.', 'the', 'public', 'was', 'not', 'allowed', 'at', 'the', 'parking', 'lot', 'where', 'the', 'relay', 'started', '.', 'after', 'the', 'zen', '##ko', '##ji', 'monks', 'held', 'a', 'prayer', 'ceremony', 'for', 'victims', 'of', 'the', 'recent', 'events', 'in', 'tibet', '.', 'more', 'than', '100', 'police', 'officers', 'ran', 'with', 'the', 'torch', 'and', 'riot', 'police', 'lined', 'the', 'streets', 'while', 'three', 'helicopters', 'flew', 'above', '.', 'only', 'two', 'chinese', 'guards', 'were', 'allowed', 'to', 'accompany', 'the', 'torch', 'because', 'of', 'japan', \"'\", 's', 'concern', 'over', 'their', 'treatment', 'of', 'demonstrators', 'at', 'previous', 'relay', '##s', '.', 'a', 'man', 'with', 'a', 'tibetan', 'flag', 'tried', 'to', 'stop', 'the', 'torch', 'at', 'the', 'beginning', 'of', 'the', 'relay', 'but', 'was', 'dragged', 'off', 'by', 'police', '.', 'some', 'raw', 'eggs', 'were', 'also', 'thrown', 'from', 'the', 'crowd', '.', '[SEP]'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUvWR31SbRIH"
      },
      "source": [
        "And how the tokenizer can provide us the positions of each token:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IDygx3Cb4Vb",
        "outputId": "f5c87c48-8629-471f-9cad-9d462bf88ed7"
      },
      "source": [
        "rnd_index = random.randint(0, len(tokenized_example[\"input_ids\"][0])-1)\n",
        "token_id = tokenized_example[\"input_ids\"][0][rnd_index]\n",
        "offsets = tokenized_example[\"offset_mapping\"][0][rnd_index]\n",
        "\n",
        "print(f'Token {rnd_index} \\t{tokenizer.convert_ids_to_tokens(token_id)}\\n')\n",
        "\n",
        "print(f'Start position \\t{offsets[0]}')\n",
        "print(f'End position \\t{offsets[1]}')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token 379 \tpolice\n",
            "\n",
            "Start position \t1844\n",
            "End position \t1850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyKmuAv3wz79"
      },
      "source": [
        "To distinguish which parts of the offsets correspond to the question and which part correspond to the context, we can use [`sequence_ids`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.BatchEncoding.sequence_ids) method. It returns `None` for the special tokens, then 0 or 1 depending on whether the corresponding token comes from the first sentence past (the question) or the second (the context)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dLSn6Z4ej8N",
        "outputId": "2356d3be-d232-4119-81d7-213563860390"
      },
      "source": [
        "sequence_ids = tokenized_example.sequence_ids()\n",
        "print(sequence_ids)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[None, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-FZScaFfq92"
      },
      "source": [
        "With all of this, the last step is to check if the answer is in the feature or in the next one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_T4P94NfqPa",
        "outputId": "2903b3a7-5df3-4127-f6e8-ac66e34bdd8a"
      },
      "source": [
        "answers = example[\"answers\"]\n",
        "start_char = answers[\"answer_start\"][0]\n",
        "end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "# Start token index of the current span in the text.\n",
        "token_start_index = 0\n",
        "while sequence_ids[token_start_index] != 1:\n",
        "    token_start_index += 1\n",
        "\n",
        "# End token index of the current span in the text.\n",
        "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
        "while sequence_ids[token_end_index] != 1:\n",
        "    token_end_index -= 1\n",
        "\n",
        "# Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "offsets = tokenized_example[\"offset_mapping\"][0]\n",
        "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "    # Move the token_start_index and token_end_index to the two ends of the answer.\n",
        "    # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "        token_start_index += 1\n",
        "    start_position = token_start_index - 1\n",
        "    while offsets[token_end_index][1] >= end_char:\n",
        "        token_end_index -= 1\n",
        "    end_position = token_end_index + 1\n",
        "    print(f'Original answer \\t{answers[\"text\"][0]}', '\\n')\n",
        "    print(f'Start position \\t\\t{start_position}')\n",
        "    print(f'End position \\t\\t{end_position}')\n",
        "    print(f'In feature \\t\\t{tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1])}')\n",
        "else:\n",
        "    print(\"The answer is not in this feature.\")"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original answer \t1998 Winter Olympics \n",
            "\n",
            "Start position \t\t22\n",
            "End position \t\t26\n",
            "In feature \t\t1998 winter olympics, on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt4b2eCbrz-Y"
      },
      "source": [
        "Once all steps are explained, we can integrate them in a whole function to preprocess whole data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQz2mF7fwz8A"
      },
      "source": [
        "def preprocessing_for_qa(examples):\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],               #tokenize question\n",
        "        examples[\"context\"],                #tokenize context\n",
        "        truncation=\"only_second\",           #truncate only context if necessary\n",
        "        max_length=max_length,              #variable max_length\n",
        "        stride=doc_stride,                  #overlap to stride\n",
        "        return_overflowing_tokens=True,     #return overflowing tokens\n",
        "        return_offsets_mapping=True,        #return offsets mapping\n",
        "        padding=\"max_length\"                #pad to max length\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != 1:\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != 1:\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd0323JyKkoZ"
      },
      "source": [
        "Now, we only have to apply the function to the different splits. We can use the [`map`](https://huggingface.co/docs/datasets/v1.4.1/package_reference/main_classes.html?highlight=map#datasets.Dataset.map) method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "f5ed8e38e4b4407d83b5d9c6516ad618",
            "2f892028c9bc4c6b9cea9f0d2e353dc2",
            "c3b92a65cd0a4012842d73c4086088c8",
            "54d404bf1a8d4b4aaefed7782383ecde",
            "c881957e5ca34a188462b064d9bfb4eb",
            "6202167ee6d345b2b29089f11e4ed2f1",
            "1b90775d537f469f86a502fc639c4ddb",
            "5f15ef64c5184a0e939a3ad73493b9c2",
            "d738dc2ae8ea443d995c8fb7818689e6",
            "8dba3b398bd448f5bb566cff7eff8e01",
            "b98e804f288642339daa0b1ab87a46df",
            "87cc1d01fb0342cb989a5263badc7cb4",
            "3260cd759ea049c396fc9ecf0e4057ad",
            "8ca632cc43a74b66808c8ef7388ba68c",
            "aaab5f370f714015b3e5be2e5f9165f0",
            "636a9eac22bf4772947966da4279e91b",
            "da3d877e32c945aa999b7b5eebd5db03",
            "e76b6bf40b4d440eb6ec653f0393f8fd",
            "de9866dc89834e06bdd9ed8fe8cc2638",
            "4905ca4ba5834a229575a8f9dcf9c361",
            "a64f5fc3f09941c59d0f17551f5c44f1",
            "feaafc37b3684796804531838d243140",
            "f58d720e28bf4852887200a86e00fc8d",
            "fedf476a7ab04330a4803d0b499606fe"
          ]
        },
        "id": "fUC0DNfzNJIW",
        "outputId": "dbefc200-d89c-45a4-f0ef-3f15f6e25395"
      },
      "source": [
        "tokenized_datasets = datasets.map(preprocessing_for_qa, \n",
        "                                  batched=True, \n",
        "                                  remove_columns=datasets[\"train\"].column_names)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5ed8e38e4b4407d83b5d9c6516ad618",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d738dc2ae8ea443d995c8fb7818689e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da3d877e32c945aa999b7b5eebd5db03",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voWiw8C7IrJV"
      },
      "source": [
        "The results are automatically cached by the [Datasets](https://huggingface.co/docs/datasets/v1.4.1/index.html) library to avoid spending time on this step the next time you run your notebook. With `load_from_cache_file=False` in the call to [`map`](https://huggingface.co/docs/datasets/v1.4.1/package_reference/main_classes.html?highlight=map#datasets.Dataset.map), the cached files are not used and the preprocessing is applied again.\n",
        "\n",
        "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGeN3Ju3WZzQ"
      },
      "source": [
        "Once the original datasets are tokenizer, we get another [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), but with different columns than the original one: `attention_mask`, used to indicate words from additional padding, `input_ids`, tokens as integers, and `token_type_ids`, indicating to which sentence words belongs. Finally the start and end positions of the answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "OauAJlyHWtpQ",
        "outputId": "84ff1c1f-4055-4dcb-d40b-32c018b91b78"
      },
      "source": [
        "#@markdown Select a split\n",
        "split = \"train\" #@param [\"train\", \"validation\", \"test\"]\n",
        "#@markdown Select number of examples to visualize it\n",
        "num_examples = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "print(f'Some sentences of {split} split, which has a length of {tokenized_datasets[split].num_rows}\\n')\n",
        "show_random_elements(tokenized_datasets[split], num_examples)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some sentences of train split, which has a length of 59327\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>end_positions</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>start_positions</th>\n",
              "      <th>token_type_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
              "      <td>110</td>\n",
              "      <td>[101, 2054, 2095, 2106, 10692, 2707, 2037, 3171, 4125, 2241, 2006, 2844, 14338, 1029, 102, 2138, 1997, 1996, 3795, 3171, 19396, 2008, 2211, 1999, 2289, 1010, 1996, 14230, 1997, 10692, 10548, 2011, 1015, 1012, 1018, 1003, 1999, 1996, 3416, 4284, 1997, 2263, 1010, 2058, 1017, 1003, 1999, 1996, 3822, 4284, 1997, 2263, 1010, 1998, 2058, 1023, 1003, 1999, 1996, 4343, 4284, 1997, 2263, 1012, 1996, 12029, 2231, 2081, 1037, 26215, 4997, 5166, 1010, 2029, 2001, 2979, 2011, 15544, 8004, 12676, 12193, 1012, 1996, 6599, 1997, 1996, 5166, 2001, 10548, 2005, 2263, 2011, 25212, 2243, 1020, 1012, 1015, 4551, 1998, 1996, ...]</td>\n",
              "      <td>110</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>42</td>\n",
              "      <td>[101, 1999, 2289, 1010, 2054, 2001, 1996, 2988, 5813, 1997, 1996, 21388, 26797, 2291, 1029, 102, 1999, 2289, 1010, 1996, 2880, 8418, 25311, 6692, 2739, 4034, 2988, 2008, 1996, 5813, 1997, 1996, 21388, 26797, 2291, 2001, 2004, 2152, 2004, 1014, 1012, 1019, 3620, 1012, 2007, 1996, 4493, 5310, 17703, 2009, 3544, 2008, 1996, 10250, 12322, 9250, 10640, 2003, 2322, 2213, 1006, 2531, 2213, 1010, 4895, 9289, 12322, 9250, 1007, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>36</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
              "      <td>178</td>\n",
              "      <td>[101, 2054, 12763, 2024, 3378, 2007, 25353, 21850, 6856, 1029, 102, 1999, 5184, 29393, 8458, 8189, 11233, 1010, 1996, 2034, 12553, 3424, 1011, 1999, 25969, 3512, 4319, 1010, 2001, 2764, 2011, 2703, 15501, 12190, 7033, 1998, 15535, 6152, 17064, 12112, 1997, 1996, 2820, 1997, 6388, 7242, 1999, 4068, 1012, 1996, 4319, 2001, 2445, 1996, 3293, 2171, 16183, 10755, 8791, 1012, 15501, 12190, 7033, 1010, 9073, 2119, 1996, 2236, 22423, 1997, 29596, 1998, 1996, 13228, 16326, 1997, 3056, 18554, 2015, 2011, 10327, 1010, 1044, 22571, 14573, 2229, 3550, 2008, 2019, 29596, 1011, 4820, 18554, 2007, 2714, 13228, 16326, 5144, 2071, 2022, ...]</td>\n",
              "      <td>168</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQBsd8ivQ8cX"
      },
      "source": [
        "## 6.4 - Generate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_mjlVIIncTf"
      },
      "source": [
        "To fine tune on **Question Answering**, it is introduced a start vector $ S \\in \\mathbb R^{H} $ and an end vector $ E \\in \\mathbb R^{H} $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPARYgkTSI7X"
      },
      "source": [
        "![Fine tune Q&A](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/question_answering_fine_tune.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb12e17xqRSr"
      },
      "source": [
        "To compute the probability of a word $ i $ being the start or the end of the answer, we compute the dot product between $ S $ and $ T_i $ followed by a softmax over all the words in the sequence.\n",
        "\n",
        "\\begin{equation}\n",
        "    P_i = \\frac{e^{S \\cdot T_i}}{\\sum_{j} e^{S \\cdot T_j}}\n",
        "\\end{equation} \n",
        "\n",
        "The score for a candidate is defined as $ S \\cdot T_i \\ + \\ E \\cdot T_j $, where $ i $ is the start position and $ j $ the final position. The maximum scoring span: $ \\hat{s_{i, j}} = max_{j \\geq i} S \\cdot T_i \\ + \\ E \\cdot T_j $ is used as prediction, where the training objective is the sum of the log-likelihoods of the correct start and end positions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwmIElx_DKBV"
      },
      "source": [
        "![Model Q&A](https://raw.githubusercontent.com/ion-bueno/bert-from-inside/main/images/bert-qa.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URbe2r4LuNkG"
      },
      "source": [
        "To extend to SQuAD 2.0, questions which do not have an answer have an span with start and end at the $ [CLS] $ token. It is compared the score of the null answer span: $ s_{null} = S \\cdot C \\ + E \\cdot C $ with $ \\hat{s_{i, j}} $. It is predicted a non-null answer if $ \\hat{s_{i, j}} > s_{null} \\ + \\ \\tau$, where threshold $ \\tau $ i selected on the validation set to maximize F1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4iHhaveC1HX"
      },
      "source": [
        "In this task we are going to use the model designed by Hugging Face [`BertForQuestionAnswering`](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertForQuestionAnswering)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eddDHjFJ_6zq",
        "outputId": "00996296-fe8e-43ec-a352-5717ab8bce4e"
      },
      "source": [
        "from transformers import BertForQuestionAnswering\n",
        "\n",
        "bert_qa = BertForQuestionAnswering.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtD_B4OnAGJP",
        "outputId": "d045a63b-ee6d-4b8b-920a-d87bfe4bb3aa"
      },
      "source": [
        "#@markdown Select whole model, only pretrained BERT or the question & answer outputs\n",
        "block = \"model\" #@param [\"model\", \"bert\", \"qa_outputs\"]\n",
        "if block == 'model':\n",
        "    print(bert_qa)\n",
        "else:\n",
        "    print(getattr(model, block))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertForQuestionAnswering(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvBPQ9ytQLkS"
      },
      "source": [
        "## 6.5 - Fine-Tune on SQuAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKMFi-Oy3JHL"
      },
      "source": [
        "Now it is the moment to train the model for our specific task. We can use an instance of [`Trainer`](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainer#transformers.Trainer) class in order to avoid many lines of code. The most important is the [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUKFtfhi58BY"
      },
      "source": [
        "from transformers import TrainingArguments"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNvT62_G3SMm"
      },
      "source": [
        "#@title 6.5.1 - Hyperparameters Selection\n",
        "batch_size =  16#@param {type:\"integer\"}\n",
        "learning_rate = 5e-5 #@param {type:\"number\"}\n",
        "epochs =  3#@param {type:\"integer\"}\n",
        "epsilon = 1e-8 #@param {type:\"number\"}\n",
        "weight_decay=0.01 #@param {type:\"number\"}\n",
        "qa_dir = Path('question_answering')\n",
        "strategy = 'epoch'\n",
        "\n",
        "args = TrainingArguments(\n",
        "    qa_dir,\n",
        "    evaluation_strategy = strategy,\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=epochs,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_dir= 'squad_logs',\n",
        "    logging_strategy=strategy,\n",
        "    load_best_model_at_end=True\n",
        ")"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzb8iZf5LQQg"
      },
      "source": [
        "For example, in this case we set the evaluation to be done at the end of each epoch in `evaluation_strategy`. Customize batch size per GPU core for training `per_device_train_batch_size` and evaluation `per_device_eval_batch_size`. In addition to give values for the total number of epochs to perform `num_train_epohs`, `learning_rate` and `weight_decay`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DUzYVcWPV5Z"
      },
      "source": [
        "Then it is only needed to pass the arguments and dataset to [`Trainer`](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainer#transformers.Trainer). The data collator will batch our processed examples together. The tokenizer is used again in order to perfom padding according to the model's preferences: rigth or left and with which token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRjT5yTnZDI6"
      },
      "source": [
        "from transformers import Trainer, default_data_collator"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcSaL_qe6HI9"
      },
      "source": [
        "trainer = Trainer(\n",
        "    bert_qa,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=default_data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDFqOt-4QW8q"
      },
      "source": [
        "In order to fine-tune the model it is only required to call the [`train`](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainer#transformers.Trainer.train) method for [`Trainer`](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainer#transformers.Trainer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "-kiqohIHQc2R",
        "outputId": "cd1a0862-d617-412f-fcca-fdcf8f072a2b"
      },
      "source": [
        "info_device()    \n",
        "out = trainer.train()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using GPU Tesla P100-PCIE-16GB. \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11124' max='11124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11124/11124 2:20:25, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.351000</td>\n",
              "      <td>1.043283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.726700</td>\n",
              "      <td>1.072840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.406700</td>\n",
              "      <td>1.296904</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFsuoranIfjQ"
      },
      "source": [
        "Now it is necesary to perform some operation to get the final results. We need to load the saved checkpoint and extract the information. Mention Hugging Face does not provide the training time per epoch, only total one. Due to that, we assume an equal distribution of time in each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHbVFmrCCOqc"
      },
      "source": [
        "checkpoint = qa_dir/f'checkpoint-{out.global_step}/trainer_state.json'\n",
        "\n",
        "with open(checkpoint) as json_file:\n",
        "    train_dic = json.load(json_file)\n",
        "\n",
        "total_train_time = out.metrics['train_runtime']\n",
        "training_stats = []\n",
        "for i in range(epochs):\n",
        "    training_stats.append(\n",
        "                {\n",
        "                    'epoch': i + 1,\n",
        "                    'Training Loss': train_dic['log_history'][i*2]['loss'],\n",
        "                    'Validation Loss': train_dic['log_history'][i*2+1]['eval_loss'],\n",
        "                    'Validation Time':  format_time(train_dic['log_history'][i*2+1]['eval_runtime'])\n",
        "                }\n",
        "    )"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfjbYPTqDt4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "f8e212b4-8a2e-4c19-e7bc-372cd882e2b5"
      },
      "source": [
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats['Training Time'] = format_time(total_train_time/epochs)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats = df_stats[['Training Loss', 'Validation Loss', 'Training Time', 'Validation Time']]\n",
        "\n",
        "# Save data frame\n",
        "df_stats.to_excel(qa_dir/'training_stats.xlsx')\n",
        "\n",
        "df_stats"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.3510</td>\n",
              "      <td>1.043283</td>\n",
              "      <td>0:46:49</td>\n",
              "      <td>0:02:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7267</td>\n",
              "      <td>1.072840</td>\n",
              "      <td>0:46:49</td>\n",
              "      <td>0:02:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4067</td>\n",
              "      <td>1.296904</td>\n",
              "      <td>0:46:49</td>\n",
              "      <td>0:02:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Validation Loss Training Time Validation Time\n",
              "epoch                                                              \n",
              "1             1.3510         1.043283       0:46:49         0:02:20\n",
              "2             0.7267         1.072840       0:46:49         0:02:20\n",
              "3             0.4067         1.296904       0:46:49         0:02:20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzyvvSLKHdGF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "d9a3e99f-df1c-4222-f405-e4816391f61c"
      },
      "source": [
        "plot_loss_curves(df_stats)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mSjPuJZ-XTl"
      },
      "source": [
        "### 6.5.2 - Save and load model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w13kj3lHKLIv"
      },
      "source": [
        "Save the model and the corresponding state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4KKmHUcJeQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c72165f3-8562-48bb-96ac-c43fb06fdf1b"
      },
      "source": [
        "print('Saving model, tokenizer and training arguments...')\n",
        "trainer.save_model()\n",
        "trainer.save_state()\n",
        "\n",
        "print('Saving training statistics..')\n",
        "save_json(qa_dir/'training_stats.json', training_stats)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model, tokenizer and training arguments...\n",
            "Saving training statistics..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2R7Zlxw_JCf"
      },
      "source": [
        "And if we want to load it again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUK3eaRs_Lum"
      },
      "source": [
        "'''bert_qa = BertForQuestionAnswering.from_pretrained(qa_dir)\n",
        "bert_qa.to(device)\n",
        "trainer = Trainer(\n",
        "    bert_qa,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=default_data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv56bYwLH1IG"
      },
      "source": [
        "## 6.6 - Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xr8LoOJWdpV"
      },
      "source": [
        "Once the model is trained, in order to perform the predictions and get an intuition about the result, we need to map the predictions back to parts of the context. The model itself predicts logits for the start and end position of our answers. The output of the model is a dict-like object that contains the loss (since we provided labels), the start and end logits. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ2CpVHdH5Ic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ed2ac4-813d-4ce5-f096-ea3c3b208ef2"
      },
      "source": [
        "for batch in trainer.get_test_dataloader(tokenized_datasets['test']):\n",
        "    break\n",
        "batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n",
        "with torch.no_grad():\n",
        "    output = bert_qa(**batch)\n",
        "\n",
        "print('Output of the model')\n",
        "print(output.keys())\n",
        "print('\\nDimension start and end logits')\n",
        "print(tuple(output.start_logits.shape))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output of the model\n",
            "odict_keys(['loss', 'start_logits', 'end_logits'])\n",
            "\n",
            "Dimension start and end logits\n",
            "(16, 384)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_dH31wtYt8U"
      },
      "source": [
        "There is one logit per feature and token. One idea to predict an answer is to take the index for the maximum of the start logits as a star position and the index of the maximum of the ends logits as an end position. The problem is if this prediction gives us an impossible result, as a greater start position than the end one.\n",
        "\n",
        "To classify the answer, we add the start and end logits to obtain a score. With hyper-parameter `n_best_size` we limit the possible answers. Best indices in the start and end logits are picked and gather all the answers this predicts. After checking if each one is valid, we will sort them by their score and keep the best one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mwi1uEyE7Fo"
      },
      "source": [
        "And then we can sort the `valid_answers` according to their `score` and only keep the best one. The only point left is how to check a given span is inside the context (and not the question) and how to get back the text inside. To do this, we need to add two things to our validation features:\n",
        "- the ID of the example that generated the feature (since each example can generate several features, as seen before);\n",
        "- the offset mapping that will give us a map from token indices to character positions in the context.\n",
        "\n",
        "That's why we will re-process the validation set with the following function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQVj0dCbNJbl"
      },
      "source": [
        "def prepare_test_features(examples):\n",
        "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
        "        # position is part of the context or not.\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == 1 else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1oLfP50bSAU"
      },
      "source": [
        "And like before, we can apply that function to our test set easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ysa43PrQhhE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "856056c4642b4429af66ebeb631b84da",
            "7ed69ba4d23341cbb9336b0789fbf8e3",
            "87d0dead72df43f4b34af202e9aaddc3",
            "39c51d45461f41a99858a7152ca4094c",
            "03d48ffab67d46b7accda89888d0a85b",
            "a0e4162e8a054cefbe06d5998f966c0c",
            "0b72447fda4c4b4cba86a3b3cd060206",
            "2827b3ba903241f8b0db34a65d5d5ba7"
          ]
        },
        "outputId": "18968f32-f2ad-4e8e-cb68-9499dd0a4a47"
      },
      "source": [
        "test_features = datasets['test'].map(\n",
        "    prepare_test_features,\n",
        "    batched=True,\n",
        "    remove_columns=datasets['test'].column_names\n",
        ")\n",
        "test_features = test_features.add_column('start_positions', tokenized_datasets['test']['start_positions'])\n",
        "test_features = test_features.add_column('end_positions', tokenized_datasets['test']['end_positions'])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "856056c4642b4429af66ebeb631b84da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnN3-DI6bXG2"
      },
      "source": [
        "Now we can get the predictions and the metrics for all features by using the [`predict`](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainer%20predict#transformers.Trainer.predict)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7aw7mq9RM0F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "82b1aafc-e717-4e03-f60e-f51d246446c2"
      },
      "source": [
        "info_device()\n",
        "print('Testing\\n')\n",
        "raw_predictions = trainer.predict(test_features)\n",
        "\n",
        "test_stats = {\n",
        "    'test_loss': raw_predictions.metrics['test_loss'],\n",
        "    'test_runtime': format_time(raw_predictions.metrics['test_runtime'])\n",
        "}\n",
        "\n",
        "print('\\n')\n",
        "print(f\"{'Test Loss':^12} | {'Test time':^11}\")\n",
        "print(\"-\"*27)\n",
        "print(f\"{test_stats['test_loss']:^12.6f} | {test_stats['test_runtime']:^11}\")\n",
        "print(\"-\"*27)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using GPU Tesla P100-PCIE-16GB. \n",
            "\n",
            "Testing\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-e1559867ac0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minfo_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m test_stats = {\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         output = eval_loop(\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m         )\n\u001b[1;32m   2068\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeed_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0mobserved_num_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m         \u001b[0;31m# Main evaluation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2148\u001b[0m             \u001b[0;31m# Update the observed num examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m             \u001b[0mobserved_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mdefault_data_collator\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tq29b5KZJQ9"
      },
      "source": [
        "print('Saving test statistics...')\n",
        "save_json(qa_dir/'test_stats.json', test_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbG4KyzJbut_"
      },
      "source": [
        "The `Trainer` *hides* the columns that are not used by the model (here `example_id` and `offset_mapping` which we will need for our post-processing), so we set them back:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0d33x7Me3OW"
      },
      "source": [
        "test_features.set_format(type=test_features.format[\"type\"], columns=list(test_features.features.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkeV1CEqcHsW"
      },
      "source": [
        "We set `None` in the offset mappings when it corresponds to a part of the question, so it's easy to check if an answer is fully inside the context. We also eliminate very long answers from our considerations with hyper-parameter `max_answer_length`.\n",
        "\n",
        "We also need a map between examples and their corresponding features. Also, we gather together all the answers in all the features generated by a given example, then pick the best one.\n",
        "\n",
        "The last bit to deal with is the impossible answer (when `squad_v2 = True`). We need to also grab the score for the impossible answer (which has start and end indices corresponding to the index of the CLS token). When one example gives several features, we have to predict the impossible answer when all the features give a high score to the impossible answer, since one feature could predict the impossible answer just because the answer isn't in the part of the context it has access too. We then predict the impossible answer when that score is greater than the score of the best non-impossible answer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpR-1V_cwz8O"
      },
      "source": [
        "import collections\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def postprocess_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
        "    m = nn.Softmax(dim=1)\n",
        "    all_start_logits, all_end_logits = raw_predictions\n",
        "    # Build a map example to its corresponding features.\n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = collections.defaultdict(list)\n",
        "    for i, feature in enumerate(features):\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "    # The dictionaries we have to fill.\n",
        "    predictions = collections.OrderedDict()\n",
        "\n",
        "    # Logging.\n",
        "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
        "\n",
        "    # Let's loop over all the examples!\n",
        "    for example_index, example in enumerate(tqdm(examples)):\n",
        "        # Those are the indices of the features associated to the current example.\n",
        "        feature_indices = features_per_example[example_index]\n",
        "\n",
        "        min_null_score = None # Only used if squad_v2 is True.\n",
        "        valid_answers = []\n",
        "        \n",
        "        context = example[\"context\"]\n",
        "        # Looping through all the features associated to the current example.\n",
        "        for feature_index in feature_indices:\n",
        "            # We grab the predictions of the model for this feature.\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
        "            # context.\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            # Update minimum null prediction.\n",
        "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
        "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
        "            if min_null_score is None or min_null_score < feature_null_score:\n",
        "                min_null_score = feature_null_score\n",
        "\n",
        "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
        "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                    # to part of the input_ids that are not in the context.\n",
        "                    if (\n",
        "                        start_index >= len(offset_mapping)\n",
        "                        or end_index >= len(offset_mapping)\n",
        "                        or offset_mapping[start_index] is None\n",
        "                        or offset_mapping[end_index] is None\n",
        "                    ):\n",
        "                        continue\n",
        "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                        continue\n",
        "\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    valid_answers.append(\n",
        "                        {\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                            \"text\": context[start_char: end_char]\n",
        "                        }\n",
        "                    )\n",
        "        \n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
        "\n",
        "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
        "        if not squad_v2:\n",
        "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
        "        else:\n",
        "            predictions[example[\"id\"]] = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else ''\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MbIqiaakkbH"
      },
      "source": [
        "And we can apply our post-processing function to our raw predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trrh8PkOerpE"
      },
      "source": [
        "final_predictions = postprocess_predictions(datasets['test'], test_features, raw_predictions.predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHwf6B2iNKDI"
      },
      "source": [
        "Now it is necessary to indicate how to compute metrics from the predictions. We use a [`metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric) which is in charge of compute the corresponding metrics for each model. We load it using the class method [`load_metric`](https://huggingface.co/docs/datasets/v1.4.1/package_reference/loading_methods.html?highlight=load_metric#datasets.load_metric)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu29AdtVe-kd"
      },
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")\n",
        "metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrcNU7OykqAU"
      },
      "source": [
        "We just need to format predictions and labels a bit as it expects a list of dictionaries and not one big dictionary. In the case of squad_v2, we also have to set a `no_answer_probability` argument which we set to 0.0.\n",
        "\n",
        "Metrics computation returns:\n",
        "    \n",
        "- `exact_match`: exact match (the normalized answer exactly match the gold answer).\n",
        "\n",
        "- `f1`: the F-score of predicted tokens versus the gold answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXzmbIchfLgv"
      },
      "source": [
        "if squad_v2:\n",
        "    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
        "else:\n",
        "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
        "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets['test']]\n",
        "scores = metric.compute(predictions=formatted_predictions, references=references)\n",
        "\n",
        "print(f\"{'Exact match':^13} | {'f1 score':^10}\")\n",
        "print(26*'-')\n",
        "print(f\"{scores['exact_match']:^13.5f} | {scores['f1']:^10.5f}\")\n",
        "print(26*'-')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z70BC9qnnH2I"
      },
      "source": [
        "def show_predictions(dataset, predictions, num_examples):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    df.drop(['id', 'title'], axis=1, inplace=True)\n",
        "    df['answers'] = df['answers'].map(lambda dic: dic['text'][0]).values\n",
        "    df['predicted answers'] = [predictions[idx]['prediction_text'] for idx in picks]\n",
        "    df = df[['context', 'question', 'answers', 'predicted answers']]\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
        "    display(HTML(df.to_html()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kojOMeuaoi5e"
      },
      "source": [
        "#@markdown Select number of examples to visualize it\n",
        "num_examples = 3 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "show_predictions(datasets['test'], formatted_predictions, num_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5RmM7PStRs8"
      },
      "source": [
        "### 6.6.1 - Pipeline for Custom Sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2UW-J8ZtZrZ"
      },
      "source": [
        "In order to get a fast intuiton about the application, let's define a pipeline to process and try to answer to a question from our own text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXsY72rh1NF_"
      },
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "def bert_for_qa(context, question, trainer, id='0'):\n",
        "    # Generate dataset from input data\n",
        "    dataset = Dataset.from_dict(\n",
        "        {'id': [id], 'context': [context], 'question': [question]}\n",
        "    )\n",
        "    # Preprocess data\n",
        "    features = dataset.map(\n",
        "        prepare_test_features,\n",
        "        batched=True,\n",
        "        remove_columns=dataset.column_names\n",
        "    )\n",
        "    # Predictions\n",
        "    predictions = trainer.predict(features)\n",
        "    # Postprocess data\n",
        "    processed_predictions = postprocess_predictions(dataset, features, predictions.predictions)\n",
        "    # Return answer\n",
        "    return processed_predictions[id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUQk4hhc1GYh"
      },
      "source": [
        "#@title { vertical-output: true }\n",
        "context = \"BERT is the best model for NLP, so much better than RNNs... I love it!\" #@param {type:\"string\"}\n",
        "question = \"Which model do I love?\" #@param {type:\"string\"}\n",
        "answer = bert_for_qa(context, question, trainer)\n",
        "\n",
        "print('\\nThe predicted answer is\\n')\n",
        "print(answer)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuyFHz59oCNt"
      },
      "source": [
        "To donwload it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhOP8g9MoBzP"
      },
      "source": [
        "#download_folder(qa_dir)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}